{
  "id": "ce40b20b-cf0b-471a-99ab-386b71fd2280",
  "title": "AutoQ: Automated Kernel-Wise Neural Network Quantization",
  "authors": [
    "Qian Lou",
    "Feng Guo",
    "Lantao Liu",
    "Minje Kim",
    "Lei Jiang"
  ],
  "year": 2020,
  "venue": "ICLR 2020",
  "doi": "10.48550/arXiv.1902.05690",
  "arxiv_id": "1902.05690",
  "abstract": "AutoQ는 레이어 단위를 넘어 **커널(필터) 단위**로 비트폭을 자동 할당하는 계층적 심층 강화학습(Hierarchical DRL) 프레임워크다. 같은 레이어 내 커널들도 분산이 서로 달라 중복도가 다르다는 관찰에서 출발한다. 상위 컨트롤러(HLC)가 레이어 전체 목표 비트폭을 정하면, 하위 컨트롤러(LLC)가 각 커널의 실제 비트폭을 결정하는 HIRO 기반 2단계 RL을 사용한다. 기존 레이어별 DRL 방법 대비 지연 54.06%, 에너지 50.69% 감소를 동일 정확도에서 달성했다.",
  "notes_summary": "레이어 내 커널별 분산 차이를 활용해 커널 단위 비트폭을 자동 탐색하는 계층적 DRL 프레임워크. HLC+LLC 2단계 구조로 지수적 탐색 공간 문제 해결.",
  "key_contributions": [
    "커널별 양자화: 같은 레이어 내 커널도 분산이 다르면 중복도가 달라 최적 비트폭이 다름. 레이어 단위 할당의 정밀도 낭비를 커널 단위로 해소.",
    "계층적 DRL (HIRO): 상위 컨트롤러(HLC)가 레이어 목표 비트폭 생성 → 하위 컨트롤러(LLC)가 각 커널 비트폭 결정. 지수적 탐색 공간을 분해해 탐색 효율 확보.",
    "외재적+내재적 리워드: LLC에 외재적 리워드(하드웨어 지표) 외에 HLC 목표 달성 내재적 리워드 추가. 동적 ζ 가중치로 학습 초반 목표 달성에 집중, 후반 성능 최적화.",
    "저장 오버헤드 최소화: 커널별 4비트 QBN 인덱스 저장으로 ResNet-18 기준 모델 크기의 0.07%만 추가, 실용적 커널별 양자화 가능성 실증.",
    "다중 하드웨어 일반화: 시간적(temporal) 가속기와 공간적(spatial, BitFusion) 가속기 모두에서 기존 방법 대비 우월한 성능 달성."
  ],
  "algorithms": [
    "HLC(상위 컨트롤러): 레이어별 활성화 QBN과 가중치 평균 목표 QBN 생성. TD3 기반 off-policy 업데이트.",
    "LLC(하위 컨트롤러): HLC 목표를 받아 각 커널의 실제 QBN 결정. 상태에 커널 인덱스·현재 레이어 누적 비트 할당 포함.",
    "외재적 리워드: eRd = log(acc^ψ_acc / (lat^ψ_l · en^ψ_e · area^ψ_a)). ψ 파라미터로 자원 제약(Resource) vs 정확도 보장(Accuracy) 모드 전환.",
    "내재적 리워드: iRd_Li = (1−ζ)·(−||g_Li·c_out − Σa_{Li,Kj}||_2) + ζ·ΣeRd_{Li,Kj}. ζ를 0.1→0.8로 동적 증가시켜 목표 달성→성능 최적화로 학습 전략 전환.",
    "커널별 비트폭 저장: 4비트 QBN 인덱스를 커널마다 저장. ResNet-18 기준 전체 모델 크기의 0.07% 추가 오버헤드."
  ],
  "key_equations": [
    {
      "name": "외재적 리워드 (로그 복합 지표)",
      "latex": "eRd = \\log\\frac{\\mathrm{acc}^{\\psi_{\\mathrm{acc}}}}{\\mathrm{lat}^{\\psi_l}\\cdot \\mathrm{en}^{\\psi_e}\\cdot \\mathrm{area}^{\\psi_a}}",
      "description": "정확도, 지연, 에너지, 면적을 로그 공간에서 가중 결합. ψ 조합으로 자원 제약 모드(정확도 최대화)와 정확도 보장 모드(자원 최소화) 전환."
    },
    {
      "name": "내재적 리워드 (목표 달성 + 외재적 성능)",
      "latex": "iRd_{Li} = (1-\\zeta)\\cdot\\left(-\\left\\|g_{Li}\\cdot c_{\\mathrm{out}} - \\sum_j a_{Li,K_j}\\right\\|_2\\right) + \\zeta\\cdot\\sum_j eRd_{Li,K_j}",
      "description": "LLC가 HLC 목표(g_Li·c_out)에 얼마나 근접했는지와 실제 하드웨어 성능을 가중 결합. ζ 동적 증가(0.1→0.8)로 학습 전략 전환."
    },
    {
      "name": "자원 제약 모드 파라미터 설정",
      "latex": "\\psi_{\\mathrm{acc}}=1,\\;\\psi_l=\\psi_e=\\psi_a=0\\;\\Rightarrow\\;eRd=\\log(\\mathrm{acc})",
      "description": "하드웨어 제약 하에서 정확도만 최대화. 제약은 별도의 조기 종료(penalty) 조건으로 처리."
    },
    {
      "name": "정확도 보장 모드 파라미터 설정",
      "latex": "\\psi_{\\mathrm{acc}}=2,\\;\\psi_l,\\psi_e,\\psi_a>0\\;\\Rightarrow\\;eRd=\\log\\frac{\\mathrm{acc}^2}{\\mathrm{lat}^{\\psi_l}\\cdot\\mathrm{en}^{\\psi_e}}",
      "description": "정확도를 보장하면서 지연·에너지 최소화. 정확도에 제곱 가중치를 주어 정확도 저하에 큰 페널티."
    }
  ],
  "architecture_detail": "## 1) 왜 커널 단위 양자화인가?\n\n기존 방법들(HAQ 포함)은 레이어 단위로 비트폭을 할당한다. 그런데 **같은 레이어 내 커널들도 분산이 크게 다르다**:\n- 분산이 큰 커널: 다양한 패턴 포착 → 중복도 낮음 → 높은 비트폭 필요\n- 분산이 작은 커널: 단순 패턴 → 중복도 높음 → 낮은 비트폭으로 충분\n\n레이어 단위 양자화는 이 차이를 무시해 **비트 자원 낭비**가 발생한다. AutoQ는 커널 단위로 비트폭을 할당해 이를 해결.\n\n**탐색 공간 문제**: 커널별 비트폭 탐색 공간은 $33^{\\sum c_{\\mathrm{out}}}$로 지수 폭발. 단순 RL로는 불가능 → 계층적 구조 필요.\n\n## 2) 계층적 DRL 구조 (HIRO 기반)\n\n**HIRO** (HIerarchical Reinforcement learning with Off-policy correction): 고수준 목표 설정 컨트롤러와 저수준 실행 컨트롤러를 분리.\n\n**HLC (High-Level Controller)**:\n- 레이어 i의 활성화 QBN 결정\n- 레이어 i의 가중치 평균 목표 QBN $g_{Li}$ 생성\n- TD3(Twin Delayed DDPG) 기반 off-policy 업데이트\n\n**LLC (Low-Level Controller)**:\n- HLC 목표 $g_{Li}$를 받아 각 커널 $K_j$의 실제 QBN $a_{Li,K_j}$ 결정\n- 목표 달성(HLC와의 합의)과 실제 성능 최적화를 동시에 추구\n\n두 컨트롤러는 동시에 학습. LLC는 HLC 목표를 따르면서도 커널별 세밀한 최적화.\n\n## 3) 리워드 설계 — 외재적 + 내재적\n\n**외재적 리워드** (환경에서 얻음):\n$$\neRd = \\log\\frac{\\mathrm{acc}^{\\psi_{\\mathrm{acc}}}}{\\mathrm{lat}^{\\psi_l}\\cdot \\mathrm{en}^{\\psi_e}\\cdot \\mathrm{area}^{\\psi_a}}\n$$\n$\\psi$ 파라미터로 두 가지 모드:\n- **자원 제약 모드**: $\\psi_{\\mathrm{acc}}=1$, others=0 → 제약 내 정확도 최대화\n- **정확도 보장 모드**: $\\psi_{\\mathrm{acc}}=2$, 나머지>0 → 정확도 보장하며 자원 최소화\n\n**내재적 리워드** (LLC 학습 가이드):\n$$\niRd_{Li} = (1-\\zeta)\\cdot\\left(-\\left\\|g_{Li}\\cdot c_{\\mathrm{out}} - \\sum_j a_{Li,K_j}\\right\\|_2\\right) + \\zeta\\cdot\\sum_j eRd_{Li,K_j}\n$$\n- 첫 번째 항: LLC가 HLC 목표($g_{Li}\\cdot c_{\\mathrm{out}}$)에 얼마나 근접했는지 (목표 달성)\n- 두 번째 항: 실제 하드웨어 성능 (외재적 리워드)\n- $\\zeta$: 에폭마다 0.1 → 0.8 동적 증가 → **초반엔 목표 달성에 집중, 후반엔 성능 최적화**\n\n## 4) 상태 공간 설계\n\nLLC 상태에는 레이어 정보 외에 **커널별 고유 정보**가 포함:\n- 커널 인덱스\n- 현재 레이어에서 지금까지 할당된 누적 비트 수\n- 이전 커널의 결정값\n\n이를 통해 LLC가 레이어 내 비트 예산을 관리하며 커널별 할당을 균형.\n\n## 5) 저장 오버헤드 분석\n\n커널별 QBN(0~8비트)을 4비트로 인코딩해 저장:\n- ResNet-18: 전체 모델 대비 **0.07%** 추가\n- ResNet-50: **0.05%** 추가\n\n사실상 무시할 수 있는 오버헤드로 커널별 양자화의 실용성 입증.\n\n## 6) 실험 결과 요약\n\n**시간적 가속기 (Temporal Accelerator)**:\n| 모델 | 방법 | 지연 (ms) | 에너지 절감 |\n|------|------|---------|------------|\n| ResNet-18 | AutoQ | 286.3 | 54.06% 지연 감소 |\n| ResNet-18 | HAQ(레이어별) | 640+ | 기준 |\n| MobileNetV2 | AutoQ | 10.2 | vs 23.9 (레이어별) |\n\n**공간적 가속기 (BitFusion)**:\n- ResNet-50: 42.2% 지연 감소 vs 레이어별 방법\n\n**수렴 속도**: AutoQ가 200 에피소드에서 70% 정확도 달성, 기존 DDPG는 250 에피소드에서도 20%.",
  "category": "quantization",
  "tags": [
    "autoq",
    "kernel-wise-quantization",
    "hierarchical-rl",
    "HIRO",
    "DDPG",
    "hardware-aware",
    "mixed-precision"
  ],
  "pdf_url": "https://arxiv.org/pdf/1902.05690",
  "code_url": null,
  "color_hex": "#BE185D",
  "icon_name": null
}