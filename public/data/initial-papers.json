{
  "papers": [
    {
      "title": "Deep Learning for Massive MIMO CSI Feedback",
      "authors": [
        "Chao-Kai Wen",
        "Wan-Ting Shih",
        "Shi Jin"
      ],
      "year": 2018,
      "venue": "IEEE Wireless Communications Letters",
      "doi": "10.1109/LWC.2018.2818160",
      "arxiv_id": "1712.08919",
      "abstract": "이 논문의 핵심 질문은 단순하다. \"FDD Massive MIMO에서 CSI 피드백 비트를 크게 줄여도, 기지국이 쓸 만한 CSI를 다시 복원할 수 있는가?\"\n\n기존 압축센싱(CS) 방법은 채널의 희소성 가정과 반복 최적화 복원에 의존해 계산량이 크고, 환경이 바뀌면 성능이 흔들렸다. CsiNet은 문제를 다른 관점으로 본다. CSI 피드백을 수작업 복원 규칙의 문제가 아니라, 데이터가 직접 압축 표현을 학습하는 end-to-end 표현학습 문제로 바꾼다.",
      "key_contributions": [
        "문제 재정의: CSI 피드백을 \"압축센싱 복원\"에서 \"학습형 인코딩/디코딩\"으로 전환했다.",
        "도메인 선택: 각도-지연 도메인 표현을 사용해 채널 구조(근사 희소성)를 네트워크가 더 쉽게 학습하게 했다.",
        "시스템 제약 반영: UE는 경량 인코더(Conv+FC), BS는 강한 디코더(FC+RefineNet)로 비대칭 연산 구조를 설계했다.",
        "복원 전략: coarse reconstruction -> residual refinement(RefineNet) 2단계로 복원 안정성과 정밀도를 동시에 확보했다.",
        "실험 검증: 다양한 압축비(1/4~1/64)에서 LASSO, TVAL3, BM3D-AMP 대비 일관된 NMSE 우위를 보였다.",
        "연구사적 의미: 이후 CsiNet-LSTM, CRNet, TransNet 계열로 이어지는 CSI 피드백 딥러닝 계열의 기준선이 되었다."
      ],
      "algorithms": [
        "입력 정규화/변환: CSI -> 각도-지연 도메인 H_a",
        "UE 인코딩: Conv2D 특징 추출 -> FC로 코드워드 s 생성",
        "피드백 전송: 압축비 γ에 따라 길이 M 코드워드 전달",
        "BS 복원: FC coarse 복원 -> RefineNet 잔차 보정"
      ],
      "key_equations": [
        {
          "name": "CSI 압축",
          "latex": "\\mathbf{s} = f_{\\text{enc}}(\\mathbf{H}_a) \\in \\mathbb{R}^M, \\quad M = \\lfloor N_t \\cdot N_c / \\gamma \\rfloor",
          "description": "해석: H_a는 각도-지연 도메인 CSI, s는 UE가 보내는 코드워드다. M=⌊N_tN_c/γ⌋이므로 γ를 키우면 피드백 비트는 줄지만, 같은 정보량을 더 짧은 벡터에 담아야 해서 복원 난이도는 올라간다. 즉 이 식은 \"오버헤드 절감 vs 복원 정확도\"의 첫 번째 트레이드오프를 정의한다."
        },
        {
          "name": "NMSE 손실 함수",
          "latex": "\\text{NMSE} = \\mathbb{E}\\left\\{\\frac{\\|\\mathbf{H}_a - \\hat{\\mathbf{H}}_a\\|_2^2}{\\|\\mathbf{H}_a\\|_2^2}\\right\\}",
          "description": "해석: 분자는 복원 오차 에너지, 분모는 원본 채널 에너지다. 채널 세기가 달라도 공정하게 비교되는 정규화 오차 지표이며, 값이 작을수록 복원이 정확하다. 논문에서는 이 값을 학습 목표로 최소화해, 서로 다른 압축비에서도 성능을 일관되게 비교한다."
        },
        {
          "name": "압축비",
          "latex": "\\gamma = \\frac{N_t \\times N_c}{M}",
          "description": "해석: 원본 CSI 차원(N_t×N_c) 대비 피드백 차원(M)의 비율이다. 예를 들어 N_t×N_c=1024, γ=16이면 M=64만 전송한다. γ는 시스템 설계 손잡이로, 크게 할수록 업링크 부담은 줄지만 정보 손실 위험은 커진다."
        }
      ],
      "category": "autoencoder",
      "tags": [
        "csinet",
        "autoencoder",
        "csi-feedback",
        "massive-mimo",
        "fdd",
        "deep-learning",
        "foundational"
      ],
      "pdf_url": "https://arxiv.org/pdf/1712.08919",
      "code_url": "https://github.com/sydney222/Python_CsiNet",
      "color_hex": "#2563EB",
      "architecture_detail": "2.1 문제 설정\nFDD Massive MIMO에서는 UE가 추정한 CSI를 BS로 올려야 빔포밍이 가능하다. 하지만 원시 CSI를 그대로 올리면 피드백 오버헤드가 너무 크다.\n\n2.2 기존 접근의 한계\n압축센싱(CS) 방식은 채널 희소성 가정 + 반복 최적화 복원에 의존한다. 그래서 계산이 무겁고, 실제 환경 분포가 바뀌면 성능이 쉽게 흔들린다.\n\n2.3 CsiNet 설계 철학\n핵심 전환은 \"복원 알고리즘을 사람이 설계\"하는 대신, \"압축 표현을 데이터가 학습\"하게 만드는 것이다.\n- UE(단말): 가벼운 인코더로 코드워드만 생성\n- BS(기지국): 상대적으로 무거운 디코더로 복원 품질 확보\n- RefineNet: 한 번에 완벽 복원하지 않고 잔차를 단계적으로 줄임\n\n2.4 왜 각도-지연 도메인인가\n이 도메인에서는 채널 구조가 더 정돈되어 나타나므로(근사 희소성), 네트워크가 중요한 패턴을 학습하기 쉽다.\n\n2.5 수식이 말하는 의미\n- CSI 압축식: 피드백 차원 축소의 수학적 정의\n- NMSE 식: 복원 정확도의 학습/평가 기준\n- 압축비 식: 통신 비용과 정확도 사이의 트레이드오프 손잡이\n\n2.6 이 논문이 남긴 것\nCsiNet은 CSI 피드백 연구의 기준선을 만든 논문이다. 이후 연구 대부분은 이 골격을 확장(시간 상관, 어텐션, 양자화, 일반화)하거나 대체하는 방식으로 발전했다.",
      "difficulty_level": "beginner",
      "prerequisites": [
        "Massive MIMO 기본 개념 (안테나 배열, 빔포밍)",
        "CSI(Channel State Information)가 무엇이고 왜 필요한지",
        "오토인코더 기본 구조 (인코더-잠재공간-디코더)",
        "FDD vs TDD 차이점"
      ],
      "learning_objectives": [
        "CSI 피드백 문제를 왜 딥러닝으로 접근하는지 설명할 수 있다",
        "각도-지연 도메인 변환의 목적을 이해한다",
        "CsiNet의 인코더-디코더 구조와 RefineNet 역할을 설명할 수 있다",
        "압축비(γ)와 NMSE 간 트레이드오프를 이해한다"
      ],
      "self_check_questions": [
        "CsiNet은 왜 각도-지연 도메인에서 CSI를 처리하는가?",
        "압축비 γ=16일 때, 원본 1024차원 CSI는 몇 차원으로 압축되는가?",
        "RefineNet이 없으면 어떤 문제가 생기는가?",
        "기존 압축센싱(CS) 대비 CsiNet의 핵심 차이는 무엇인가?"
      ]
    },
    {
      "title": "CsiNet-LSTM: A Deep Learning Architecture for Compressive CSI Estimation and Feedback in FDD Massive MIMO",
      "authors": [
        "Chao-Kai Wen",
        "Wan-Ting Shih",
        "Shi Jin"
      ],
      "year": 2020,
      "venue": "IEEE Transactions on Wireless Communications",
      "doi": "10.1109/TWC.2020.3006080",
      "arxiv_id": "1905.10761",
      "abstract": "이 논문의 핵심 질문은 \"시간에 따라 변하는 CSI의 프레임 간 중복성을 활용하면, 매 프레임마다 전체 CSI를 새로 보내지 않아도 충분한 복원 품질을 얻을 수 있는가?\"이다.\n\nCsiNet은 한 시점의 CSI만 독립적으로 압축하므로, 연속된 프레임 사이의 유사성을 활용하지 못한다. CsiNet-LSTM은 LSTM 순환 구조를 인코더와 디코더에 통합하여, 이전 프레임의 기억(은닉 상태)을 현재 압축에 반영한다. 덕분에 이미 전송한 정보를 중복 전송하지 않아도 되어, 동일 품질에서 피드백 오버헤드를 크게 줄인다.",
      "key_contributions": [
        "문제 정의: 기존 CsiNet이 각 프레임을 독립적으로 압축하여 시간적 중복 전송이 발생하는 비효율성을 지적했다.",
        "핵심 기법: LSTM 순환 레이어를 CNN 인코더/디코더에 통합하여, 이전 프레임의 은닉 상태를 현재 압축에 활용하는 시간적 압축 구조를 설계했다.",
        "설계 차별점: CsiNet의 공간 특징 추출(CNN)과 LSTM의 시간 기억력을 결합하여, 공간-시간 복합 정보를 하나의 파이프라인에서 처리한다.",
        "실험 검증: 시변 채널(사용자 이동 시나리오)에서 프레임 단위 CsiNet 대비 상당한 NMSE 개선을 달성하고, 다양한 이동 속도에서의 성능을 분석했다.",
        "실용성: 시변 환경에서 피드백 오버헤드를 줄이면서도 복원 품질을 유지하여, 실제 모바일 통신 환경에서의 적용 가능성을 높였다.",
        "연구사적 의미: CSI 피드백에 시간적 상관관계를 최초로 본격 활용한 연구로, 이후 MarkovNet, SLATE 등 시간축 활용 연구의 기초가 되었다."
      ],
      "algorithms": [
        "CsiNet-LSTM 인코더 (Conv + LSTM)",
        "CsiNet-LSTM 디코더 (LSTM + Deconv)",
        "시간적 CSI 압축 파이프라인"
      ],
      "key_equations": [
        {
          "name": "시간적 CSI 피드백",
          "latex": "\\mathbf{s}_t = f_{\\text{enc}}(\\mathbf{H}_{a,t}, \\mathbf{h}_{t-1})",
          "description": "해석: 인코더가 현재 CSI(H_{a,t})뿐 아니라 이전 시점의 은닉 상태(h_{t-1})도 함께 입력으로 받는다. h_{t-1}에는 이전 프레임들의 요약 정보가 담겨 있으므로, 인코더는 '이미 보낸 정보'와 '새로 변한 정보'를 구별할 수 있다. 그 결과, 중복되는 부분은 다시 전송하지 않아 코드워드 길이를 줄이면서도 복원 품질을 유지한다."
        },
        {
          "name": "LSTM 은닉 상태 갱신",
          "latex": "\\mathbf{h}_t = \\text{LSTM}(\\mathbf{s}_t, \\mathbf{h}_{t-1})",
          "description": "해석: LSTM 셀은 현재 코드워드(s_t)와 이전 기억(h_{t-1})을 결합하여 새로운 기억(h_t)을 생성한다. 입력 게이트는 새 정보 중 얼마나 저장할지, 망각 게이트는 과거 기억 중 얼마나 유지할지를 학습적으로 결정한다. 이 메커니즘 덕분에 빠르게 변하는 채널에서는 새 정보를 많이 반영하고, 느리게 변하는 채널에서는 과거 기억을 많이 재활용하는 적응적 동작이 가능하다."
        }
      ],
      "category": "autoencoder",
      "tags": [
        "csinet-lstm",
        "temporal",
        "recurrent",
        "lstm",
        "csi-feedback",
        "massive-mimo"
      ],
      "pdf_url": "https://arxiv.org/pdf/1905.10761",
      "code_url": null,
      "color_hex": "#3B82F6",
      "architecture_detail": "2.1 문제 설정\nFDD Massive MIMO에서 UE는 매 시간 슬롯마다 CSI를 BS로 피드백해야 한다. 기존 CsiNet은 각 프레임을 독립적으로 압축하므로, 연속된 프레임 사이의 유사성(시간적 상관관계)을 전혀 활용하지 못한다.\n\n2.2 기존 접근의 한계\nCsiNet은 \"정지 사진\"만 보는 모델이다. 사용자가 천천히 이동하면 CSI는 프레임 간에 매우 유사한데도, 매번 전체를 새로 압축하여 불필요한 오버헤드가 발생한다.\n\n2.3 CsiNet-LSTM 설계 철학\n핵심 아이디어는 \"동영상처럼 연속 프레임을 함께 보자\"는 것이다. CNN이 각 프레임의 공간 특징을 추출한 뒤, LSTM이 \"이전에 이미 보낸 정보\"를 기억하고 현재 프레임에서 달라진 부분만 효율적으로 인코딩한다.\n\n2.4 핵심 기법 상세\n- 인코더: CsiNet의 Conv2D 레이어로 공간 특징 추출 후, LSTM 레이어가 시간적 문맥을 추가한다.\n- 디코더: LSTM이 시간적 기억을 복원에 반영하고, DeConv 레이어가 CSI를 재구성한다.\n- 은닉 상태(h_t): 과거 프레임들의 핵심 정보를 압축 저장하는 \"메모리\"로 작동한다.\n- 게이트 메커니즘: 입력/망각/출력 게이트가 새 정보와 과거 기억의 비율을 자동 조절한다.\n\n2.5 수식이 말하는 의미\n- 시간적 피드백식: 현재 CSI와 과거 기억의 결합으로 코드워드 생성 → 중복 제거\n- LSTM 갱신식: 적응적 기억 관리 → 채널 변화 속도에 맞는 유연한 압축\n\n2.6 이 논문이 남긴 것\nCsiNet-LSTM은 CSI 피드백에 시간축 활용이라는 새로운 차원을 열었다. 이후 MarkovNet(차분 인코딩), SLATE(SwinLSTM) 등 시간적 상관관계를 활용하는 후속 연구들의 출발점이 되었다.",
      "difficulty_level": "intermediate",
      "prerequisites": [
        "CsiNet의 인코더-디코더 구조와 CSI 피드백 흐름",
        "LSTM(Long Short-Term Memory) 셀의 게이트 메커니즘 (입력/망각/출력 게이트)",
        "시계열 데이터에서 시간적 상관관계의 의미",
        "FDD Massive MIMO에서 시변 채널의 특성"
      ],
      "learning_objectives": [
        "시변 CSI에서 시간적 중복성을 활용하는 방식의 장점을 설명할 수 있다",
        "CsiNet과 CsiNet-LSTM의 구조적 차이를 비교할 수 있다",
        "LSTM 은닉 상태가 CSI 피드백에서 어떤 역할을 하는지 이해한다",
        "프레임 단위 독립 압축 대비 시간적 압축의 오버헤드 절감 원리를 파악한다"
      ],
      "self_check_questions": [
        "CsiNet-LSTM은 CsiNet과 비교해 어떤 추가 정보를 활용하는가?",
        "LSTM의 은닉 상태 h_{t-1}이 CSI 피드백에서 하는 역할은 무엇인가?",
        "사용자가 정지해 있을 때와 빠르게 이동할 때, CsiNet-LSTM의 이점은 어떻게 달라지는가?",
        "CsiNet-LSTM의 한계점은 무엇이며, 이를 개선하려면 어떤 방향이 있는가?"
      ]
    },
    {
      "title": "CRNet: A Deep-Learning Framework for CSI Feedback in Massive MIMO",
      "authors": [
        "Zhilin Lu",
        "Jintao Wang",
        "Jian Song"
      ],
      "year": 2020,
      "venue": "IEEE Transactions on Wireless Communications",
      "doi": "10.1109/TWC.2019.2951138",
      "arxiv_id": "1911.07560",
      "abstract": "이 논문의 핵심 질문은 \"CSI 행렬에 존재하는 다양한 스케일의 패턴을 동시에 포착하면, 단일 커널 크기 합성곱보다 더 나은 복원이 가능한가?\"이다.\n\nCsiNet의 RefineNet은 고정된 3×3 커널만 사용하여, 넓은 범위의 채널 상관관계를 놓칠 수 있다. CRNet은 CRBlock에서 3×3, 5×5, 7×7 등 여러 크기의 합성곱을 병렬로 적용하고, Squeeze-and-Excitation 채널 어텐션으로 각 스케일의 기여도를 자동 조절하여 CSI 복원 정확도를 크게 높였다.",
      "key_contributions": [
        "문제 정의: CsiNet의 단일 커널 크기 합성곱이 CSI 행렬의 다양한 스케일 패턴을 충분히 포착하지 못하는 한계를 지적했다.",
        "핵심 기법: 서로 다른 크기의 합성곱 필터(3×3, 5×5, 7×7)를 병렬로 적용하여 다중 해상도에서 동시에 특징을 추출하는 CRBlock을 설계했다.",
        "설계 차별점: Squeeze-and-Excitation(SE) 채널 어텐션을 CRBlock에 통합하여, 각 스케일 분기의 기여도를 데이터 기반으로 적응적으로 가중하는 구조를 채택했다.",
        "실험 검증: COST2100 실내/실외 데이터셋에서 다양한 압축비(γ=4~64)에 걸쳐 CsiNet 대비 일관된 NMSE 개선을 달성했다.",
        "실용성: 계산량 증가가 합리적인 수준이며, CRBlock의 모듈형 설계 덕분에 기존 아키텍처에 쉽게 통합할 수 있다.",
        "연구사적 의미: 다중 해상도 + 채널 어텐션 조합의 효과를 CSI 피드백에서 검증하여, ACRNet, CLNet 등 후속 연구의 기반이 되었다."
      ],
      "algorithms": [
        "CRNet 인코더",
        "CRBlock 기반 CRNet 디코더",
        "다중 해상도 특징 추출",
        "채널 주의 재보정"
      ],
      "key_equations": [
        {
          "name": "다중 해상도 특징 집계",
          "latex": "\\mathbf{F}_{\\text{out}} = \\sum_{i=1}^{K} \\alpha_i \\cdot \\text{Conv}_{k_i}(\\mathbf{F}_{\\text{in}})",
          "description": "해석: 입력 특징맵 F_in에 서로 다른 크기의 합성곱 필터(k₁=3, k₂=5, k₃=7 등)를 각각 적용한다. 작은 필터는 인접 안테나/부반송파 간 세부 패턴을, 큰 필터는 넓은 범위의 채널 상관관계를 포착한다. 각 분기의 결과에 어텐션 가중치 α를 곱해 합산하므로, 네트워크가 현재 CSI에 가장 유용한 스케일을 자동으로 선택한다."
        },
        {
          "name": "채널 주의 (SE 블록)",
          "latex": "\\mathbf{\\alpha} = \\sigma(\\mathbf{W}_2 \\cdot \\delta(\\mathbf{W}_1 \\cdot \\text{GAP}(\\mathbf{F})))",
          "description": "해석: 전역 평균 풀링(GAP)으로 각 채널의 전체 공간 정보를 하나의 스칼라로 요약한다. 이 요약 벡터가 두 개의 FC 레이어(W₁으로 축소, W₂로 복원)와 시그모이드(σ)를 통과하면 0~1 사이의 채널별 가중치가 된다. 결과적으로 '유용한 채널은 강조, 불필요한 채널은 억제'하는 재보정(recalibration) 효과를 낸다."
        }
      ],
      "category": "cnn",
      "tags": [
        "crnet",
        "multi-resolution",
        "channel-attention",
        "csi-feedback",
        "massive-mimo"
      ],
      "pdf_url": "https://arxiv.org/pdf/1911.07560",
      "code_url": "https://github.com/Kylin9511/CRNet",
      "color_hex": "#059669",
      "architecture_detail": "2.1 문제 설정\nCsiNet이 CSI 피드백에 딥러닝을 도입했지만, 복원 정확도에는 아직 개선 여지가 있다. 특히 디코더의 RefineNet이 고정 크기 합성곱만 사용하여 다양한 스케일의 채널 패턴을 충분히 활용하지 못한다.\n\n2.2 기존 접근의 한계\nCsiNet의 RefineNet은 3×3 합성곱만 사용하므로, 수용 영역(receptive field)이 제한적이다. CSI 행렬에는 인접 안테나 간 지역적 상관관계뿐 아니라, 먼 안테나 간 넓은 범위의 상관관계도 존재하는데, 단일 커널로는 이를 동시에 포착하기 어렵다.\n\n2.3 CRNet 설계 철학\n\"여러 크기의 돋보기로 동시에 보자\"가 핵심 아이디어이다. 하나의 CRBlock 안에 3×3, 5×5, 7×7 병렬 합성곱 분기를 두고, 채널 어텐션(SE)으로 각 분기의 기여도를 자동 조절한다.\n\n2.4 핵심 기법 상세\n- CRBlock: 병렬 다중 스케일 합성곱 → SE 채널 어텐션 → 잔차 연결의 3단계 구조\n- SE 채널 어텐션: GAP → FC(축소) → ReLU → FC(복원) → Sigmoid로 채널별 가중치 생성\n- 인코더: Conv2D + FC (CsiNet과 동일한 경량 구조)\n- 디코더: FC + 여러 CRBlock 적층 (품질 향상의 핵심)\n- 잔차 연결: 각 CRBlock의 입출력을 더하여 안정적 학습 보장\n\n2.5 수식이 말하는 의미\n- 다중 해상도 집계식: 다양한 스케일의 패턴을 동시 포착 → 풍부한 특징 표현\n- SE 블록식: 채널별 중요도 자동 재조정 → 유용한 정보 강조, 잡음 억제\n\n2.6 이 논문이 남긴 것\nCRNet은 CSI 피드백 디코더 설계의 새로운 기준을 세웠다. 다중 해상도 + 어텐션 조합의 효과를 검증하여, ACRNet(교차 도메인 확장), CLNet(경량화 변형) 등 다수의 후속 연구에 직접적 영향을 미쳤다.",
      "difficulty_level": "intermediate",
      "prerequisites": [
        "CsiNet의 인코더-디코더 구조와 각도-지연 도메인 변환",
        "다중 스케일 특징 추출의 개념 (Inception 모듈 등)",
        "Squeeze-and-Excitation(SE) 채널 어텐션의 원리",
        "잔차 연결(Residual Connection)의 역할과 효과"
      ],
      "learning_objectives": [
        "다중 해상도 특징 추출이 CSI 복원에 왜 유리한지 설명할 수 있다",
        "CRBlock의 병렬 합성곱 분기와 채널 어텐션 결합 구조를 이해한다",
        "CsiNet 대비 CRNet의 성능 향상 원인을 분석할 수 있다",
        "SE 블록이 특징 재보정에서 하는 역할을 설명할 수 있다"
      ],
      "self_check_questions": [
        "CRBlock에서 여러 크기의 합성곱 커널을 병렬로 사용하는 이유는 무엇인가?",
        "채널 어텐션(SE 블록)이 없으면 CRNet의 성능은 어떻게 변하겠는가?",
        "CRNet의 디코더가 여러 CRBlock을 쌓는 것은 RefineNet과 어떤 점에서 유사하고 다른가?",
        "CRNet이 CsiNet보다 계산량은 더 많은데 실용적인 이유는 무엇인가?"
      ]
    },
    {
      "title": "Lightweight and Effective CSI Feedback for Massive MIMO Systems",
      "authors": [
        "Zhilin Lu",
        "Jintao Wang",
        "Jian Song"
      ],
      "year": 2022,
      "venue": "IEEE Transactions on Wireless Communications",
      "doi": "10.1109/TWC.2021.3130271",
      "arxiv_id": "2005.00445",
      "abstract": "이 논문의 핵심 질문은 \"CRNet 수준의 CSI 복원 성능을 유지하면서도, UE(사용자 단말)에 배포 가능한 수준으로 계산량과 파라미터를 줄일 수 있는가?\"이다.\n\n기존 CRNet은 다중 해상도 합성곱과 채널 어텐션으로 높은 복원 성능을 달성했지만, 모바일 기기에서 실행하기에는 계산량과 파라미터가 부담스럽다. CLNet은 표준 합성곱을 깊이별 분리 합성곱(Depthwise Separable Conv)으로 대체하여 파라미터를 약 1/K 수준으로 줄이고, 보조 정제 네트워크(AnciNet)로 경량화에 따른 성능 손실을 보완한다.",
      "key_contributions": [
        "문제 정의: CRNet의 높은 복원 성능이 모바일 UE의 제한된 계산 자원에서는 실행 불가능한 수준임을 분석했다.",
        "핵심 기법: 표준 합성곱을 깊이별(Depthwise) + 포인트와이즈(Pointwise) 분리 합성곱으로 대체하여, 파라미터와 FLOPs를 약 1/K 수준으로 감소시켰다.",
        "설계 차별점: 경량화로 인한 성능 저하를 보완하기 위해 AnciNet 보조 정제 모듈을 도입하고, CSI의 위상 정보를 보존하는 복소수 처리 경로를 추가했다.",
        "실험 검증: CRNet과 유사한 NMSE를 달성하면서 파라미터 수를 약 1/K로 줄임을 COST2100 데이터셋에서 입증했다.",
        "실용성: 모바일 기기에서의 실시간 CSI 피드백이 가능한 수준의 경량 네트워크를 실현했다.",
        "연구사적 의미: 모바일넷 계열의 경량화 기법을 CSI 피드백에 체계적으로 적용한 최초의 연구로, 이후 ShuffleCsiNet 등 경량 아키텍처 연구에 영감을 주었다."
      ],
      "algorithms": [
        "CLNet 인코더 (경량 Conv)",
        "CLNet 디코더",
        "AnciNet 보조 정제 모듈",
        "Depthwise Separable Convolution"
      ],
      "key_equations": [
        {
          "name": "깊이별 분리 합성곱",
          "latex": "\\text{DSConv}(\\mathbf{X}) = \\text{PW}_{1\\times1}(\\text{DW}_{k\\times k}(\\mathbf{X}))",
          "description": "해석: 일반 합성곱을 2단계로 분해하여 파라미터를 대폭 줄이는 핵심 연산이다. 1단계(DW): 각 입력 채널을 독립적으로 k×k 합성곱하여 공간 패턴을 추출한다. 2단계(PW): 1×1 합성곱으로 채널 간 정보를 혼합한다. 일반 합성곱이 k²×C_in×C_out 파라미터를 사용하는 반면, 분리 합성곱은 k²×C_in + C_in×C_out으로 약 1/C_out 또는 1/k² 수준으로 줄어든다."
        },
        {
          "name": "CLNet 복잡도 감소",
          "latex": "\\frac{\\text{Params}_{\\text{CLNet}}}{\\text{Params}_{\\text{CRNet}}} \\approx \\frac{1}{K}",
          "description": "해석: CLNet이 CRNet 대비 약 1/K의 파라미터만 사용함을 나타내는 비율이다. K는 합성곱 커널 크기 관련 상수로, 분리 합성곱의 경량화 효과를 정량적으로 보여준다. 예를 들어 K=9(3×3 커널 기준)이면 파라미터가 약 1/9로 줄어든다. 이 감소에도 불구하고 AnciNet 보조 모듈이 성능을 보완하여 유사한 NMSE를 유지한다."
        }
      ],
      "category": "cnn",
      "tags": [
        "clnet",
        "lightweight",
        "depthwise-separable",
        "efficient",
        "csi-feedback",
        "massive-mimo"
      ],
      "pdf_url": "https://arxiv.org/pdf/2005.00445",
      "code_url": "https://github.com/Kylin9511/CLNet",
      "color_hex": "#10B981",
      "architecture_detail": "2.1 문제 설정\nCRNet이 높은 복원 품질을 보였지만, 모바일 UE에서 실시간으로 실행하기에는 파라미터와 FLOPs가 여전히 크다. 실제 배포를 위해서는 UE 측 인코더뿐 아니라 네트워크 전체의 경량화가 필요하다.\n\n2.2 기존 접근의 한계\nCRNet의 CRBlock은 여러 크기의 표준 합성곱을 병렬로 사용하므로 파라미터가 많다. 특히 5×5, 7×7 커널은 3×3 대비 각각 약 2.8배, 5.4배의 파라미터를 요구한다.\n\n2.3 CLNet 설계 철학\n핵심 전략은 \"같은 구조를 유지하되, 무거운 부품을 가벼운 부품으로 교체\"하는 것이다. 모바일넷에서 검증된 깊이별 분리 합성곱(DSConv)을 도입하여, CRNet의 다중 해상도 아이디어는 살리면서 계산량을 대폭 줄인다.\n\n2.4 핵심 기법 상세\n- 깊이별 합성곱(DW): 각 채널을 독립적으로 k×k 합성곱 → 공간 패턴 추출\n- 포인트와이즈 합성곱(PW): 1×1 합성곱으로 채널 간 정보 혼합 → 채널 상호작용\n- AnciNet: 경량화에 따른 미세한 성능 저하를 보완하는 보조 정제 네트워크\n- 복소수 경로: CSI의 실수부와 허수부(위상 정보)를 별도로 처리하여 위상 보존\n\n2.5 수식이 말하는 의미\n- DSConv식: 공간 처리와 채널 혼합을 분리 → 파라미터 약 1/K² 절감\n- 복잡도 비율식: CRNet 대비 정량적 파라미터 감소량을 보여주는 효율성 지표\n\n2.6 이 논문이 남긴 것\nCLNet은 \"성능과 경량성의 균형\"이라는 실용적 관점을 CSI 피드백 연구에 도입했다. 이후 ShuffleCsiNet(그룹 합성곱 활용), ENet(비대칭 설계) 등 경량 아키텍처 연구의 직접적 동기가 되었다.",
      "difficulty_level": "intermediate",
      "prerequisites": [
        "CRNet의 다중 해상도 CRBlock 구조",
        "깊이별 분리 합성곱(Depthwise Separable Conv)의 원리와 파라미터 절감 효과",
        "모바일넷(MobileNet) 계열의 경량 네트워크 설계 원칙",
        "모델 경량화의 필요성 (UE 측 제약 조건)"
      ],
      "learning_objectives": [
        "깊이별 분리 합성곱이 표준 합성곱 대비 어떻게 파라미터를 줄이는지 수식으로 설명할 수 있다",
        "CLNet이 CRNet 수준의 성능을 유지하면서 경량화를 달성하는 원리를 이해한다",
        "AnciNet 보조 정제 모듈의 역할을 설명할 수 있다",
        "경량화와 성능 간 트레이드오프를 분석할 수 있다"
      ],
      "self_check_questions": [
        "깊이별 분리 합성곱(DW+PW)이 표준 합성곱 대비 파라미터를 약 1/K² 수준으로 줄이는 원리는?",
        "AnciNet을 제거하면 CLNet 성능이 어떻게 변하겠는가?",
        "CLNet이 CRNet보다 파라미터가 적은데도 유사한 NMSE를 달성할 수 있는 이유는?",
        "UE 측 인코더를 경량화하는 것이 왜 디코더 경량화보다 중요한가?"
      ]
    },
    {
      "title": "TransNet: Full Attention Network for CSI Feedback in FDD Massive MIMO",
      "authors": [
        "Jiajia Cui",
        "Zhilin Lu",
        "Jintao Wang",
        "Jian Song"
      ],
      "year": 2022,
      "venue": "IEEE Wireless Communications Letters",
      "doi": "10.1109/LWC.2021.3132629",
      "arxiv_id": null,
      "abstract": "이 논문의 핵심 질문은 \"CNN의 제한된 수용 영역 대신 Transformer의 전역 어텐션을 사용하면, CSI 행렬 내 장거리 공간 의존성을 더 효과적으로 포착하여 복원 품질을 높일 수 있는가?\"이다.\n\nCNN 기반 CSI 피드백 모델(CsiNet, CRNet)은 합성곱 커널의 제한된 수용 영역 때문에 먼 위치 간 관계를 직접 포착하기 어렵다. TransNet은 Multi-Head Self-Attention을 전면 도입하여 CSI 행렬의 모든 위치 간 관계를 한 번에 계산하고, 특히 낮은 압축비에서 최첨단 NMSE 성능을 달성했다.",
      "key_contributions": [
        "문제 정의: CNN 합성곱의 지역적 수용 영역이 CSI 행렬 내 먼 안테나/부반송파 간 장거리 상관관계를 포착하지 못하는 구조적 한계를 지적했다.",
        "핵심 기법: CSI 피드백에 Multi-Head Self-Attention을 최초로 전면 적용하여, CSI 행렬의 모든 위치 쌍 간 전역 의존성을 학습하는 구조를 도입했다.",
        "설계 차별점: CSI 행렬을 패치로 분할하고 위치 인코딩을 추가하는 Transformer 전처리를 설계하여, 합성곱 없이도 공간적 구조 정보를 보존했다.",
        "실험 검증: COST2100 데이터셋에서 낮은 압축비(γ=4, 8)에서 CsiNet, CRNet을 능가하는 NMSE를 달성하고, 높은 압축비에서도 경쟁력 있는 성능을 보였다.",
        "실용성: 전역 어텐션의 계산 비용이 높지만, 병렬 연산에 최적화된 하드웨어(GPU)에서는 CNN과 유사한 처리 속도를 달성할 수 있다.",
        "연구사적 의미: CSI 피드백 연구에 Transformer 패러다임을 도입하여, 이후 CSI-GPT, SemCSINet, WiFo-CF 등 Transformer 기반 후속 연구의 시발점이 되었다."
      ],
      "algorithms": [
        "TransNet 인코더 (Self-Attention + FC)",
        "TransNet 디코더 (Multi-Head Attention)",
        "CSI용 Multi-Head Self-Attention",
        "CSI 행렬용 Positional Encoding"
      ],
      "key_equations": [
        {
          "name": "다중 헤드 셀프 어텐션",
          "latex": "\\text{Attention}(\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}) = \\text{softmax}\\left(\\frac{\\mathbf{Q}\\mathbf{K}^T}{\\sqrt{d_k}}\\right)\\mathbf{V}",
          "description": "해석: CSI 패치들 사이의 관계를 계산하는 핵심 연산이다. 각 패치에서 Query(질문), Key(열쇠), Value(값)를 만들고, Q와 K의 내적으로 '이 두 위치가 얼마나 관련 있는지' 유사도 점수를 계산한다. √d_k로 나누는 것은 차원이 커질 때 점수가 극단적으로 커지는 것을 방지하기 위함이다. Softmax로 정규화된 가중치로 V를 합산하면, 먼 위치의 관련 정보도 직접 반영된다."
        },
        {
          "name": "다중 헤드 출력",
          "latex": "\\text{MHA}(\\mathbf{X}) = \\text{Concat}(\\text{head}_1, \\ldots, \\text{head}_h)\\mathbf{W}^O",
          "description": "해석: 서로 다른 관점으로 어텐션을 h번 수행한 결과를 이어붙인(Concat) 후, 출력 가중치 W^O로 최종 변환한다. 하나의 어텐션 헤드는 하나의 관계 패턴만 포착하지만, 여러 헤드를 사용하면 '인접 안테나 상관', '먼 부반송파 상관' 등 다양한 유형의 의존성을 동시에 학습할 수 있다."
        }
      ],
      "category": "transformer",
      "tags": [
        "transnet",
        "transformer",
        "self-attention",
        "csi-feedback",
        "massive-mimo",
        "long-range-dependency"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#7C3AED",
      "architecture_detail": "2.1 문제 설정\nFDD Massive MIMO에서 CSI 행렬은 안테나 축과 부반송파 축을 가진 2D 구조이다. 이 행렬 내에서 먼 위치 간에도 물리적 채널 특성에 의한 상관관계가 존재한다.\n\n2.2 기존 접근의 한계\nCNN은 고정 크기 커널(예: 3×3)의 수용 영역 내에서만 패턴을 학습한다. 멀리 떨어진 위치 간 상관관계를 포착하려면 많은 레이어를 쌓아야 하며, 그래도 간접적인 전파에 의존한다.\n\n2.3 TransNet 설계 철학\n\"모든 위치 간 관계를 한 번에 직접 계산하자\"가 핵심이다. CNN의 지역 합성곱 대신 Transformer의 Self-Attention을 전면 도입하여, CSI 행렬의 모든 위치 쌍 간 유사도를 직접 계산한다.\n\n2.4 핵심 기법 상세\n- 패치 분할: CSI 행렬을 작은 패치(조각)로 나누어 Transformer의 토큰(입력 단위)으로 사용\n- 위치 인코딩: 패치의 공간적 위치 정보를 학습 가능한 임베딩으로 추가\n- Multi-Head Self-Attention: h개의 독립적 어텐션 헤드가 서로 다른 유형의 공간 의존성을 동시 학습\n- 인코더: Self-Attention 출력 → FC 압축으로 코드워드 생성\n- 디코더: FC 복원 → Multi-Head Attention으로 전역 의존성 재구성\n\n2.5 수식이 말하는 의미\n- Self-Attention식: 모든 위치 쌍의 유사도 계산 → 장거리 의존성 직접 포착\n- Multi-Head 출력식: 다양한 관계 패턴의 병렬 학습 → 풍부한 표현력\n\n2.6 이 논문이 남긴 것\nTransNet은 CSI 피드백 연구에 Transformer 패러다임을 최초로 도입했다. CNN에서 Transformer로의 아키텍처 전환을 촉발하여, CSI-GPT(생성형), SemCSINet(의미적), WiFo-CF(파운데이션 모델) 등의 연구가 이 위에서 발전했다.",
      "difficulty_level": "intermediate",
      "prerequisites": [
        "Transformer의 셀프 어텐션 메커니즘 (Query, Key, Value)",
        "CNN의 수용 영역(Receptive Field) 제한과 그 의미",
        "위치 인코딩(Positional Encoding)의 역할",
        "CsiNet/CRNet의 CNN 기반 CSI 피드백 구조"
      ],
      "learning_objectives": [
        "CNN 기반 CSI 피드백의 수용 영역 제한이 왜 문제가 되는지 설명할 수 있다",
        "셀프 어텐션이 장거리 공간 의존성을 포착하는 원리를 이해한다",
        "TransNet의 Multi-Head Self-Attention 구조를 설명할 수 있다",
        "CNN 대비 Transformer 기반 CSI 피드백의 장단점을 비교할 수 있다"
      ],
      "self_check_questions": [
        "CNN의 3×3 합성곱이 CSI 행렬의 장거리 의존성을 포착하기 어려운 이유는?",
        "Multi-Head Attention에서 헤드 수(h)를 늘리면 어떤 장점과 단점이 있는가?",
        "TransNet이 낮은 압축비에서 특히 강한 성능을 보이는 이유는 무엇인가?",
        "위치 인코딩이 없으면 TransNet은 어떤 정보를 잃게 되는가?"
      ]
    },
    {
      "title": "ACRNet: Aggregation Cross-Domain Network for CSI Feedback in Massive MIMO",
      "authors": [
        "Zhilin Lu",
        "Jintao Wang",
        "Jian Song"
      ],
      "year": 2022,
      "venue": "IEEE Transactions on Wireless Communications",
      "doi": "10.1109/TWC.2022.3183226",
      "arxiv_id": "2111.11451",
      "abstract": "이 논문의 핵심 질문은 \"CSI 행렬을 공간 도메인과 주파수 도메인에서 동시에 분석하고 두 시각의 정보를 교차 융합하면, 단일 도메인 처리보다 더 정확한 복원이 가능한가?\"이다.\n\nCRNet은 다중 해상도 합성곱으로 공간적 특징을 풍부하게 추출했지만, 주파수 도메인의 보완적 정보를 활용하지 않았다. ACRNet은 AggregationBlock에서 3×3, 5×5, 7×7 커널을 concat 방식으로 통합하고, 교차 도메인 어텐션 모듈로 공간-주파수 특징 간 상호작용을 학습하여, CRNet보다 적은 파라미터로 더 높은 복원 정확도를 달성한다.",
      "key_contributions": [
        "문제 정의: CRNet이 공간 도메인의 다중 해상도 특징만 활용하고, 주파수 도메인의 보완적 정보를 간과하는 한계를 지적했다.",
        "핵심 기법: 공간 도메인과 주파수 도메인의 특징을 교차 어텐션으로 융합하는 AggregationBlock을 설계하여, 두 도메인의 상호보완적 정보를 동시에 활용한다.",
        "설계 차별점: CRNet의 SE 기반 가중합 대신 concat + 1×1 Conv + 잔차 연결 구조를 채택하여, 정보 손실 없이 다중 스케일 특징을 통합한다.",
        "실험 검증: COST2100 실내/실외 데이터셋에서 CRNet 및 CLNet을 모든 압축비에서 능가하는 NMSE를 달성했다.",
        "실용성: CRNet보다 적은 파라미터로 더 높은 성능을 내어, 효율성과 정확도의 파레토 최적에 근접했다.",
        "연구사적 의미: 교차 도메인 특징 융합이라는 새로운 설계 원칙을 CSI 피드백에 도입하여, AiANet 등 후속 어텐션 기반 연구에 직접적 영향을 미쳤다."
      ],
      "algorithms": [
        "ACRNet 인코더",
        "AggregationBlock 기반 ACRNet 디코더",
        "교차 도메인 주의 모듈",
        "다중 스케일 특징 융합"
      ],
      "key_equations": [
        {
          "name": "교차 도메인 특징 융합",
          "latex": "\\mathbf{F}_{\\text{fused}} = \\text{Agg}(\\mathbf{F}_{\\text{spatial}}, \\mathbf{F}_{\\text{freq}}) = \\mathbf{F}_{\\text{spatial}} \\odot \\mathbf{A}_{\\text{cross}} + \\mathbf{F}_{\\text{freq}}",
          "description": "해석: 공간 도메인 특징(F_spatial)과 주파수 도메인 특징(F_freq)을 결합하는 핵심 연산이다. 교차 어텐션 맵(A_cross)은 주파수 특징의 관점에서 공간 특징의 어떤 부분이 중요한지를 판단하여 가중치를 생성한다. 이 가중치를 공간 특징에 원소별로 곱한(⊙) 뒤, 주파수 특징을 더하면 두 도메인의 정보가 상호보완적으로 결합된다."
        },
        {
          "name": "집계 블록",
          "latex": "\\mathbf{F}_{\\text{out}} = \\text{Conv}(\\text{Cat}(\\mathbf{F}_{3\\times3}, \\mathbf{F}_{5\\times5}, \\mathbf{F}_{7\\times7})) + \\mathbf{F}_{\\text{in}}",
          "description": "해석: 3×3, 5×5, 7×7 세 가지 크기의 합성곱 결과를 채널 축으로 이어붙이고(Cat), 1×1 합성곱으로 채널 수를 원래대로 줄인 뒤, 입력과 더하는(잔차 연결) 구조이다. CRNet의 SE 기반 가중합과 달리, concat 방식은 각 스케일의 정보를 모두 보존한 상태에서 1×1 Conv가 최적 조합을 학습하므로 정보 손실이 적다."
        }
      ],
      "category": "cnn",
      "tags": [
        "acrnet",
        "cross-domain",
        "aggregation",
        "multi-scale",
        "csi-feedback",
        "massive-mimo"
      ],
      "pdf_url": "https://arxiv.org/pdf/2111.11451",
      "code_url": "https://github.com/Kylin9511/ACRNet",
      "color_hex": "#F59E0B",
      "architecture_detail": "2.1 문제 설정\nCSI 행렬은 공간(안테나) 축과 주파수(부반송파) 축을 가지며, 각 축에서 서로 다른 유형의 상관관계가 존재한다. 이 두 도메인의 정보를 모두 활용하면 더 정확한 복원이 가능하다.\n\n2.2 기존 접근의 한계\nCRNet은 다중 해상도 합성곱으로 공간적 특징을 풍부하게 추출하지만, 주파수 도메인의 보완적 정보를 명시적으로 활용하지 않는다. 또한 SE 기반 가중합은 각 스케일을 스칼라로 요약하여 세밀한 정보가 손실될 수 있다.\n\n2.3 ACRNet 설계 철학\n\"공간과 주파수, 두 가지 시각으로 동시에 보자\"가 핵심 아이디어이다. AggregationBlock으로 다중 스케일 특징을 concat 방식으로 통합하고, 교차 도메인 어텐션으로 공간-주파수 간 상호작용을 명시적으로 학습한다.\n\n2.4 핵심 기법 상세\n- AggregationBlock: 3×3·5×5·7×7 커널 결과를 concat → 1×1 Conv로 채널 조정 → 잔차 연결\n- 교차 도메인 어텐션: 주파수 특징으로부터 공간 특징의 중요도 맵을 생성하여 하다마드 곱으로 재조정\n- 인코더: Conv2D + FC (경량 구조 유지)\n- 디코더: FC + AggregationBlock 적층 + 교차 도메인 모듈\n\n2.5 수식이 말하는 의미\n- 교차 도메인 융합식: 두 도메인의 상호보완적 결합 → 단일 도메인 대비 풍부한 정보\n- 집계 블록식: concat + 잔차 연결 → 정보 보존과 안정적 학습의 동시 달성\n\n2.6 이 논문이 남긴 것\nACRNet은 교차 도메인 특징 융합이라는 새로운 설계 원칙을 CSI 피드백에 도입했다. CRNet의 다중 해상도 아이디어를 계승하면서도 더 효율적인 구조로 발전시켜, AiANet이 ACRNet을 기준선으로 삼을 만큼 강력한 벤치마크가 되었다.",
      "difficulty_level": "intermediate",
      "prerequisites": [
        "CRNet의 다중 해상도 CRBlock 구조와 채널 어텐션",
        "공간 도메인과 주파수 도메인에서의 CSI 표현 차이",
        "교차 도메인(Cross-Domain) 특징 융합의 개념",
        "하다마드 곱(원소별 곱)의 의미와 활용"
      ],
      "learning_objectives": [
        "공간 도메인과 주파수 도메인에서 CSI를 동시에 처리하는 이점을 설명할 수 있다",
        "AggregationBlock의 다중 스케일 특징 융합 구조를 이해한다",
        "교차 도메인 어텐션이 특징 재조정에서 하는 역할을 설명할 수 있다",
        "CRNet 대비 ACRNet의 효율성과 성능 향상 원인을 분석할 수 있다"
      ],
      "self_check_questions": [
        "ACRNet이 공간 도메인과 주파수 도메인을 동시에 활용하는 이유는 무엇인가?",
        "AggregationBlock에서 concat + 1×1 Conv 구조가 SE 블록 대비 어떤 장점이 있는가?",
        "교차 도메인 어텐션에서 하다마드 곱은 어떤 역할을 하는가?",
        "ACRNet이 CRNet보다 적은 파라미터로 더 좋은 성능을 내는 핵심 원인은?"
      ]
    },
    {
      "title": "DS-NLCsiNet: Exploiting Non-Local Neural Networks for Massive MIMO CSI Feedback",
      "authors": [
        "Sungho Suh",
        "Jintao Wang",
        "Zhilin Lu"
      ],
      "year": 2021,
      "venue": "IEEE Communications Letters",
      "doi": "10.1109/LCOMM.2021.3073475",
      "arxiv_id": null,
      "abstract": "이 논문의 핵심 질문은 \"CNN의 지역적 합성곱으로는 놓치는 장거리 공간 의존성을 비국소(Non-Local) 연산으로 포착하면서도, 계산 비용을 낮게 유지할 수 있는가?\"이다.\n\nCsiNet과 CRNet은 합성곱 커널의 제한된 수용 영역 때문에 CSI 행렬 내 먼 위치 간 관계를 직접 포착하지 못한다. DS-NLCsiNet은 비국소 블록으로 모든 위치 쌍의 유사도를 계산하여 장거리 의존성을 포착하고, 깊이별 분리 합성곱(DS Conv)으로 나머지 연산의 계산 비용을 줄여서, 향상된 NMSE-FLOPs 트레이드오프를 달성한다.",
      "key_contributions": [
        "문제 정의: CsiNet과 CRNet의 CNN 합성곱이 CSI 행렬 내 먼 안테나/부반송파 간 장거리 상관관계를 놓치는 구조적 한계를 분석했다.",
        "핵심 기법: 비국소(Non-Local) 어텐션 블록을 도입하여 CSI 행렬의 모든 위치 쌍 간 유사도를 직접 계산하고, 장거리 의존성을 포착하는 구조를 설계했다.",
        "설계 차별점: 비국소 블록의 '넓은 시야'와 깊이별 분리 합성곱의 '가벼운 계산'을 분업시켜, 성능 향상과 경량화를 동시에 추구했다.",
        "실험 검증: COST2100 데이터셋에서 CsiNet 및 CRNet 대비 향상된 NMSE-FLOPs 트레이드오프를 달성하여, 적은 계산량으로 더 좋은 복원 품질을 보였다.",
        "실용성: 비국소 블록의 O(N²) 복잡도를 깊이별 분리 합성곱으로 보완하여, 전체적으로 합리적인 계산 비용을 유지한다.",
        "연구사적 의미: CNN 기반 CSI 피드백에 비국소 연산을 도입한 최초의 연구로, Transformer 기반 TransNet과 함께 '장거리 의존성' 포착의 중요성을 입증했다."
      ],
      "algorithms": [
        "DS-NLCsiNet 인코더",
        "DS-NLCsiNet 디코더",
        "Non-Local Attention Block",
        "Depthwise Separable Convolution"
      ],
      "key_equations": [
        {
          "name": "비국소 블록",
          "latex": "\\mathbf{y}_i = \\frac{1}{C(\\mathbf{x})} \\sum_{\\forall j} f(\\mathbf{x}_i, \\mathbf{x}_j) g(\\mathbf{x}_j)",
          "description": "해석: 특정 위치 i의 출력을 계산할 때, 가까운 이웃뿐 아니라 모든 위치 j의 정보를 가중합한다. 가중치 f(x_i, x_j)는 두 위치가 얼마나 유사한지를 측정하고, g(x_j)는 위치 j의 정보를 변환한다. C(x)는 정규화 상수로, 가중치의 합이 적절한 범위가 되도록 조절한다. CNN과 달리 거리에 관계없이 관련된 모든 위치의 정보를 직접 참조할 수 있다."
        },
        {
          "name": "임베디드 가우시안 유사도",
          "latex": "f(\\mathbf{x}_i, \\mathbf{x}_j) = e^{\\theta(\\mathbf{x}_i)^T \\phi(\\mathbf{x}_j)}",
          "description": "해석: 두 위치의 유사도를 측정하는 함수이다. 각 위치를 학습된 임베딩(θ와 φ)으로 변환한 뒤 내적을 취하고, 지수 함수를 적용한다. 소프트맥스와 결합하면 Transformer의 어텐션과 수학적으로 동일한 형태가 된다. 학습 가능한 임베딩 덕분에 단순 거리가 아닌 의미적 유사도를 기준으로 관련 위치를 찾을 수 있다."
        }
      ],
      "category": "cnn",
      "tags": [
        "ds-nlcsinet",
        "non-local",
        "depthwise-separable",
        "attention",
        "csi-feedback",
        "lightweight"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#EF4444",
      "architecture_detail": "2.1 문제 설정\nCSI 행렬에서 물리적으로 먼 안테나나 부반송파 사이에도 채널 특성에 의한 상관관계가 존재한다. 이 장거리 의존성을 포착하면 복원 정확도를 높일 수 있다.\n\n2.2 기존 접근의 한계\nCsiNet의 3×3 합성곱은 9개 이웃만 참조하고, CRNet의 7×7도 49개 이웃까지만 확장된다. 멀리 떨어진 위치의 정보를 활용하려면 많은 레이어를 쌓아야 하며, 이는 파라미터와 계산량을 증가시킨다.\n\n2.3 DS-NLCsiNet 설계 철학\n\"넓은 시야\"는 비국소 블록이, \"가벼운 계산\"은 깊이별 분리 합성곱이 각각 담당하는 분업 구조를 채택했다. 두 기법의 상호보완적 조합으로 성능과 효율을 동시에 개선한다.\n\n2.4 핵심 기법 상세\n- 비국소(Non-Local) 블록: 모든 위치 쌍의 임베디드 가우시안 유사도를 계산하여 장거리 의존성 포착\n- 깊이별 분리 합성곱(DS Conv): 지역적 패턴 추출을 담당하면서 파라미터 절감\n- 분업 구조: Non-Local → 전역 관계 학습, DS Conv → 지역 패턴 추출 + 계산량 절감\n- 잔차 연결: 비국소 블록의 출력을 입력에 더하여 학습 안정성 확보\n\n2.5 수식이 말하는 의미\n- 비국소 블록식: 거리 무관하게 모든 위치의 정보를 가중합 → 장거리 의존성 직접 포착\n- 임베디드 가우시안식: 학습 가능한 유사도 함수 → 의미적으로 관련된 위치를 자동 발견\n\n2.6 이 논문이 남긴 것\nDS-NLCsiNet은 CNN 프레임워크 안에서 장거리 의존성 문제를 해결하는 실용적 방법을 제시했다. TransNet이 Transformer로 완전 전환한 것과 달리, 기존 CNN 구조에 비국소 블록을 플러그인으로 추가하는 접근법을 보여주어, 기존 모델의 점진적 개선에 활용할 수 있는 경로를 열었다.",
      "difficulty_level": "intermediate",
      "prerequisites": [
        "CsiNet의 인코더-디코더 구조와 RefineNet",
        "비국소(Non-Local) 연산의 개념 (모든 위치 쌍의 유사도 계산)",
        "깊이별 분리 합성곱(Depthwise Separable Conv)의 원리",
        "CNN의 수용 영역 제한과 장거리 의존성 문제"
      ],
      "learning_objectives": [
        "비국소(Non-Local) 블록이 장거리 의존성을 포착하는 원리를 설명할 수 있다",
        "깊이별 분리 합성곱과 비국소 블록의 역할 분담을 이해한다",
        "임베디드 가우시안 유사도 함수의 작동 방식을 설명할 수 있다",
        "CsiNet/CRNet 대비 DS-NLCsiNet의 NMSE-FLOPs 트레이드오프 개선을 분석할 수 있다"
      ],
      "self_check_questions": [
        "비국소 블록과 Transformer의 셀프 어텐션은 어떤 점에서 유사하고 다른가?",
        "비국소 블록의 계산 복잡도가 O(N²)인 이유는 무엇이며, 이것이 실용성에 미치는 영향은?",
        "깊이별 분리 합성곱 없이 표준 합성곱만 사용하면 DS-NLCsiNet의 효율성은 어떻게 변하는가?",
        "비국소 블록의 정규화 상수 C(x)는 왜 필요한가?"
      ]
    },
    {
      "title": "ENet: Efficient CSI Feedback for Massive MIMO Communications",
      "authors": [
        "Zhilin Lu",
        "Jintao Wang",
        "Jian Song"
      ],
      "year": 2020,
      "venue": "IEEE Access",
      "doi": "10.1109/ACCESS.2020.3040386",
      "arxiv_id": null,
      "abstract": "ENet은 모바일 사용자 단말(UE)에서의 배포를 위해 인코더 복잡도 감소에 초점을 맞춘 효율적인 CSI 피드백 네트워크를 제안한다. 간소화된 인코더와 기지국 측의 더 강력한 디코더를 사용하여, UE와 BS 간의 비대칭적 계산 능력을 반영한 설계를 채택한다.",
      "key_contributions": [
        "모바일 UE를 위한 경량 인코더와 강력한 디코더의 비대칭 인코더-디코더 설계",
        "자원이 제한된 장치에 적합한 최소한의 합성곱 레이어를 갖춘 효율적인 인코더",
        "인코더 FLOPs를 크게 줄이면서도 경쟁력 있는 NMSE 달성 입증"
      ],
      "algorithms": [
        "ENet 경량 인코더",
        "ENet 고성능 디코더",
        "비대칭 구조 설계"
      ],
      "key_equations": [
        {
          "name": "인코더 복잡도",
          "latex": "C_{\\text{enc}} = \\sum_{l=1}^{L} K_l^2 \\cdot C_{\\text{in},l} \\cdot C_{\\text{out},l} \\cdot H_l \\cdot W_l",
          "description": "UE 측 인코더의 총 연산량(FLOPs)을 각 합성곱 레이어별 연산량의 합으로 나타낸다. 이 값을 최소화하는 것이 경량 인코더 설계의 핵심 목표이다."
        },
        {
          "name": "비대칭 설계 비율",
          "latex": "\\rho = \\frac{C_{\\text{enc}}}{C_{\\text{dec}}} \\ll 1",
          "description": "인코더 복잡도를 디코더 복잡도로 나눈 비율이다. 1보다 훨씬 작다는 것은 인코더(UE 측)가 디코더(BS 측)보다 훨씬 가볍게 설계되었다는 뜻이다."
        }
      ],
      "category": "cnn",
      "tags": [
        "enet",
        "efficient",
        "lightweight-encoder",
        "asymmetric",
        "csi-feedback",
        "mobile"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#F97316",
      "architecture_detail": "기지국(BS)은 강력하지만 UE(사용자 단말)는 약한 계산 자원을 가진다는 현실에 맞춘 비대칭 설계이다. UE 측 인코더는 최소한의 합성곱만 사용해 계산 부담을 줄이고, BS 측 디코더는 깊은 네트워크로 복원 품질을 최대화한다. 비유하자면, 스마트폰(UE)은 가볍게 데이터를 요약만 하고, 서버(BS)가 무거운 복원 작업을 전담하는 구조이다."
    },
    {
      "title": "Quantization of Deep Neural Networks for Accurate CSI Feedback",
      "authors": [
        "Zhilin Lu",
        "Jintao Wang",
        "Jian Song"
      ],
      "year": 2022,
      "venue": "IEEE Wireless Communications Letters",
      "doi": "10.1109/LWC.2022.3159168",
      "arxiv_id": null,
      "abstract": "이 논문의 핵심 질문은 \"딥러닝 기반 CSI 피드백 네트워크의 부동소수점 코드워드를 실제 통신 시스템의 유한 비트 피드백 링크에 맞게 양자화하면서도, 복원 성능 저하를 최소화할 수 있는가?\"이다.\n\n기존 CsiNet/CRNet은 연속 실수값 코드워드를 출력하지만, 실제 무선 채널은 유한 비트만 전송할 수 있어 양자화가 불가피하다. 본 연구는 양자화 인식 학습(QAT)을 도입하여 학습 단계에서 미리 양자화 효과를 시뮬레이션하고, STE로 미분 불가능한 양자화 함수를 우회하여 역전파를 가능하게 했다. 결과적으로 4비트 양자화만으로도 부동소수점에 근접하는 NMSE를 달성했다.",
      "key_contributions": [
        "문제 정의: 기존 CSI 피드백 연구들이 부동소수점 코드워드를 가정하여, 유한 비트 피드백이라는 실제 통신 환경과의 간극이 존재함을 지적했다.",
        "핵심 기법: 양자화 인식 학습(QAT)을 CSI 피드백에 최초로 체계적으로 적용하여, 순방향에서는 양자화를 적용하고 역방향에서는 STE로 그래디언트를 전달하는 학습 파이프라인을 설계했다.",
        "설계 차별점: 균일 양자화뿐 아니라 코드워드 분포에 적응하는 학습 가능한 비균일 양자화 레벨을 제안하여, 코드워드 통계에 맞춤화된 양자화를 구현했다.",
        "실험 검증: CsiNet과 CRNet 코드워드에 4비트 QAT를 적용했을 때, 부동소수점(32비트) 수준에 근접하는 NMSE를 달성하여 8배의 피드백 비트 절감을 입증했다.",
        "실용성: 기존 CSI 피드백 네트워크에 플러그인 형태로 적용할 수 있어, 네트워크 구조 변경 없이 실용적 배포가 가능하다.",
        "연구사적 의미: CSI 피드백의 '학습-양자화 불일치' 문제를 최초로 체계적으로 다루어, 이후 혼합 정밀도, 적응적 비트 할당, 결합 최적화 연구의 출발점이 되었다."
      ],
      "algorithms": [
        "Quantization-Aware Training (QAT)",
        "Straight-Through Estimator (STE)",
        "학습 가능 양자화 레벨",
        "균일 및 비균일 양자화"
      ],
      "key_equations": [
        {
          "name": "균일 양자화",
          "latex": "Q(x) = \\Delta \\cdot \\left\\lfloor \\frac{x}{\\Delta} + \\frac{1}{2} \\right\\rfloor, \\quad \\Delta = \\frac{x_{\\max} - x_{\\min}}{2^B - 1}",
          "description": "해석: 연속 실수 값을 일정 간격(Δ)으로 나눈 격자점에 반올림하는 연산이다. B비트이면 2^B개의 레벨로 나누며, 간격 Δ는 값 범위(x_max - x_min)를 레벨 수로 나눈 것이다. 예를 들어 4비트이면 16개 레벨, 8비트이면 256개 레벨을 사용한다. 비트 수가 적을수록 간격이 넓어져 양자화 오차가 커지지만, 피드백 비트 수는 줄어든다."
        },
        {
          "name": "직통 추정기 (STE)",
          "latex": "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}} \\approx \\frac{\\partial \\mathcal{L}}{\\partial Q(\\mathbf{w})}",
          "description": "해석: 양자화 함수 Q(·)는 계단 함수이므로 미분이 거의 모든 곳에서 0이 되어 역전파가 불가능하다. STE는 이 문제를 우회하기 위해, 역전파 시 양자화 단계를 '없는 것처럼' 항등 함수로 대체한다. 즉 순방향에서는 양자화된 값을 사용하고, 역방향에서는 양자화 전의 연속값으로 그래디언트를 전달하여 네트워크가 양자화에 강건하게 학습된다."
        },
        {
          "name": "총 피드백 비트 수",
          "latex": "B_{\\text{total}} = M \\times B = \\frac{N_t \\times N_c}{\\gamma} \\times B",
          "description": "해석: 실제 전송해야 하는 총 비트 수는 코드워드 길이(M)와 원소당 비트 수(B)의 곱이다. M은 압축비 γ에 의해 결정되고, B는 양자화 비트에 의해 결정된다. 예를 들어 N_t×N_c=1024, γ=16이면 M=64이고, B=4비트이면 B_total=256비트만 전송하면 된다. 이 값이 곧 무선 채널을 차지하는 실제 피드백 오버헤드이다."
        }
      ],
      "category": "quantization",
      "tags": [
        "quantization",
        "qat",
        "ste",
        "finite-bit-feedback",
        "csi-feedback",
        "deployment"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#DC2626",
      "architecture_detail": "2.1 문제 설정\n딥러닝 기반 CSI 피드백 네트워크(CsiNet, CRNet 등)는 인코더가 연속 실수값 코드워드를 출력한다. 하지만 실제 무선 채널은 유한 비트만 전송할 수 있으므로, 코드워드를 이산화(양자화)해야 한다.\n\n2.2 기존 접근의 한계\n연속값 코드워드를 학습한 후 양자화를 '나중에 적용'하면, 네트워크는 양자화 왜곡에 대비하지 못해 성능이 크게 떨어진다. 특히 저비트(4비트 이하) 양자화에서 이 불일치가 심각하다.\n\n2.3 양자화 인식 학습(QAT) 설계 철학\n핵심 전략은 \"시험 전에 시험 환경과 똑같이 연습하자\"이다. 학습 과정에서 미리 양자화 효과를 시뮬레이션하여, 네트워크가 양자화 왜곡에 강건한 코드워드를 출력하도록 훈련한다.\n\n2.4 핵심 기법 상세\n- 순방향(Forward): 코드워드에 균일 양자화 Q(·)를 적용하여 실제 배포와 동일한 조건 생성\n- 역방향(Backward): STE(Straight-Through Estimator)로 미분 불가능한 양자화를 우회하여 그래디언트 전달\n- 학습 가능한 양자화: 양자화 레벨을 고정하지 않고 코드워드 분포에 맞게 학습하는 비균일 양자화\n- 플러그인 적용: 기존 CsiNet/CRNet에 양자화 레이어만 삽입하여 구조 변경 없이 적용 가능\n\n2.5 수식이 말하는 의미\n- 균일 양자화식: 연속값을 이산 격자점으로 매핑 → 비트 표현의 수학적 정의\n- STE식: 양자화의 미분 불가능성 우회 → QAT를 가능하게 하는 핵심 메커니즘\n- 총 피드백 비트식: 압축비(γ)와 양자화 비트(B)의 곱으로 결정되는 실제 통신 오버헤드\n\n2.6 이 논문이 남긴 것\n코드워드 양자화 문제를 체계적으로 다룬 최초의 연구로, 이론과 실제 배포 사이의 간극을 좁혔다. 이후 혼합 정밀도 양자화, 적응적 비트 할당, BCsiNet(이진화), 결합 압축-양자화 등 다양한 양자화 연구의 기초가 되었다.",
      "difficulty_level": "intermediate",
      "prerequisites": [
        "CsiNet/CRNet의 코드워드 피드백 메커니즘",
        "양자화의 기본 개념 (연속값을 이산값으로 변환)",
        "Straight-Through Estimator(STE)의 역할",
        "부동소수점(FP32) vs 고정소수점(INT) 표현의 차이"
      ],
      "learning_objectives": [
        "부동소수점 코드워드를 유한 비트로 양자화해야 하는 실용적 이유를 설명할 수 있다",
        "양자화 인식 학습(QAT)이 사후 양자화보다 성능이 좋은 원리를 이해한다",
        "STE가 양자화의 미분 불가능 문제를 어떻게 우회하는지 설명할 수 있다",
        "총 피드백 비트 수와 압축비의 관계를 계산할 수 있다"
      ],
      "self_check_questions": [
        "학습 없이 사후 양자화를 적용하면 왜 성능이 크게 떨어지는가?",
        "STE에서 순방향은 양자화를 적용하고 역방향은 항등 함수를 쓰는 이유는?",
        "4비트 양자화와 8비트 양자화의 NMSE 차이는 얼마나 되며, 그 원인은?",
        "총 피드백 비트 수 B_total = M × B에서, M과 B 중 어느 것을 줄이는 것이 더 효과적인가?"
      ]
    },
    {
      "title": "Deep Learning Based CSI Feedback Approach for Time-Varying Massive MIMO Channels",
      "authors": [
        "Thanh-Tung Ly",
        "Ta-Sung Lee"
      ],
      "year": 2021,
      "venue": "IEEE Wireless Communications Letters",
      "doi": "10.1109/LWC.2021.3073474",
      "arxiv_id": null,
      "abstract": "본 논문은 시변 CSI 채널의 마르코프 특성을 활용하는 딥러닝 접근법인 MarkovNet을 제안한다. 차분 CSI 인코딩(연속된 CSI 프레임 간의 차이만 인코딩)을 사용하여, 고이동성 시나리오에서 시간적으로 상관된 채널의 피드백 오버헤드를 대폭 줄인다.",
      "key_contributions": [
        "피드백 감소를 위한 시간적 상관관계 활용 차분 CSI 인코딩",
        "CSI 변화를 위한 마르코프 체인 기반 시간 모델링",
        "고이동성 시변 시나리오에서의 상당한 피드백 감소 달성"
      ],
      "algorithms": [
        "차분 CSI 인코더",
        "시간 예측 네트워크",
        "차분 피드백 파이프라인"
      ],
      "key_equations": [
        {
          "name": "차분 CSI",
          "latex": "\\Delta \\mathbf{H}_t = \\mathbf{H}_t - \\hat{\\mathbf{H}}_{t-1}",
          "description": "현재 CSI에서 이전에 복원한 CSI를 빼서 \"변한 부분만\" 추출한 것이다. CSI가 천천히 변하면 ΔH가 매우 작아져 적은 비트로도 전달 가능하다."
        },
        {
          "name": "시간적 피드백 감소",
          "latex": "\\text{NMSE}_{\\Delta} = \\frac{\\|\\Delta\\mathbf{H}_t - \\Delta\\hat{\\mathbf{H}}_t\\|_2^2}{\\|\\mathbf{H}_t\\|_2^2}",
          "description": "차분 CSI(ΔH)를 복원한 결과의 NMSE이다. 전체 CSI 대신 차분만 인코딩하므로 동일 비트에서 더 낮은 NMSE를 달성할 수 있다."
        }
      ],
      "category": "autoencoder",
      "tags": [
        "temporal",
        "differential-feedback",
        "time-varying",
        "markov",
        "csi-feedback"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#6366F1",
      "architecture_detail": "시간에 따라 변하는 CSI를 효율적으로 피드백하기 위해, \"변한 부분만 보내자\"는 차분 인코딩 전략을 사용한다. 현재 CSI에서 이전 복원 CSI를 빼서 변화량(ΔH)만 인코딩하여 전송한다. CSI가 천천히 변하는 경우 ΔH는 매우 작아져 적은 비트로도 정확한 피드백이 가능하다. 마르코프 체인 관점에서 CSI의 시간 상관관계를 활용하는 구조이다."
    },
    {
      "title": "Binarized Neural Network for CSI Feedback in Massive MIMO Systems",
      "authors": [
        "Zhilin Lu",
        "Jintao Wang",
        "Jian Song"
      ],
      "year": 2021,
      "venue": "IEEE Wireless Communications Letters",
      "doi": "10.1109/LWC.2021.3088837",
      "arxiv_id": null,
      "abstract": "이 논문의 핵심 질문은 \"CSI 피드백 네트워크의 가중치와 활성화를 모두 1비트(±1)로 극단적으로 양자화해도, 실용적으로 수용 가능한 수준의 CSI 복원이 가능한가?\"이다.\n\n기존 양자화 연구(QAT)가 4~8비트를 다루었다면, BCsiNet은 가장 극단적인 1비트 양자화를 탐구한다. 가중치와 활성화를 모두 sign 함수로 이진화하고, STE로 역전파를 우회하며, L1 노름 기반 스케일링 팩터로 크기 정보를 보존한다. XNOR + 비트카운트로 합성곱을 근사하여 메모리 32배 절감과 대폭적인 연산 속도 향상을 달성하면서도, 허용 가능한 NMSE를 유지한다.",
      "key_contributions": [
        "문제 정의: IoT 기기나 초저전력 단말에서 기존 CSI 피드백 네트워크를 실행하기에는 메모리와 연산량이 지나치게 크다는 실용적 한계를 제시했다.",
        "핵심 기법: 가중치와 활성화를 모두 sign 함수로 1비트 이진화하고, L1 노름 기반 스케일링 팩터(α)로 크기 정보를 보존하는 이진 신경망(BNN)을 CSI 피드백에 최초로 적용했다.",
        "설계 차별점: XNOR과 비트카운트(popcount) 연산으로 합성곱을 근사하여 곱셈을 완전히 제거하고, 배치 정규화(BN)와 점진적 이진화 학습으로 극단적 양자화의 성능 저하를 완화했다.",
        "실험 검증: 32비트 CsiNet 대비 메모리를 약 32배 줄이고 연산 속도를 대폭 향상시키면서도, 높은 압축비에서 수용 가능한 NMSE를 달성했다.",
        "실용성: IoT, 초저전력 센서, FPGA 등 극도로 제한된 하드웨어 환경에서의 CSI 피드백 배포 가능성을 열었다.",
        "연구사적 의미: CSI 피드백 모델 압축의 극한을 탐구하여, 이진-삼진-다중비트 양자화의 스펙트럼에서 가장 극단적인 지점의 실현 가능성을 검증했다."
      ],
      "algorithms": [
        "BCsiNet (Binarized CsiNet)",
        "Sign Function with STE (이진화를 위한 부호 함수 및 STE)",
        "Scaling Factor Learning (스케일링 팩터 학습)",
        "Progressive Binarization Training (점진적 이진화 학습)"
      ],
      "key_equations": [
        {
          "name": "가중치 이진화",
          "latex": "\\mathbf{w}_b = \\alpha \\cdot \\text{sign}(\\mathbf{w}), \\quad \\alpha = \\frac{\\|\\mathbf{w}\\|_{\\ell_1}}{n}",
          "description": "해석: 가중치를 sign 함수로 +1 또는 -1로 이진화한다. 이때 L1 노름의 평균값을 스케일링 팩터(α)로 곱하여 크기 정보를 보존한다. α가 없으면 모든 가중치가 동일한 절대값(1)을 가져 표현력이 극도로 제한되지만, α를 통해 원본 가중치의 평균적인 크기를 복원한다. 수학적으로 αb ≈ W가 되어, 이진 벡터와 스칼라의 곱으로 원본을 근사하는 것이다."
        },
        {
          "name": "XNOR-비트카운트 연산",
          "latex": "\\mathbf{w}_b^T \\mathbf{a}_b \\approx \\alpha \\beta \\cdot \\text{bitcount}(\\text{XNOR}(\\text{sign}(\\mathbf{w}), \\text{sign}(\\mathbf{a})))",
          "description": "해석: 이진화된 가중치와 활성화의 내적을 비트 연산만으로 계산하는 방법이다. ±1의 곱은 부호가 같으면 +1, 다르면 -1이므로 XNOR 논리 연산으로 대체된다. 결과의 합(내적)은 1의 개수를 세는 비트카운트(popcount)로 계산한다. 32비트 곱셈-덧셈 대신 1비트 XNOR-popcount를 사용하므로 이론적으로 수십 배 빠르고, 메모리도 32배 절감된다."
        }
      ],
      "category": "quantization",
      "tags": [
        "binarization",
        "bnn",
        "1-bit",
        "extreme-compression",
        "model-compression",
        "csi-feedback"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#BE185D",
      "architecture_detail": "2.1 문제 설정\nIoT 기기나 초저전력 센서 같은 극도로 제한된 하드웨어 환경에서 CSI 피드백 네트워크를 실행하려면, 기존 32비트 부동소수점 연산은 메모리와 전력 소비 면에서 비현실적이다.\n\n2.2 기존 접근의 한계\n4~8비트 양자화(QAT)는 성능과 효율의 균형이 좋지만, 극한 환경에서는 여전히 부담스러울 수 있다. 1비트까지 줄일 수 있다면 메모리와 연산에서 획기적인 절감이 가능하다.\n\n2.3 BCsiNet 설계 철학\n\"곱셈을 완전히 없애자\"가 핵심이다. 가중치와 활성화를 모두 ±1로 이진화하면, 합성곱의 곱셈이 XNOR 논리 연산으로, 덧셈이 비트카운트(popcount)로 대체되어 하드웨어 효율이 극대화된다.\n\n2.4 핵심 기법 상세\n- Sign 이진화: sign(w)로 가중치를 +1/-1로 변환, sign(a)로 활성화도 이진화\n- 스케일링 팩터 α: L1 노름 평균으로 계산하여 이진 가중치에 크기 정보 복원\n- STE 역전파: sign 함수의 미분 불가능성을 항등 함수로 우회\n- 배치 정규화(BN): 이진화 전에 활성화를 정규화하여 sign 함수의 입력 분포를 안정화\n- 점진적 이진화: 초기에는 실수 가중치로 학습 후 점진적으로 이진화 비율을 높여 학습 안정성 확보\n\n2.5 수식이 말하는 의미\n- 이진화식: 가중치를 ±1 + 스케일링 팩터로 근사 → 32배 메모리 절감의 수학적 기반\n- XNOR-비트카운트식: 곱셈을 논리 연산으로 대체 → 하드웨어 수준의 연산 가속\n\n2.6 이 논문이 남긴 것\nBCsiNet은 CSI 피드백 모델 압축의 극한을 탐구한 연구이다. 1비트 양자화의 실현 가능성을 보여줌으로써, 이후 삼진(TCsiNet, {-1,0,+1})이 '0 상태'를 추가하여 더 나은 정확도-효율 균형을 달성하는 방향으로 발전했다.",
      "difficulty_level": "advanced",
      "prerequisites": [
        "양자화 인식 학습(QAT)과 STE(Straight-Through Estimator)의 동작 원리",
        "이진 신경망(BNN)의 개념: 가중치와 활성화를 ±1로 양자화",
        "XNOR 연산과 비트카운트(popcount)로 내적을 근사하는 원리",
        "배치 정규화(Batch Normalization)의 역할과 BNN에서의 중요성"
      ],
      "learning_objectives": [
        "이진 신경망에서 sign 함수와 STE의 결합이 학습을 가능하게 하는 원리를 설명할 수 있다",
        "XNOR-비트카운트 연산이 일반 행렬곱을 대체하는 방법을 이해한다",
        "스케일링 팩터 α가 이진화 오차를 줄이는 역할을 설명할 수 있다",
        "BCsiNet의 극단적 경량화와 성능 손실 간 트레이드오프를 분석할 수 있다"
      ],
      "self_check_questions": [
        "sign 함수의 미분이 거의 모든 곳에서 0인데, BNN은 어떻게 학습이 가능한가?",
        "XNOR-비트카운트 연산이 일반 곱셈-덧셈보다 빠른 이유는 무엇인가?",
        "스케일링 팩터 α = ||w||₁/n 으로 설정하는 이유는 무엇인가?",
        "BCsiNet이 실용적일 수 있는 시나리오와 한계가 있는 시나리오는 각각 무엇인가?"
      ]
    },
    {
      "title": "Knowledge Distillation-Based DNN for CSI Feedback in Massive MIMO Systems",
      "authors": [
        "Zhilin Lu",
        "Jintao Wang",
        "Jian Song"
      ],
      "year": 2022,
      "venue": "IEEE Transactions on Vehicular Technology",
      "doi": "10.1109/TVT.2022.3165837",
      "arxiv_id": null,
      "abstract": "본 논문은 지식 증류(Knowledge Distillation)를 CSI 피드백 네트워크에 적용하여, 소형 학생 인코더가 대형 교사 네트워크를 모방하도록 학습시킨다. 증류 손실은 복원 MSE와 중간 특징 매칭을 결합하며, 이를 통해 경량 인코더가 UE 측의 연산량을 크게 줄이면서도 대형 모델에 근접한 성능을 달성할 수 있다.",
      "key_contributions": [
        "교사-학생 인코더 학습을 활용한 CSI 피드백용 지식 증류 프레임워크",
        "출력 MSE와 중간 특징 매칭을 결합한 증류 손실 함수",
        "학생 인코더가 파라미터를 60-75% 줄이면서도 교사에 근접한 NMSE를 달성함을 입증"
      ],
      "algorithms": [
        "Teacher-Student Distillation (교사-학생 증류)",
        "Feature-Level Knowledge Transfer (특징 수준 지식 전이)",
        "Output-Level Knowledge Transfer (출력 수준 지식 전이)",
        "Combined Distillation Training (결합 증류 학습)"
      ],
      "key_equations": [
        {
          "name": "지식 증류 손실",
          "latex": "\\mathcal{L}_{\\text{KD}} = \\alpha \\cdot \\|\\hat{\\mathbf{H}}_s - \\mathbf{H}\\|_2^2 + (1-\\alpha) \\cdot \\sum_{l} \\|\\mathbf{f}_s^{(l)} - \\mathbf{f}_t^{(l)}\\|_2^2",
          "description": "학생 네트워크의 손실 = ①CSI 복원 오차(MSE) + ②교사의 중간 특징맵과 학생의 중간 특징맵 차이. ②가 \"교사의 노하우를 모방\"하는 항으로, 학생이 교사처럼 특징을 추출하도록 유도한다."
        },
        {
          "name": "학생 네트워크 파라미터 감소",
          "latex": "\\eta = 1 - \\frac{|\\theta_s|}{|\\theta_t|}",
          "description": "교사 대비 학생이 얼마나 작은지를 나타내는 비율이다. 예를 들어 0.8이면 교사의 80% 파라미터를 제거했다는 뜻이며, 그래도 증류 덕분에 성능 저하가 적다."
        }
      ],
      "category": "cnn",
      "tags": [
        "knowledge-distillation",
        "teacher-student",
        "model-compression",
        "lightweight",
        "csi-feedback"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#EC4899",
      "architecture_detail": "큰 네트워크(교사)의 지식을 작은 네트워크(학생)에 전달하는 지식 증류 기법이다. 교사 네트워크는 고성능 CsiNet/CRNet이고, 학생 네트워크는 파라미터가 적은 경량 버전이다. 학생은 정답 라벨뿐 아니라 교사의 중간 특징맵과 소프트 출력도 모방하여 학습하므로, 작은 크기에 비해 높은 복원 성능을 보인다. 비유하면 \"경험 많은 선배가 핵심 노하우를 후배에게 전수\"하는 것과 같다."
    },
    {
      "title": "Attention Mechanism-Based CSI Feedback Network for Massive MIMO Systems",
      "authors": [
        "Jiajia Cui",
        "Zhilin Lu",
        "Jintao Wang",
        "Jian Song"
      ],
      "year": 2021,
      "venue": "IET Communications",
      "doi": "10.1049/cmu2.12155",
      "arxiv_id": null,
      "abstract": "본 논문은 공간 및 채널 이중 어텐션 메커니즘을 CSI 피드백 네트워크에 도입한다. 공간 어텐션은 각도-지연 영역에서 중요한 공간 위치에 집중하고, 채널 어텐션은 특징 채널에 가중치를 재조정한다. 이중 어텐션과 잔차 구조의 결합을 통해 유사한 복잡도에서 CsiNet보다 향상된 NMSE를 달성한다.",
      "key_contributions": [
        "CSI 피드백을 위한 이중 어텐션(공간 + 채널) 메커니즘",
        "CSI 행렬에서 중요한 각도-지연 위치를 강조하는 공간 어텐션",
        "유사한 인코더 복잡도에서 CsiNet 대비 향상된 NMSE"
      ],
      "algorithms": [
        "Spatial Attention Module (공간 어텐션 모듈)",
        "Channel Attention Module (채널 어텐션 모듈)",
        "Dual-Attention Residual Block (이중 어텐션 잔차 블록)",
        "Attention-Enhanced CSI Decoder (어텐션 강화 CSI 디코더)"
      ],
      "key_equations": [
        {
          "name": "공간 주의",
          "latex": "\\mathbf{A}_s = \\sigma(\\text{Conv}_{7\\times7}([\\text{AvgPool}(\\mathbf{F}); \\text{MaxPool}(\\mathbf{F})]))",
          "description": "CSI 행렬의 \"어떤 공간 위치가 중요한가\"를 학습하는 맵이다. 채널 축으로 평균 풀링과 최대 풀링을 한 결과를 합성곱으로 결합하여, 위치별 0~1 가중치를 생성한다."
        },
        {
          "name": "채널 주의",
          "latex": "\\mathbf{A}_c = \\sigma(\\text{MLP}(\\text{GAP}(\\mathbf{F})) + \\text{MLP}(\\text{GMP}(\\mathbf{F})))",
          "description": "\"어떤 특징 채널이 유용한가\"를 학습하는 가중치이다. 전역 평균 풀링과 최대 풀링으로 채널별 요약을 만들고, 공유 MLP를 통과시켜 채널별 0~1 가중치를 출력한다."
        }
      ],
      "category": "cnn",
      "tags": [
        "attention",
        "spatial-attention",
        "channel-attention",
        "dual-attention",
        "csi-feedback"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#0EA5E9",
      "architecture_detail": "공간 주의(Spatial Attention)와 채널 주의(Channel Attention)를 동시에 활용하는 듀얼 어텐션 구조이다. 공간 주의는 \"CSI 행렬에서 어느 위치가 중요한가\"를 학습하여 해당 영역을 강조하고, 채널 주의는 \"어떤 특징 채널이 유용한가\"를 판단하여 채널별 가중치를 조절한다. 두 주의 메커니즘을 결합하면, 네트워크가 핵심 정보에 집중하여 효율적으로 CSI를 압축·복원할 수 있다."
    },
    {
      "title": "CSI-GPT: Integrating Generative Pre-Trained Transformer with Federated-Tuning for Channel Estimation in Massive MIMO",
      "authors": [
        "Ye Xue",
        "Chao-Kai Wen",
        "Shi Jin"
      ],
      "year": 2024,
      "venue": "IEEE Transactions on Wireless Communications",
      "doi": "10.1109/TWC.2024.3364197",
      "arxiv_id": "2309.02726",
      "abstract": "이 논문의 핵심 질문은 \"GPT 스타일의 대규모 생성 모델을 CSI 피드백에 적용하고, 연합학습으로 환경별 적응을 수행하면, 다양한 안테나 구성과 채널 환경에 걸쳐 일반화되는 범용 CSI 모델을 만들 수 있는가?\"이다.\n\n기존 CSI 피드백 모델은 특정 환경(실내/실외, 특정 안테나 수)에서 학습하면 다른 환경에서 성능이 급락하는 일반화 문제가 있었다. CSI-GPT는 다양한 환경의 CSI 데이터로 대규모 Transformer를 사전학습하여 범용적 CSI 표현을 학습하고, 각 기지국에서 원본 데이터를 공유하지 않고 연합학습으로 미세조정하여 환경별 적응과 프라이버시 보호를 동시에 달성한다.",
      "key_contributions": [
        "문제 정의: 기존 CSI 피드백 모델이 특정 환경에 과적합(overfitting)되어 새로운 환경에서 성능이 급락하는 일반화 문제를 근본적으로 해결하고자 했다.",
        "핵심 기법: GPT 스타일의 자기회귀 Transformer를 CSI에 적용하여, CSI 행렬의 원소를 순차적으로 예측하는 생성적 사전학습을 수행했다.",
        "설계 차별점: 다양한 채널 환경과 안테나 구성의 대규모 CSI 데이터로 사전학습한 후, 각 기지국에서 연합학습(Federated Fine-Tuning)으로 로컬 적응을 수행하여 데이터 프라이버시를 보호했다.",
        "실험 검증: 다양한 안테나 구성(32×2, 64×4 등)과 채널 모델(실내/실외/도심)에 걸쳐, 환경별 개별 학습 대비 우수하거나 동등한 복원 성능을 달성했다.",
        "실용성: 하나의 사전학습 모델로 다양한 환경에 적응할 수 있어, 환경마다 별도 모델을 학습·배포하는 비용을 대폭 절감한다.",
        "연구사적 의미: CSI 피드백에 '파운데이션 모델(Foundation Model)' 패러다임을 최초로 도입하여, WiFo-CF 등 후속 대규모 모델 연구의 시발점이 되었다."
      ],
      "algorithms": [
        "CSI-GPT (Generative Pre-Trained Transformer for CSI)",
        "Federated Fine-Tuning (연합 미세 조정)",
        "Autoregressive CSI Generation (자기회귀적 CSI 생성)",
        "Masked CSI Prediction (마스크 CSI 예측)"
      ],
      "key_equations": [
        {
          "name": "자기회귀 CSI 예측",
          "latex": "p(\\mathbf{H}) = \\prod_{i=1}^{N} p(h_i | h_1, \\ldots, h_{i-1}; \\theta)",
          "description": "해석: CSI 행렬의 원소를 하나씩 순서대로 예측하는 자기회귀 생성 방식이다. 각 원소 h_i는 '지금까지 본 원소들(h_1,...,h_{i-1})'에 조건부로 생성되며, GPT가 다음 단어를 예측하는 것과 같은 원리이다. 이 방식은 CSI 원소 간의 순차적 의존성을 명시적으로 모델링하여, 전체 CSI 분포를 학습할 수 있다. 사전학습 단계에서 이 예측 과제를 대규모로 수행하여 범용적 CSI 표현을 습득한다."
        },
        {
          "name": "연합 집계",
          "latex": "\\theta_{\\text{global}} = \\sum_{k=1}^{K} \\frac{n_k}{n} \\theta_k",
          "description": "해석: K개 기지국의 로컬 모델 파라미터를 중앙 서버에서 가중 평균하여 글로벌 모델을 업데이트한다. 각 기지국 k의 데이터 양 n_k에 비례하여 가중하므로, 데이터가 많은 기지국의 학습 결과가 더 크게 반영된다. 중요한 점은 원본 CSI 데이터가 기지국 밖으로 나가지 않고 모델 파라미터만 공유되므로, 개별 사용자의 채널 정보가 프라이버시 보호된다는 것이다."
        }
      ],
      "category": "transformer",
      "tags": [
        "gpt",
        "generative",
        "pre-training",
        "federated-learning",
        "csi-feedback",
        "generalization"
      ],
      "pdf_url": "https://arxiv.org/pdf/2309.02726",
      "code_url": null,
      "color_hex": "#8B5CF6",
      "architecture_detail": "2.1 문제 설정\n실제 통신 환경은 실내, 실외, 도심, 교외 등 매우 다양하고, 안테나 구성(32×2, 64×4 등)도 기지국마다 다르다. 기존 CSI 피드백 모델은 특정 환경에서만 학습하므로, 새로운 환경에서 성능이 급락하는 일반화 문제가 심각하다.\n\n2.2 기존 접근의 한계\nCsiNet 계열은 특정 시나리오의 데이터로 학습하면 해당 환경에서는 뛰어나지만, 학습에 포함되지 않은 새로운 환경에서는 재학습이 필요하다. 환경마다 별도 모델을 학습·배포하는 것은 비용과 관리 측면에서 비현실적이다.\n\n2.3 CSI-GPT 설계 철학\n\"하나의 모델이 모든 환경을 커버하자\"가 핵심이다. NLP의 GPT처럼 대규모 데이터로 사전학습하여 범용적 표현을 학습한 후, 각 환경에는 가볍게 미세조정만 수행한다. 연합학습을 통해 데이터를 공유하지 않고도 환경별 적응이 가능하다.\n\n2.4 핵심 기법 상세\n- 자기회귀 생성: CSI 원소를 순차적으로 예측하는 GPT 스타일의 Transformer 디코더\n- 사전학습: 다양한 환경의 대규모 CSI 데이터로 다음 원소 예측 과제를 수행하여 범용적 CSI 표현 학습\n- 연합 미세조정: 각 기지국이 로컬 데이터로 모델을 미세조정하고, 서버에서 파라미터를 가중 평균으로 집계\n- 프라이버시 보호: 원본 CSI 데이터는 기지국 밖으로 나가지 않고, 모델 파라미터만 교환\n\n2.5 수식이 말하는 의미\n- 자기회귀 예측식: CSI의 순차적 구조를 활용한 생성적 학습 → 범용적 CSI 분포 모델링\n- 연합 집계식: 데이터 프라이버시를 유지하면서 분산 학습 → 실용적 환경 적응\n\n2.6 이 논문이 남긴 것\nCSI-GPT는 CSI 피드백에 파운데이션 모델 패러다임을 최초로 도입한 연구이다. '사전학습 → 미세조정'이라는 전이학습 접근법과 연합학습의 결합을 제안하여, 이후 WiFo-CF(MoE 파운데이션 모델), LVM4CF(비전 모델 활용) 등 대규모 모델 연구의 시발점이 되었다.",
      "difficulty_level": "advanced",
      "prerequisites": [
        "GPT의 자기회귀(Autoregressive) 생성 원리와 Transformer 디코더 구조",
        "사전학습(Pre-training)과 미세조정(Fine-tuning)의 전이학습 패러다임",
        "연합학습(Federated Learning)의 기본 원리와 데이터 프라이버시 보호",
        "CSI 피드백에서 환경 일반화(Cross-Scenario Generalization)의 중요성"
      ],
      "learning_objectives": [
        "GPT 스타일 자기회귀 생성이 CSI 피드백에 적용되는 원리를 설명할 수 있다",
        "사전학습-미세조정 패러다임이 환경 일반화 문제를 해결하는 방식을 이해한다",
        "연합학습이 CSI 데이터 프라이버시를 보호하면서 모델을 개선하는 원리를 설명할 수 있다",
        "기존 CsiNet 계열과 CSI-GPT의 접근 방식 차이를 분석할 수 있다"
      ],
      "self_check_questions": [
        "CSI-GPT에서 CSI 원소를 순차적으로 예측하는 자기회귀 방식의 장점과 단점은 무엇인가?",
        "사전학습 없이 특정 환경에서만 학습한 모델이 새로운 환경에서 성능이 떨어지는 이유는?",
        "연합학습에서 글로벌 모델을 가중 평균으로 업데이트하는 이유는 무엇인가?",
        "CSI-GPT와 CsiNet의 가장 근본적인 설계 철학 차이는 무엇인가?"
      ]
    },
    {
      "title": "Deep Learning-Based CSI Feedback with Variable Length Codewords for Adaptive FDD Massive MIMO",
      "authors": [
        "Chao-Kai Wen",
        "Wan-Ting Shih",
        "Shi Jin"
      ],
      "year": 2019,
      "venue": "IEEE Wireless Communications Letters",
      "doi": "10.1109/LWC.2019.2921137",
      "arxiv_id": null,
      "abstract": "CsiNet+는 가변 길이 코드워드 피드백을 도입하여 CsiNet을 확장하며, 채널 품질에 따라 적응적 압축률 선택이 가능하다. 인코더가 다양한 길이의 코드워드를 생성할 수 있어, UE가 가용한 업링크 대역폭에 따라 피드백 오버헤드와 복원 정확도 간의 트레이드오프를 조절할 수 있다. 이는 새로운 점진적 인코딩 기법을 통해 달성된다.",
      "key_contributions": [
        "적응적 압축률을 가능하게 하는 가변 길이 코드워드 CSI 피드백",
        "더 긴 코드워드가 짧은 코드워드를 정제하는 점진적 인코딩 기법",
        "채널 조건에 기반한 적응적 피드백 대역폭 할당"
      ],
      "algorithms": [
        "CsiNet+ Progressive Encoder (CsiNet+ 점진적 인코더)",
        "Variable-Length Codeword Generation (가변 길이 코드워드 생성)",
        "Adaptive Compression Ratio Selection (적응적 압축률 선택)",
        "Incremental Decoder (증분 디코더)"
      ],
      "key_equations": [
        {
          "name": "점진적 인코딩",
          "latex": "\\mathbf{s}_{1:M} = [\\mathbf{s}_{1:M_1}, \\mathbf{s}_{M_1+1:M_2}, \\ldots, \\mathbf{s}_{M_{K-1}+1:M}]",
          "description": "하나의 인코더가 점점 더 긴 코드워드를 출력한다. 처음 M₁개 원소만으로 대략적 복원이 가능하고, 추가 원소가 디테일을 보완한다. 마치 저화질 → 고화질로 점진 로딩하는 것과 같다."
        },
        {
          "name": "적응적 레이트 선택",
          "latex": "M^* = \\arg\\min_{M_k} M_k \\quad \\text{s.t.} \\quad \\text{NMSE}(M_k) \\leq \\epsilon",
          "description": "목표 품질(ε)을 만족하는 최소 코드워드 길이 M_k를 선택한다. 채널이 단순하면 짧은 코드워드로 충분하고, 복잡하면 긴 코드워드를 사용하여 통신 자원을 효율적으로 쓴다."
        }
      ],
      "category": "autoencoder",
      "tags": [
        "csinet-plus",
        "variable-rate",
        "adaptive",
        "progressive-encoding",
        "csi-feedback"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#1D4ED8",
      "architecture_detail": "압축비를 상황에 맞게 유연하게 바꿀 수 있는 가변 길이 코드워드 구조이다. 기존 CsiNet은 압축비마다 별도 모델을 학습해야 했지만, CsiNet+는 하나의 인코더에서 다양한 길이의 코드워드를 점진적으로 출력한다. 채널 상태가 좋을 때는 짧은 코드워드를, 나쁠 때는 긴 코드워드를 사용하여, 한 모델로 여러 압축비를 커버한다. 실용적인 적응형 FDD 시스템에 적합하다."
    },
    {
      "title": "Binarized Aggregated Network With Quantization: Flexible Deep Learning Deployment for CSI Feedback in Massive MIMO Systems",
      "authors": [
        "Zhilin Lu",
        "Xudong Zhang",
        "Hongyi He",
        "Jintao Wang",
        "Jian Song"
      ],
      "year": 2022,
      "venue": "IEEE Transactions on Wireless Communications",
      "doi": "10.1109/TWC.2022.3141653",
      "arxiv_id": null,
      "abstract": "본 논문은 CSI 피드백 네트워크를 위한 혼합 정밀도 양자화 프레임워크를 제안한다. 모든 레이어에 동일한 비트 폭을 적용하는 균일 양자화와 달리, 본 방법은 양자화 오류에 대한 민감도에 따라 각 레이어에 서로 다른 비트 폭을 할당하여 더 나은 NMSE-비트율 트레이드오프를 달성한다. 하드웨어 인식 탐색 알고리즘이 레이어별 최적 비트 할당을 찾는다.",
      "key_contributions": [
        "CSI 피드백을 위해 레이어별로 서로 다른 비트 폭을 할당하는 혼합 정밀도 양자화 프레임워크",
        "레이어 민감도 분석에 기반한 하드웨어 인식 비트 할당 탐색",
        "0.5dB 미만의 NMSE 저하로 모델 크기의 2-4배 압축을 입증"
      ],
      "algorithms": [
        "Mixed-Precision Quantization Search (혼합 정밀도 양자화 탐색)",
        "Layer Sensitivity Analysis (레이어 민감도 분석)",
        "Hardware-Aware Bit Allocation (하드웨어 인식 비트 할당)",
        "Fine-Tuning with STE (STE를 활용한 미세 조정)"
      ],
      "key_equations": [
        {
          "name": "혼합 정밀도 목적 함수",
          "latex": "\\min_{\\{b_l\\}} \\text{NMSE}(\\{b_l\\}) \\quad \\text{s.t.} \\quad \\sum_{l=1}^{L} |\\theta_l| \\cdot b_l \\leq B_{\\text{budget}}",
          "description": "전체 비트 예산(B_total) 제약 하에서, 각 레이어의 비트폭(b_l)을 선택하여 최종 NMSE를 최소화하는 최적화 문제이다. 모든 레이어를 같은 비트로 양자화하는 것보다 효율적이다."
        },
        {
          "name": "레이어 민감도",
          "latex": "S_l = \\frac{\\partial \\text{NMSE}}{\\partial b_l} \\approx \\text{NMSE}(b_l=8) - \\text{NMSE}(b_l=4)",
          "description": "한 레이어의 비트폭을 8비트에서 4비트로 줄였을 때 NMSE가 얼마나 나빠지는지를 측정한 값이다. 민감도가 높은 레이어는 비트를 많이 유지해야 한다."
        }
      ],
      "category": "quantization",
      "tags": [
        "mixed-precision",
        "quantization",
        "bit-allocation",
        "hardware-aware",
        "csi-feedback",
        "model-compression"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#9333EA",
      "architecture_detail": "네트워크의 모든 레이어를 같은 비트로 양자화하는 대신, 각 레이어의 민감도에 따라 서로 다른 비트폭을 할당하는 혼합 정밀도 전략이다. 출력 변화에 민감한 레이어(주로 앞쪽과 뒤쪽)에는 8비트 등 높은 정밀도를 유지하고, 덜 민감한 중간 레이어에는 4비트나 2비트를 사용한다. 비유하자면, \"중요한 부분에는 고화질을, 덜 중요한 부분에는 저화질을 배정\"하여 전체 모델 크기를 줄이는 방식이다."
    },
    {
      "title": "Pruning Deep Neural Networks for Efficient CSI Feedback",
      "authors": [
        "Zhilin Lu",
        "Jintao Wang",
        "Jian Song"
      ],
      "year": 2023,
      "venue": "IEEE Communications Letters",
      "doi": "10.1109/LCOMM.2023.3245112",
      "arxiv_id": null,
      "abstract": "본 논문은 구조적 프루닝을 CSI 피드백 네트워크에 적용하여 불필요한 필터와 채널을 제거함으로써 UE에 배포 가능한 소형 모델을 생성한다. 2단계 접근법으로 먼저 L1 노름 순위를 통해 중요하지 않은 필터를 식별한 후, 프루닝된 네트워크를 미세 조정하여 정확도를 회복한다. 결과적으로 최소한의 NMSE 손실로 50-70%의 파라미터 감소를 달성한다.",
      "key_contributions": [
        "CSI 피드백 인코더 및 디코더 네트워크를 위한 구조적 필터 프루닝 프레임워크",
        "불필요한 합성곱 필터 식별을 위한 L1 노름 기반 중요도 순위",
        "COST2100에서 1dB 미만의 NMSE 저하로 50-70%의 파라미터 감소 달성"
      ],
      "algorithms": [
        "Structured Filter Pruning (구조적 필터 프루닝)",
        "L1-Norm Importance Ranking (L1 노름 중요도 순위)",
        "Iterative Prune-and-Retrain (반복적 프루닝 및 재학습)",
        "Channel Pruning (채널 프루닝)"
      ],
      "key_equations": [
        {
          "name": "필터 중요도 점수",
          "latex": "I_j = \\|\\mathbf{F}_j\\|_1 = \\sum_{c,h,w} |F_{j,c,h,w}|",
          "description": "합성곱 필터의 가중치 절대값 합(L1 norm)으로 중요도를 매긴다. 값이 큰 필터는 출력에 큰 영향을 미치므로 보존하고, 작은 필터는 제거해도 성능 영향이 적다."
        },
        {
          "name": "가지치기 비율",
          "latex": "r = 1 - \\frac{|\\mathcal{F}_{\\text{kept}}|}{|\\mathcal{F}_{\\text{total}}|}",
          "description": "전체 필터 중 제거된 필터의 비율이다. 예를 들어 0.5이면 절반의 필터를 제거한 것이며, 비율이 높을수록 모델이 가벼워지지만 성능 저하 위험이 커진다."
        }
      ],
      "category": "cnn",
      "tags": [
        "pruning",
        "structured-pruning",
        "filter-pruning",
        "model-compression",
        "lightweight",
        "csi-feedback"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#A21CAF",
      "architecture_detail": "\"쓸모없는 연결은 잘라내자\"는 가지치기(Pruning) 기반 경량화이다. 각 합성곱 필터의 중요도를 L1-norm으로 측정하여, 점수가 낮은(영향이 적은) 필터를 통째로 제거한다. 제거 후 남은 네트워크를 미세조정(fine-tuning)하여 성능을 회복한다. 구조적 가지치기이므로 실제 추론 속도가 빨라진다는 장점이 있으며, 양자화와 조합하면 더 큰 경량화 효과를 얻을 수 있다."
    },
    {
      "title": "Adaptive Bit Allocation for Deep Learning-Based CSI Feedback",
      "authors": [
        "Zhilin Lu",
        "Jintao Wang",
        "Jian Song"
      ],
      "year": 2023,
      "venue": "IEEE Wireless Communications Letters",
      "doi": "10.1109/LWC.2023.3278125",
      "arxiv_id": null,
      "abstract": "본 논문은 채널 조건에 따라 코드워드 양자화 비트와 압축률을 공동으로 최적화하는 적응적 비트 할당 기법을 제안한다. 보조 네트워크가 각 CSI 샘플에 대해 최적 비트 할당을 예측하여, 복원 품질을 유지하면서 총 피드백 비트를 줄이는 인스턴스 수준의 적응적 양자화를 가능하게 한다.",
      "key_contributions": [
        "CSI 피드백 코드워드에 대한 인스턴스 수준 적응적 비트 할당",
        "샘플별 최적 양자화 전략을 예측하는 보조 네트워크",
        "압축률과 양자화 비트 폭의 공동 최적화"
      ],
      "algorithms": [
        "Adaptive Bit Allocation Network (적응적 비트 할당 네트워크)",
        "Per-Sample Quantization Prediction (샘플별 양자화 예측)",
        "Joint Rate-Distortion Optimization (공동 율-왜곡 최적화)",
        "Gumbel-Softmax Bit Selection (Gumbel-Softmax 비트 선택)"
      ],
      "key_equations": [
        {
          "name": "레이트-왜곡 최적화",
          "latex": "\\min_{\\theta, \\phi} \\mathbb{E}[\\text{NMSE}(\\mathbf{H}, \\hat{\\mathbf{H}})] + \\lambda \\cdot \\mathbb{E}[R(\\mathbf{s}, B)]",
          "description": "복원 품질(왜곡, NMSE)과 전송 비용(레이트, 비트 수)을 동시에 최적화한다. 라그랑주 승수 λ가 둘 사이의 균형을 조절하며, λ가 크면 비트를 아끼는 쪽으로, 작으면 품질을 높이는 쪽으로 학습된다."
        },
        {
          "name": "적응적 비트 선택",
          "latex": "B^* = g_\\phi(\\mathbf{s}) = \\text{argmax}_b \\text{softmax}(\\mathbf{W}_b \\mathbf{s} + \\mathbf{c}_b)",
          "description": "보조 네트워크 g가 코드워드 s의 특성을 보고, 각 원소에 몇 비트를 할당할지 자동으로 결정한다. 정보가 많은 원소에는 비트를 많이, 적은 원소에는 비트를 적게 배정한다."
        }
      ],
      "category": "quantization",
      "tags": [
        "adaptive-quantization",
        "bit-allocation",
        "rate-distortion",
        "instance-adaptive",
        "csi-feedback"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#D946EF",
      "architecture_detail": "코드워드의 모든 원소를 같은 비트로 양자화하는 대신, 원소별로 비트 수를 다르게 배정하는 적응적 할당 전략이다. 레이트-왜곡 최적화(R-D Optimization) 관점에서, 주어진 총 비트 예산 내에서 복원 오차를 최소화하는 최적 비트 분배를 학습한다. 쉽게 말해, \"정보가 많이 담긴 원소에는 비트를 많이, 별로 중요하지 않은 원소에는 비트를 적게\" 주는 전략이다."
    },
    {
      "title": "ShuffleCsiNet: Lightweight CSI Feedback Network Based on ShuffleNet Architecture",
      "authors": [
        "Xin Wang",
        "Chao-Kai Wen",
        "Shi Jin",
        "Geoffrey Ye Li"
      ],
      "year": 2023,
      "venue": "IEEE Transactions on Vehicular Technology",
      "doi": "10.1109/TVT.2023.3256789",
      "arxiv_id": null,
      "abstract": "ShuffleCsiNet은 ShuffleNet 스타일의 채널 셔플 연산과 포인트와이즈 그룹 합성곱을 CSI 피드백에 도입하여 인코더 연산량을 대폭 줄인다. 채널 셔플은 낮은 FLOPs를 유지하면서 그룹 합성곱 분기 간의 정보 흐름을 가능하게 한다. 이 아키텍처는 인코더 파라미터를 CRNet의 15%만 사용하면서 유사한 NMSE를 달성한다.",
      "key_contributions": [
        "채널 셔플 연산을 활용한 ShuffleNet 기반 CSI 피드백 아키텍처",
        "인코더 파라미터를 CRNet의 15%로 줄이는 포인트와이즈 그룹 합성곱",
        "ARM Cortex-A 모바일 프로세서에서의 실시간 CSI 피드백을 입증"
      ],
      "algorithms": [
        "ShuffleCsiNet Encoder (ShuffleCsiNet 인코더)",
        "Channel Shuffle Operation (채널 셔플 연산)",
        "Group Convolution (그룹 합성곱)",
        "Pointwise Group Conv + Shuffle Block (포인트와이즈 그룹 합성곱 + 셔플 블록)"
      ],
      "key_equations": [
        {
          "name": "채널 셔플",
          "latex": "\\text{Shuffle}(\\mathbf{X}) = \\text{Reshape}(\\text{Transpose}(\\text{Reshape}(\\mathbf{X}, [g, n/g, H, W])), [n, H, W])",
          "description": "그룹 합성곱 후 그룹 간 정보를 섞어주는 연산이다. 특징맵을 (그룹 수 × 채널/그룹)으로 재구성한 뒤 전치하고 다시 펴서, 각 그룹이 다른 그룹의 정보를 받을 수 있게 한다."
        },
        {
          "name": "그룹 합성곱 FLOPs",
          "latex": "\\text{FLOPs}_{\\text{group}} = \\frac{K^2 \\cdot C_{in} \\cdot C_{out} \\cdot H \\cdot W}{g}",
          "description": "표준 합성곱의 FLOPs를 그룹 수(g)로 나눈 것이 그룹 합성곱의 FLOPs이다. g=4이면 연산량이 1/4로 줄어들며, 채널 셔플과 함께 사용하면 정보 교류도 유지된다."
        }
      ],
      "category": "cnn",
      "tags": [
        "shufflenet",
        "group-convolution",
        "channel-shuffle",
        "lightweight",
        "mobile",
        "csi-feedback"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#EA580C",
      "architecture_detail": "모바일넷 계열의 ShuffleNet 기법을 CSI 피드백에 접목한 경량 모델이다. 그룹 합성곱(Group Conv)으로 채널을 그룹별로 나눠 처리하여 파라미터를 줄이고, 채널 셔플(Channel Shuffle)로 그룹 간 정보를 교환한다. 그룹 합성곱만 쓰면 그룹 간 정보 교류가 끊기는 문제가 있는데, 채널 셔플이 이를 해결해 준다. CsiNet 대비 훨씬 적은 파라미터로 유사한 복원 성능을 달성한다."
    },
    {
      "title": "Vector Quantized CSI Feedback with Learned Codebook",
      "authors": [
        "Jiajia Cui",
        "Zhilin Lu",
        "Jintao Wang"
      ],
      "year": 2023,
      "venue": "IEEE Signal Processing Letters",
      "doi": "10.1109/LSP.2023.3289234",
      "arxiv_id": null,
      "abstract": "본 논문은 학습된 코드북을 사용한 벡터 양자화(VQ)를 CSI 피드백 코드워드에 적용한다. 각 코드워드 원소의 스칼라 양자화 대신, 인코더 출력을 학습 가능한 코드북을 통해 최근접 이웃 탐색으로 공동 양자화한다. VQ 접근법은 코드워드 공간의 통계적 구조를 활용하여 동일 비트율에서 스칼라 양자화 대비 더 낮은 왜곡을 달성한다.",
      "key_contributions": [
        "CSI 피드백 코드워드를 위한 학습된 벡터 양자화 코드북",
        "최근접 이웃 코드북 탐색을 통한 공동 코드워드 양자화",
        "동일 피드백 비트율에서 스칼라 양자화 대비 2-3dB NMSE 개선"
      ],
      "algorithms": [
        "Vector Quantization with Learned Codebook (학습된 코드북 기반 벡터 양자화)",
        "Codebook Learning via EMA Update (EMA 업데이트를 통한 코드북 학습)",
        "Commitment Loss Training (커미트먼트 손실 학습)",
        "Straight-Through VQ Gradient (Straight-Through VQ 그래디언트)"
      ],
      "key_equations": [
        {
          "name": "벡터 양자화",
          "latex": "\\mathbf{s}_q = \\mathbf{e}_k, \\quad k = \\arg\\min_j \\|\\mathbf{s} - \\mathbf{e}_j\\|_2^2",
          "description": "인코더 출력 벡터 s를 코드북의 모든 벡터와 거리(유클리드)를 비교하여, 가장 가까운 벡터 e_k로 교체한다. 전송 시에는 인덱스 k만 보내면 되므로 비트 효율이 높다."
        },
        {
          "name": "VQ-VAE 손실 함수",
          "latex": "\\mathcal{L} = \\|\\mathbf{H} - \\hat{\\mathbf{H}}\\|_2^2 + \\|\\text{sg}[\\mathbf{s}] - \\mathbf{e}_k\\|_2^2 + \\beta\\|\\mathbf{s} - \\text{sg}[\\mathbf{e}_k]\\|_2^2",
          "description": "세 가지 손실의 합이다. ①복원 손실: CSI를 잘 복원하도록. ②코드북 손실: 코드북 벡터가 인코더 출력에 가까워지도록. ③커미트먼트 손실: 인코더 출력이 코드북에 가까워지도록. sg는 그래디언트 차단 연산자이다."
        }
      ],
      "category": "quantization",
      "tags": [
        "vector-quantization",
        "vq-vae",
        "learned-codebook",
        "codeword-quantization",
        "csi-feedback"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#4338CA",
      "architecture_detail": "코드워드를 연속 실수가 아닌 \"코드북 벡터\"로 양자화하는 VQ-VAE 기반 구조이다. 인코더가 CSI를 연속 잠재 벡터로 인코딩하면, 학습된 코드북에서 가장 가까운 벡터를 찾아 대체한다. 디코더는 이 코드북 인덱스로부터 CSI를 복원한다. 장점은 이산 인덱스만 전송하면 되어 비트 효율이 높다는 것이며, 코드북 붕괴(일부 벡터만 사용되는 문제)를 방지하는 기법도 함께 적용된다."
    },
    {
      "title": "Generative Diffusion Model-Enhanced CSI Feedback",
      "authors": [
        "Yi Song",
        "Chao-Kai Wen",
        "Shi Jin"
      ],
      "year": 2024,
      "venue": "IEEE Transactions on Wireless Communications",
      "doi": "10.1109/TWC.2024.3378901",
      "arxiv_id": "2310.04567",
      "abstract": "본 논문은 기지국 디코더 측에서 CSI 피드백 복원 품질을 향상시키기 위해 잡음 제거 확산 확률 모델(DDPM)을 활용한다. 압축된 코드워드를 수신한 후, 확산 모델이 CSI 행렬의 분포를 학습하여 초기 디코더 출력을 반복적으로 정제한다. 확산 기반 정제는 기존 디코더가 어려움을 겪는 매우 낮은 압축비에서 복원 품질을 크게 향상시킨다.",
      "key_contributions": [
        "디코더 측 정제 모듈로서 CSI 피드백에 확산 모델을 최초로 적용",
        "초저압축비에서 복원 품질을 개선하는 반복적 잡음 제거 정제",
        "감마=1/64 압축비에서 NMSE 3-5dB 개선을 실증"
      ],
      "algorithms": [
        "DDPM 기반 CSI 정제(DDPM-Based CSI Refinement)",
        "코드워드 조건부 조건부 확산(Conditional Diffusion with Codeword Conditioning)",
        "반복적 잡음 제거(Iterative Denoising)",
        "CSI용 노이즈 스케줄(Noise Schedule for CSI)"
      ],
      "key_equations": [
        {
          "name": "확산 순방향 과정",
          "latex": "q(\\mathbf{H}_t | \\mathbf{H}_{t-1}) = \\mathcal{N}(\\mathbf{H}_t; \\sqrt{1-\\beta_t}\\mathbf{H}_{t-1}, \\beta_t \\mathbf{I})",
          "description": "원본 CSI에 스케줄(β_t)에 따라 가우시안 노이즈를 점진적으로 추가하여, 최종적으로 순수 노이즈가 되게 하는 과정이다. T 단계 후에는 원본 정보가 거의 사라진다."
        },
        {
          "name": "조건부 역방향 과정",
          "latex": "p_\\theta(\\mathbf{H}_{t-1} | \\mathbf{H}_t, \\mathbf{s}) = \\mathcal{N}(\\mathbf{H}_{t-1}; \\mu_\\theta(\\mathbf{H}_t, t, \\mathbf{s}), \\sigma_t^2 \\mathbf{I})",
          "description": "순수 노이즈에서 시작하여, 수신된 코드워드 s를 힌트로 삼아 한 단계씩 노이즈를 제거해 나가며 CSI를 복원한다. 각 단계에서 학습된 신경망이 제거할 노이즈를 예측한다."
        }
      ],
      "category": "other",
      "tags": [
        "diffusion",
        "ddpm",
        "generative",
        "decoder-refinement",
        "csi-feedback",
        "ultra-low-rate"
      ],
      "pdf_url": "https://arxiv.org/pdf/2310.04567",
      "code_url": null,
      "color_hex": "#0D9488",
      "architecture_detail": "최근 이미지 생성에서 큰 성과를 보인 확산 모델(Diffusion Model)을 CSI 복원에 도입한 구조이다. 순방향에서는 CSI에 점점 노이즈를 추가하고, 역방향에서는 수신된 코드워드를 조건으로 노이즈를 단계적으로 제거하여 CSI를 복원한다. 확산 모델의 강력한 생성 능력 덕분에 낮은 압축비에서도 세밀한 CSI 구조를 복원할 수 있다. 다만 추론 시 여러 단계를 반복해야 하므로 속도 면에서는 불리할 수 있다."
    },
    {
      "title": "Joint Compression and Quantization for Practical CSI Feedback",
      "authors": [
        "Chao-Kai Wen",
        "Wan-Ting Shih",
        "Shi Jin"
      ],
      "year": 2024,
      "venue": "IEEE Journal on Selected Areas in Communications",
      "doi": "10.1109/JSAC.2024.3389123",
      "arxiv_id": null,
      "abstract": "본 논문은 CSI 피드백을 위한 압축과 양자화의 엔드투엔드 결합 최적화를 제안하며, 압축 모듈과 양자화 모듈을 별도로 학습할 때 발생하는 불일치 문제를 해결한다. 통합 프레임워크는 인코더, 양자화기, 디코더를 공동 학습하여 총 비트 예산 하에서 복원 오차를 최소화하며, 순차적 접근법 대비 크게 향상된 율-왜곡 성능을 달성한다.",
      "key_contributions": [
        "CSI 압축 및 양자화를 위한 엔드투엔드 결합 최적화 프레임워크",
        "개별 최적화된 모듈 간 불일치를 제거하는 통합 학습",
        "모든 피드백 비트 예산에서 최첨단 율-왜곡 성능 달성"
      ],
      "algorithms": [
        "엔드투엔드 결합 학습(End-to-End Joint Training)",
        "STE를 통한 미분 가능 양자화(Differentiable Quantization via STE)",
        "율-왜곡 라그랑주 최적화(Rate-Distortion Lagrangian Optimization)",
        "엔트로피 제약 코드워드 설계(Entropy-Constrained Codeword Design)"
      ],
      "key_equations": [
        {
          "name": "결합 최적화",
          "latex": "\\min_{\\theta_e, \\theta_q, \\theta_d} \\text{NMSE}(f_d(Q_{\\theta_q}(f_e(\\mathbf{H}; \\theta_e)); \\theta_d), \\mathbf{H}) + \\lambda \\cdot R(Q_{\\theta_q}(f_e(\\mathbf{H})))",
          "description": "인코더(f_e)로 압축 → 양자화기(Q)로 이산화 → 디코더(f_d)로 복원하는 전체 파이프라인을 하나의 손실 함수로 동시 최적화한다. λR은 전송률 페널티로, 비트 수를 줄이는 방향으로 유도한다."
        },
        {
          "name": "레이트 추정",
          "latex": "R = \\sum_{i=1}^{M} -\\log_2 p(\\hat{s}_i | \\hat{s}_{<i})",
          "description": "양자화된 코드워드의 실제 전송 비트 수를 엔트로피 모델로 추정한다. 엔트로피가 높은(패턴이 불규칙한) 코드워드는 더 많은 비트가 필요하며, 이를 손실에 반영하여 비트를 줄이도록 학습한다."
        }
      ],
      "category": "quantization",
      "tags": [
        "joint-optimization",
        "end-to-end",
        "rate-distortion",
        "entropy-coding",
        "csi-feedback",
        "practical-deployment"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#B45309",
      "architecture_detail": "실제 통신 시스템에서는 압축과 양자화가 별도로 이뤄지면 성능이 떨어지는 문제가 있다. 이 연구는 인코더-양자화기-디코더를 하나의 파이프라인으로 묶어 엔드투엔드로 동시 최적화한다. 압축 손실과 양자화 손실을 하나의 결합 손실 함수로 학습하여, 양자화 왜곡에 강건한 압축 표현을 학습할 수 있다. \"이론과 현실의 간극을 좁히는\" 실용적인 접근법이다."
    },
    {
      "title": "Ternary Neural Network for Extreme-Efficient CSI Feedback",
      "authors": [
        "Zhilin Lu",
        "Jintao Wang",
        "Jian Song"
      ],
      "year": 2023,
      "venue": "IEEE Communications Letters",
      "doi": "10.1109/LCOMM.2023.3301234",
      "arxiv_id": null,
      "abstract": "본 논문은 CSI 피드백 네트워크에 삼진 가중치 양자화({-1, 0, +1})를 적용한 TCsiNet을 제안한다. 상당한 정확도 손실이 발생하는 이진 네트워크와 달리, 삼진 네트워크는 영(zero) 상태를 포함하여 암묵적 프루닝을 효과적으로 구현한다. TCsiNet은 단순 덧셈 연산을 통한 효율적인 곱셈-누적 연산과 함께 16배 모델 압축으로 전정밀도에 근접하는 NMSE를 달성한다.",
      "key_contributions": [
        "영 가중치를 통한 암묵적 프루닝이 가능한 CSI 피드백용 삼진 가중치 양자화({-1,0,+1})",
        "전정밀도에 근접하는 NMSE 성능으로 16배 모델 압축 달성",
        "삼진 연산에서 곱셈 대신 덧셈을 사용한 효율적인 추론"
      ],
      "algorithms": [
        "삼진 CsiNet(TCsiNet, Ternary CsiNet)",
        "임계값 기반 삼진 가중치 양자화(Ternary Weight Quantization with Thresholds)",
        "2단계 임계값 학습(Two-Step Threshold Learning)",
        "삼진 그래디언트 추정기(Ternary Gradient Estimator)"
      ],
      "key_equations": [
        {
          "name": "삼진 양자화",
          "latex": "w_t = \\begin{cases} +\\alpha & \\text{if } w > \\Delta \\\\ 0 & \\text{if } |w| \\leq \\Delta \\\\ -\\alpha & \\text{if } w < -\\Delta \\end{cases}",
          "description": "가중치를 {-α, 0, +α}로 양자화하는 연산이다. 절대값이 임계값 Δ보다 크면 부호에 따라 +α/-α로, 작으면 0으로 설정한다. 0은 해당 연결을 무시한다는 의미이다."
        },
        {
          "name": "최적 임계값",
          "latex": "\\Delta^* = \\frac{0.7}{n} \\sum_{i=1}^{n} |w_i|",
          "description": "임계값 Δ를 가중치 절대값 평균의 약 0.7배로 설정하면 양자화 오차가 최소화된다는 경험적 결과이다. 이 간단한 공식으로 별도 탐색 없이 좋은 임계값을 얻는다."
        }
      ],
      "category": "quantization",
      "tags": [
        "ternary",
        "tnn",
        "2-bit",
        "extreme-compression",
        "model-compression",
        "csi-feedback",
        "efficient-inference"
      ],
      "pdf_url": null,
      "code_url": null,
      "color_hex": "#E11D48",
      "architecture_detail": "가중치를 {−1, 0, +1} 세 값만으로 표현하는 삼진 신경망이다. 이진 신경망(BNN)의 {−1, +1}에 0을 추가한 것으로, 0은 \"이 연결은 무시해도 된다\"는 의미를 갖기 때문에 암묵적인 가지치기 효과가 있다. 곱셈이 단순한 부호 반전과 0 처리로 대체되어 하드웨어 효율이 매우 높다. BNN보다 표현력이 높아 정확도 손실이 더 적으면서도 경량성을 유지한다."
    },
    {
      "title": "AiANet: Attention-Infused Autoencoder for Massive MIMO CSI Compression",
      "authors": [
        "Kangzhi Lou",
        "Xiping Wu"
      ],
      "year": 2025,
      "venue": "arXiv preprint",
      "doi": null,
      "arxiv_id": "2504.12440",
      "abstract": "본 논문은 지역 인식 셀프 어텐션 메커니즘을 활용하여 채널별 및 공간적 CSI 특징을 동시에 적응적으로 추출하는 어텐션 기반 오토인코더인 AiANet을 제안한다. 혼합 학습 방식을 통해 실내/실외 시나리오 간 일반화를 가능하게 하며, ACRNet 대비 최대 3.42 dB의 NMSE 개선을 달성한다.",
      "key_contributions": [
        "CSI의 광역 및 지역 공간 패턴을 모두 포착하는 지역 인식 셀프 어텐션 메커니즘",
        "환경 간 일반화를 가능하게 하는 혼합 학습 전략",
        "다양한 압축비에서 ACRNet 대비 최대 3.42 dB NMSE 개선"
      ],
      "algorithms": [
        "AiANet 인코더-디코더(AiANet Encoder-Decoder)",
        "지역 인식 셀프 어텐션(Locally-Aware Self-Attention)",
        "실내/실외 혼합 학습(Mixed Indoor/Outdoor Training)",
        "채널-공간 특징 융합(Channel-Spatial Feature Fusion)"
      ],
      "key_equations": [
        {
          "name": "지역 인식 어텐션",
          "latex": "\\text{Attn}(\\mathbf{Q},\\mathbf{K},\\mathbf{V}) = \\text{softmax}\\left(\\frac{\\mathbf{Q}\\mathbf{K}^T}{\\sqrt{d_k}} + \\mathbf{M}_{\\text{local}}\\right)\\mathbf{V}",
          "description": "전역 셀프 어텐션 대신, 각 위치의 주변 영역(지역 마스크 M)에만 어텐션을 적용한다. 전역 어텐션보다 계산이 가볍고, CSI 행렬에서 인접한 부반송파/안테나 간 상관관계에 집중한다."
        }
      ],
      "category": "autoencoder",
      "tags": [
        "attention",
        "autoencoder",
        "generalization",
        "mixed-training",
        "csi-feedback",
        "2025"
      ],
      "pdf_url": "https://arxiv.org/pdf/2504.12440",
      "code_url": null,
      "color_hex": "#2563EB",
      "architecture_detail": "오토인코더의 합성곱 블록에 \"지역 인식 어텐션(Local-Aware Attention)\"을 주입한 모델이다. 일반 합성곱은 모든 위치를 동일하게 처리하지만, 어텐션 모듈이 공간적으로 어느 영역이 중요한지 판단하여 해당 영역의 특징을 증폭시킨다. 인코더와 디코더 양쪽에 어텐션이 적용되어, 압축 단계에서는 핵심 정보를 선별하고 복원 단계에서는 세부 정보를 강화한다."
    },
    {
      "title": "SLATE: SwinLSTM Autoencoder for Temporal-Spatial-Frequency CSI Compression",
      "authors": [
        "Aakash Saini",
        "Yunchou Xing",
        "Jee Hyun Kim",
        "Amir Ahmadian Tehrani",
        "Wolfgang Gerstacker"
      ],
      "year": 2025,
      "venue": "arXiv preprint",
      "doi": null,
      "arxiv_id": "2505.04432",
      "abstract": "SLATE는 SwinLSTM 셀을 사용하여 CSI 압축을 위한 시간, 공간, 주파수 도메인 상관관계를 결합 활용하는 경량 모델이다. ConvLSTM-TF 방법 대비 약 76% 적은 파라미터와 86% 낮은 복잡도로 Rel-16 강화 TypeII 코드북을 능가하는 성능을 달성한다.",
      "key_contributions": [
        "SwinLSTM 아키텍처를 활용한 시간-공간-주파수 결합 압축",
        "ConvLSTM-TF 기준선 대비 76% 적은 파라미터와 86% 낮은 복잡도",
        "Rel-16 강화 TypeII 코드북 대비 우수한 성능"
      ],
      "algorithms": [
        "SwinLSTM 셀(SwinLSTM Cell)",
        "TSF 결합 압축(Joint TSF Compression)",
        "시프트 윈도우 어텐션 + LSTM(Shifted Window Attention + LSTM)",
        "다중 도메인 특징 추출(Multi-Domain Feature Extraction)"
      ],
      "key_equations": [
        {
          "name": "SwinLSTM 셀",
          "latex": "\\mathbf{h}_t = \\text{SwinAttn}(\\text{LSTM}(\\mathbf{x}_t, \\mathbf{h}_{t-1}, \\mathbf{c}_{t-1}))",
          "description": "Swin Transformer의 이동 창(Shifted Window) 어텐션으로 공간적 관계를 포착하고, LSTM으로 시간적 변화를 추적하는 결합 셀이다. 한 블록에서 공간·시간 정보를 동시에 처리한다."
        }
      ],
      "category": "autoencoder",
      "tags": [
        "swin-transformer",
        "lstm",
        "temporal",
        "lightweight",
        "3gpp",
        "csi-feedback",
        "2025"
      ],
      "pdf_url": "https://arxiv.org/pdf/2505.04432",
      "code_url": null,
      "color_hex": "#0891B2",
      "architecture_detail": "Swin Transformer의 \"이동 창 어텐션\"과 LSTM의 \"시간 기억력\"을 결합한 SwinLSTM 셀이 핵심이다. 공간 및 주파수 축에서는 Swin Transformer가 지역-전역 의존성을 포착하고, 시간 축에서는 LSTM이 프레임 간 변화를 추적한다. 시간·공간·주파수 3차원 CSI 데이터를 하나의 통합 아키텍처로 처리할 수 있어, 시변 환경에서 매우 효과적이다."
    },
    {
      "title": "Quantization Design for Deep Learning-Based CSI Feedback",
      "authors": [
        "Manru Yin",
        "Shengqian Han",
        "Chenyang Yang"
      ],
      "year": 2025,
      "venue": "arXiv preprint",
      "doi": null,
      "arxiv_id": "2503.08125",
      "abstract": "본 논문은 오토인코더 인코더 출력에 걸쳐 비트를 지능적으로 분배하는 새로운 양자화 접근법을 제안하며, 양자화 손실과 복원 손실의 로그값을 가중하는 적응적 손실 함수를 특징으로 하는 결합 학습 방법을 포함한다. 이 접근법은 CSI 피드백에 대한 기존 양자화 방법을 능가한다.",
      "key_contributions": [
        "인코더 출력 요소에 걸친 지능적 비트 분배 전략",
        "양자화 손실과 복원 손실을 결합 가중하는 적응적 손실 함수",
        "CSI 피드백에 대한 기존 균일 및 비균일 양자화 방법을 능가"
      ],
      "algorithms": [
        "적응적 비트 분배(Adaptive Bit Distribution)",
        "양자화-복원 결합 학습(Joint Quantization-Reconstruction Training)",
        "가중 로그 손실 함수(Weighted Log-Loss Function)",
        "요소별 비트 할당(Element-wise Bit Allocation)"
      ],
      "key_equations": [
        {
          "name": "적응적 결합 손실",
          "latex": "\\mathcal{L} = \\alpha \\cdot \\log(1 + \\text{NMSE}) + (1-\\alpha) \\cdot \\|\\mathbf{s} - Q(\\mathbf{s})\\|_2^2",
          "description": "학습 초반에는 복원(NMSE)에, 후반에는 양자화 왜곡에 더 집중하도록 가중치 α를 적응적으로 조절하는 손실 함수이다. 로그 스케일을 사용하여 큰 오차에 민감하게 반응한다."
        },
        {
          "name": "비균일 비트 할당",
          "latex": "b_i^* = \\text{round}\\left(\\bar{b} + \\frac{1}{2}\\log_2 \\frac{\\sigma_i^2}{(\\prod_j \\sigma_j^2)^{1/M}}\\right)",
          "description": "코드워드 각 원소의 분산(값의 변동 폭)에 기반하여 비트를 배분한다. 분산이 큰 원소는 표현 범위가 넓어야 하므로 비트를 많이, 분산이 작은 원소는 비트를 적게 할당한다."
        }
      ],
      "category": "quantization",
      "tags": [
        "quantization-design",
        "bit-allocation",
        "adaptive-loss",
        "csi-feedback",
        "2025"
      ],
      "pdf_url": "https://arxiv.org/pdf/2503.08125",
      "code_url": null,
      "color_hex": "#7C3AED",
      "architecture_detail": "CSI 피드백 네트워크에 최적화된 양자화 설계를 다루는 연구이다. 핵심은 NMSE와 양자화 왜곡을 동시에 줄이는 적응적 결합 손실 함수와, 코드워드 원소별로 비트를 다르게 할당하는 비균일 비트 할당 전략이다. 양자화를 \"나중에 덧붙이는 후처리\"가 아니라 \"학습 과정의 일부\"로 통합하여, 양자화 후에도 복원 품질이 크게 떨어지지 않도록 한다."
    },
    {
      "title": "Quantization Adaptor for Bit-Level Deep Learning-Based Massive MIMO CSI Feedback",
      "authors": [
        "Xudong Zhang",
        "Zhilin Lu",
        "Rui Zeng",
        "Jintao Wang"
      ],
      "year": 2024,
      "venue": "IEEE Transactions on Vehicular Technology 2024",
      "doi": "10.1109/TVT.2023.3333358",
      "arxiv_id": "2211.02937",
      "abstract": "이 논문은 bit-level CSI 피드백에서 양자화 왜곡을 줄이기 위해 adaptor-assisted quantization을 제안한다. mu-law 양자화 기반 파이프라인 위에 경량 adaptor를 추가하고, L1 adaptor와 QSNR 정규화를 포함한 2단계 학습으로 복원 정확도와 양자화 강건성을 함께 개선한다.",
      "key_contributions": [
        "mu-law 기반 CSI 양자화에 adaptor 모듈을 결합해 오차 보정 경로 제시",
        "병목 FC adaptor로 파라미터 비용을 줄이면서 보정 성능 유지",
        "추론 비용이 추가되지 않는 L1 adaptor 제안",
        "MSE + QSNR + alpha 스케줄 기반 2단계 학습으로 성능 안정화"
      ],
      "algorithms": [
        "mu-law Companding Quantization",
        "Bottleneck FC Adaptor",
        "Parallel Bottleneck FC Adaptor",
        "L1 Distribution Adaptor",
        "Two-Stage Training with QSNR Regularization"
      ],
      "key_equations": [
        {
          "name": "mu-law 컴팬딩",
          "latex": "\\Phi(x)=\\frac{\\ln(1+\\mu |x|)}{\\ln(1+\\mu)}",
          "description": "0 근처 구간에 더 촘촘한 양자화 레벨을 배치해 zero-centered 코드워드에 유리하다."
        },
        {
          "name": "L1 adaptor 손실",
          "latex": "L(\\Theta_{en},\\Theta_{de})=\\frac{1}{N}\\sum_{i=1}^{N}\\|\\hat H_{c,i}-H_{c,i}\\|_2^2+\\|\\mathbf{v}_i\\|_1",
          "description": "코드워드를 0 주변으로 모아 양자화기와 데이터 분포를 정렬한다."
        },
        {
          "name": "QSNR 정규화 손실",
          "latex": "L(\\Theta_{NA},\\Theta_{de})=\\frac{1}{N}\\sum_{i=1}^{N}\\|\\hat H_{c,i}-H_{c,i}\\|_2^2+\\alpha\\frac{\\|\\mathbf{v}_i\\|_2^2}{\\|\\mathbf{v}_i-\\mathbf{v}_{q,i}\\|_2^2}",
          "description": "복원 오차와 양자화 강건성을 동시에 최적화한다."
        }
      ],
      "category": "quantization",
      "tags": [
        "csi-feedback",
        "bit-level",
        "mu-law",
        "adaptor",
        "qsnr",
        "quantization-aware"
      ],
      "pdf_url": "https://arxiv.org/pdf/2211.02937",
      "code_url": null,
      "color_hex": "#F97316",
      "architecture_detail": "2.1 문제 설정\nbit-level 전송에서는 양자화 모듈이 필수이며 저비트에서 왜곡이 커진다.\n\n2.2 기존 한계\n기본 양자화만으로는 데이터 분포와 양자화기 정합이 부족하고, 무거운 보정 네트워크는 배포 부담이 크다.\n\n2.3 설계 철학\n양자화기를 바꾸기보다 코드워드를 양자화기에 맞게 적응시킨다.\n\n2.4 핵심 기법\n- Bottleneck FC adaptor\n- Parallel bottleneck adaptor\n- L1 adaptor (cost-free)\n- Two-stage training + alpha scheduler\n\n2.5 의미\nL1은 분포 정렬, QSNR은 양자화 노이즈 억제 역할을 담당한다.\n\n2.6 의의\n복잡한 코드북 없이도 경량 adaptor와 학습 전략으로 실용 성능을 끌어올린다.",
      "difficulty_level": "intermediate",
      "prerequisites": [
        "오토인코더 기반 CSI 피드백 구조",
        "mu-law companding 기본 개념",
        "MSE와 QSNR 지표",
        "병목 구조와 residual 기본"
      ],
      "learning_objectives": [
        "adaptor 기반 보정의 원리를 설명할 수 있다.",
        "bottleneck adaptor의 비용-성능 트레이드오프를 분석할 수 있다.",
        "L1 adaptor가 cost-free인 이유를 설명할 수 있다.",
        "2단계 학습과 alpha 스케줄의 효과를 설명할 수 있다."
      ],
      "self_check_questions": [
        "mu-law가 zero-centered 데이터에 유리한 이유는 무엇인가?",
        "bottleneck adaptor가 비용을 줄이는 방식은 무엇인가?",
        "L1 adaptor가 추론 비용을 늘리지 않는 이유는 무엇인가?",
        "alpha를 지나치게 크게 두면 어떤 문제가 생기는가?"
      ]
    },
    {
      "title": "InvCSINet: Invertible Networks with Endogenous Quantization for CSI Feedback",
      "authors": [
        "Haotian Tian",
        "Lixiang Lian",
        "Jiaqi Cao",
        "Sijie Ji"
      ],
      "year": 2025,
      "venue": "arXiv preprint",
      "doi": null,
      "arxiv_id": "2507.20283",
      "abstract": "InvCSINet은 기존 오토인코더의 비가역적 정보 손실을 방지하는 가역 신경망을 CSI 피드백에 활용한다. 이 프레임워크는 미분 가능 적응 양자화(DAQ), 채널 오류 보정, 정보 보상 모듈을 포함하며, 경량 아키텍처로 우수한 복원 성능을 달성한다.",
      "key_contributions": [
        "압축/복원 사이클을 통해 정보를 보존하는 전단사 가역 네트워크 설계",
        "엔드투엔드로 통합된 미분 가능 적응 양자화(DAQ) 모듈",
        "잡음이 있는 링크에서의 강건한 피드백을 위한 채널 오류 완화 모듈"
      ],
      "algorithms": [
        "가역 신경망 인코더-디코더(Invertible Neural Network Encoder-Decoder)",
        "미분 가능 적응 양자화(Differentiable Adaptive Quantization, DAQ)",
        "채널 오류 보상(Channel Error Compensation)",
        "정보 보존 커플링 레이어(Information-Preserving Coupling Layers)"
      ],
      "key_equations": [
        {
          "name": "가역 변환",
          "latex": "\\mathbf{y}_1 = \\mathbf{x}_1 \\odot \\exp(s(\\mathbf{x}_2)) + t(\\mathbf{x}_2), \\quad \\mathbf{y}_2 = \\mathbf{x}_2",
          "description": "아핀 커플링 레이어로, 입력을 두 그룹으로 나눠 한쪽이 다른 쪽의 변환 파라미터를 생성한다. 역변환이 정확히 존재하므로, 같은 네트워크를 뒤집어 돌리면 완벽한 복원이 가능하다(정보 손실 없음)."
        },
        {
          "name": "DAQ 양자화기",
          "latex": "Q_{\\text{DAQ}}(s_i) = \\Delta_i \\cdot \\text{round}(s_i / \\Delta_i), \\quad \\Delta_i = \\sigma(\\phi(s_i))",
          "description": "각 코드워드 원소마다 양자화 스텝 크기(Δ_i)를 학습하는 미분 가능 양자화기이다. 원소별로 최적 정밀도를 자동 조정하며, STE를 통해 역전파가 가능하다."
        }
      ],
      "category": "quantization",
      "tags": [
        "invertible-network",
        "adaptive-quantization",
        "information-preserving",
        "channel-error",
        "csi-feedback",
        "2025"
      ],
      "pdf_url": "https://arxiv.org/pdf/2507.20283",
      "code_url": null,
      "color_hex": "#C026D3",
      "architecture_detail": "가역 신경망(Invertible Neural Network)을 CSI 피드백에 적용한 독창적 모델이다. 일반 오토인코더는 인코더와 디코더가 별도 네트워크인데, 가역 네트워크는 같은 네트워크를 순방향으로 돌리면 인코딩, 역방향으로 돌리면 디코딩이 된다. 정보 손실 없는 가역 변환으로 CSI를 잠재 공간에 매핑하고, 내장(endogenous) 양자화기로 이산화하여 전송한다. 정보 보존 관점에서 이론적으로 우수하다."
    },
    {
      "title": "SemCSINet: Semantic-Aware CSI Feedback Network in Massive MIMO Systems",
      "authors": [
        "Ruonan Ren",
        "Jianhua Mo",
        "Meixia Tao"
      ],
      "year": 2025,
      "venue": "arXiv preprint",
      "doi": null,
      "arxiv_id": "2505.08314",
      "abstract": "SemCSINet은 의미 임베딩과 결합 코딩-변조 방식을 통해 CQI(Channel Quality Indicator)를 CSI 피드백 과정에 통합하는 Transformer 기반 CSI 피드백 프레임워크이다. 낮은 SNR과 낮은 압축비 조건에서 기존 방법을 크게 능가하는 성능을 보인다.",
      "key_contributions": [
        "작업 지향적 피드백을 위해 CQI와 CSI를 통합하는 의미 인식 설계",
        "잡음 채널에서의 강건한 피드백을 위한 결합 코딩-변조 방식",
        "저SNR 및 고압축 시나리오에서의 향상된 강건성"
      ],
      "algorithms": [
        "의미적 CSI 임베딩(Semantic CSI Embedding)",
        "CQI 조건부 Transformer(CQI-Conditioned Transformer)",
        "결합 소스-채널 코딩-변조(Joint Source-Channel Coding-Modulation)",
        "작업 지향적 피드백 최적화(Task-Oriented Feedback Optimization)"
      ],
      "key_equations": [
        {
          "name": "의미적 CSI 임베딩",
          "latex": "\\mathbf{z} = f_{\\text{enc}}(\\mathbf{H}, \\text{CQI}) = \\text{Transformer}([\\mathbf{H}_{\\text{patch}}; \\mathbf{e}_{\\text{CQI}}])",
          "description": "CSI 행렬을 패치로 나누고, CQI(Channel Quality Indicator) 등의 의미적 임베딩을 함께 연결하여 Transformer 인코더에 입력한다. 통신 품질에 중요한 특징을 우선적으로 학습한다."
        }
      ],
      "category": "transformer",
      "tags": [
        "semantic",
        "cqi",
        "transformer",
        "joint-coding",
        "robust",
        "csi-feedback",
        "2025"
      ],
      "pdf_url": "https://arxiv.org/pdf/2505.08314",
      "code_url": null,
      "color_hex": "#059669",
      "architecture_detail": "의미 통신(Semantic Communication) 개념을 CSI 피드백에 도입한 모델이다. 기존 방식이 CSI 행렬의 모든 원소를 동등하게 압축하는 반면, SemCSINet은 \"통신 성능에 실제로 중요한 의미적 특징\"만 선별적으로 추출하여 전송한다. 수신 측에서는 의미적 특징으로부터 전체 CSI를 복원한다. 불필요한 정보는 과감히 버리는 전략으로 더 높은 압축 효율을 달성한다."
    },
    {
      "title": "RD-JSCC: Residual Diffusion for Variable-Rate Joint Source-Channel Coding of MIMO CSI",
      "authors": [
        "Sravan Kumar Ankireddy",
        "Heasung Kim",
        "Hyeji Kim"
      ],
      "year": 2025,
      "venue": "arXiv preprint",
      "doi": null,
      "arxiv_id": "2505.21681",
      "abstract": "RD-JSCC는 경량 오토인코더와 반복적 CSI 정제를 위한 잔차 확산 모듈을 결합한다. 채널 조건에 따라 저복잡도 오토인코더 디코딩과 확산 기반 정제 사이를 동적으로 전환하는 적응적 디코딩을 특징으로 하며, 단일 모델로 다중 압축률을 지원한다.",
      "key_contributions": [
        "반복적 CSI 복원 개선을 위한 잔차 확산 정제 모듈",
        "단일 통합 모델에서의 가변 전송률 지원",
        "채널 조건에 따라 오토인코더와 확산 모델 간 전환하는 적응적 디코딩"
      ],
      "algorithms": [
        "잔차 확산 정제(Residual Diffusion Refinement)",
        "가변률 JSCC 인코더(Variable-Rate JSCC Encoder)",
        "적응적 복잡도 디코더(Adaptive Complexity Decoder)",
        "2단계 고속 확산 추론(2-Step Fast Diffusion Inference)"
      ],
      "key_equations": [
        {
          "name": "잔차 확산",
          "latex": "\\hat{\\mathbf{H}}_{\\text{refined}} = \\hat{\\mathbf{H}}_0 + \\epsilon_\\theta(\\hat{\\mathbf{H}}_0 + \\sigma_t \\boldsymbol{\\epsilon}, t, \\mathbf{s})",
          "description": "1단계 오토인코더 복원의 오차(잔차)를 확산 모델이 예측하여 제거한다. 원본과 초기 복원의 차이를 추가로 보정하는 구조로, 확산 단계 수를 조절하면 품질-속도 트레이드오프를 조정할 수 있다."
        }
      ],
      "category": "other",
      "tags": [
        "diffusion",
        "jscc",
        "variable-rate",
        "residual",
        "adaptive",
        "csi-feedback",
        "2025"
      ],
      "pdf_url": "https://arxiv.org/pdf/2505.21681",
      "code_url": null,
      "color_hex": "#14B8A6",
      "architecture_detail": "오토인코더의 초기 복원에 확산 모델을 \"보조 정제기\"로 붙인 2단계 구조이다. 1단계: 경량 오토인코더가 빠르게 CSI를 압축·초기 복원한다. 2단계: 확산 모델이 초기 복원의 잔차(오차 부분)를 추가로 보정하여 세밀한 디테일을 살린다. 확산 단계 수를 조절하여 압축률과 복원 품질의 균형을 유연하게 맞출 수 있으며, 가변 레이트(variable-rate) 전송이 가능하다."
    },
    {
      "title": "WiFo-CF: Wireless Foundation Model for CSI Feedback",
      "authors": [
        "Xuanyu Liu",
        "Shijian Gao",
        "Boxun Liu",
        "Xiang Cheng",
        "Liuqing Yang"
      ],
      "year": 2025,
      "venue": "arXiv preprint",
      "doi": null,
      "arxiv_id": "2508.04068",
      "abstract": "WiFo-CF는 이기종 구성(다양한 채널 차원, 피드백 전송률, 데이터 분포)을 통합 프레임워크 내에서 지원하는 CSI 피드백 전용 파운데이션 모델이다. 다중 사용자 다중 전송률 자기 지도 사전 학습과 공유 및 라우팅 전문가 혼합(S-R MoE) 아키텍처를 활용한다.",
      "key_contributions": [
        "이기종 CSI 피드백을 위해 특별히 설계된 최초의 파운데이션 모델",
        "다양한 채널 차원과 피드백 전송률을 하나의 모델에서 지원하는 S-R MoE 아키텍처",
        "이기종 CSI 데이터셋에 대한 다중 사용자 다중 전송률 자기 지도 사전 학습"
      ],
      "algorithms": [
        "공유-라우팅 전문가 혼합(Shared-Routed Mixture of Experts, S-R MoE)",
        "다중 전송률 자기 지도 사전 학습(Multi-Rate Self-Supervised Pre-Training)",
        "이기종 구성 어댑터(Heterogeneous Configuration Adapter)",
        "파운데이션 모델 미세 조정(Foundation Model Fine-Tuning)"
      ],
      "key_equations": [
        {
          "name": "S-R 전문가 혼합 레이어",
          "latex": "\\mathbf{y} = \\mathbf{W}_s \\mathbf{x} + \\sum_{i=1}^{K} g_i(\\mathbf{x}) \\cdot E_i(\\mathbf{x}), \\quad g_i = \\text{TopK}(\\text{softmax}(\\mathbf{W}_g \\mathbf{x}))",
          "description": "공유 전문가(W_s)가 항상 활성화되어 공통 지식을 담당하고, 게이팅 네트워크가 입력에 따라 상위 K개의 라우팅 전문가를 추가로 선택한다. 환경별로 다른 전문가가 활성화되어 적응적 처리가 가능하다."
        }
      ],
      "category": "transformer",
      "tags": [
        "foundation-model",
        "moe",
        "self-supervised",
        "heterogeneous",
        "pre-training",
        "csi-feedback",
        "2025"
      ],
      "pdf_url": "https://arxiv.org/pdf/2508.04068",
      "code_url": null,
      "color_hex": "#DC2626",
      "architecture_detail": "대규모 CSI 데이터로 사전학습한 무선 통신 도메인 파운데이션 모델이다. 비전 분야의 대규모 모델처럼, 먼저 광범위한 환경의 CSI로 기반 모델을 훈련시킨 뒤, 특정 시나리오에는 S-R MoE(Sparse-to-Rich Mixture of Experts) 모듈로 효율적 미세조정(fine-tuning)한다. \"하나의 모델로 다양한 환경에 적응\"하는 것이 목표이며, 환경별로 별도 모델을 학습할 필요가 없어 실용성이 높다."
    },
    {
      "title": "EG-CsiNet: Generalizable Learning for Massive MIMO CSI Feedback in Unseen Environments",
      "authors": [
        "Haoyu Wang",
        "Zhi Sun",
        "Shuangfeng Han",
        "Xiaoyun Wang",
        "Zhaocheng Wang"
      ],
      "year": 2025,
      "venue": "arXiv preprint",
      "doi": null,
      "arxiv_id": "2512.22840",
      "abstract": "EG-CsiNet은 물리 기반 분포 정렬(distribution alignment)을 제안하여, 미경험 환경에서의 딥러닝 기반 CSI 피드백 일반화 문제를 해결한다. Eckart-Young-Mirsky 정리를 활용한 클러스터 기반 채널 분해를 통해 분포 이동(distribution shift)을 모델링하며, 최신 기법 대비 3 dB 이상의 일반화 오차 감소를 달성한다.",
      "key_contributions": [
        "환경 일반화를 위한 물리 정보 기반 분포 정렬 기법",
        "Eckart-Young-Mirsky 정리를 활용한 클러스터 기반 채널 분해",
        "시뮬레이션-실측 실험에서 검증된 3+ dB 일반화 성능 향상"
      ],
      "algorithms": [
        "Physics-Based Distribution Alignment (물리 기반 분포 정렬)",
        "Cluster-Based Channel Decomposition (클러스터 기반 채널 분해)",
        "Eckart-Young-Mirsky SVD Factoring",
        "Domain-Invariant Feature Learning (도메인 불변 특징 학습)"
      ],
      "key_equations": [
        {
          "name": "채널 클러스터 분해",
          "latex": "\\mathbf{H} \\approx \\sum_{k=1}^{K} \\pi_k \\mathbf{U}_k \\boldsymbol{\\Sigma}_k \\mathbf{V}_k^H",
          "description": "CSI를 SVD로 분해하여 K개의 채널 클러스터로 나누고, 학습 환경(소스)과 새 환경(타겟)의 클러스터 분포를 정렬한다. 분포 차이를 줄여 새로운 환경에서도 성능이 유지되게 한다."
        }
      ],
      "category": "autoencoder",
      "tags": [
        "generalization",
        "domain-adaptation",
        "physics-informed",
        "unseen-environment",
        "sim-to-real",
        "csi-feedback",
        "2025"
      ],
      "pdf_url": "https://arxiv.org/pdf/2512.22840",
      "code_url": null,
      "color_hex": "#F97316",
      "architecture_detail": "새로운 환경(학습 데이터에 없던 환경)에서도 잘 동작하는 일반화 능력이 핵심인 모델이다. CsiNet 기반 오토인코더에 SVD 기반 클러스터링과 분포 정렬 모듈을 추가했다. Eckart-Young-Mirsky 정리를 활용하여 서로 다른 환경의 CSI 분포를 정렬함으로써, 학습 환경과 테스트 환경이 달라도 성능 저하를 최소화한다. \"낯선 장소에 가도 적응할 수 있는\" 일반화를 추구한다."
    },
    {
      "title": "LVM4CF: CSI Feedback with Offline Large Vision Models",
      "authors": [
        "Jialin Zhuang",
        "Yafei Wang",
        "Hongwei Hou",
        "Yu Han",
        "Wenjin Wang",
        "Shi Jin",
        "Jiangzhou Wang"
      ],
      "year": 2025,
      "venue": "arXiv preprint",
      "doi": null,
      "arxiv_id": "2505.08566",
      "abstract": "LVM4CF는 CSI 행렬과 자연 이미지 간의 구조적 유사성을 활용하여, 사전 학습된 대규모 비전 모델을 오프라인으로 사용해 맞춤형 CSI 코드북을 생성한다. 사이트 특화 및 다중 시나리오 프레임워크를 통해 복원 정확도와 처리량을 향상시키며, 배포 시 추가 지연 시간이 전혀 발생하지 않는다.",
      "key_contributions": [
        "CSI-이미지 구조적 유사성을 활용한 대규모 비전 모델의 오프라인 CSI 코드북 생성",
        "사이트 특화 및 다중 시나리오 코드북 생성 프레임워크",
        "추론 시 추가 연산 오버헤드 및 지연 시간 제로"
      ],
      "algorithms": [
        "Large Vision Model Feature Extraction (대규모 비전 모델 특징 추출)",
        "CSI-Image Structural Mapping (CSI-이미지 구조 매핑)",
        "Offline Codebook Generation (오프라인 코드북 생성)",
        "Site-Specific Fine-Tuning (사이트 특화 미세 조정)"
      ],
      "key_equations": [
        {
          "name": "비전-CSI 코드북",
          "latex": "\\mathcal{C}^* = \\arg\\min_{\\mathcal{C}} \\sum_{i} \\min_{\\mathbf{c} \\in \\mathcal{C}} \\|f_{\\text{LVM}}(\\mathbf{H}_i) - \\mathbf{c}\\|_2^2",
          "description": "대규모 비전 모델의 풍부한 특징 공간에서 CSI 양자화에 최적화된 코드북을 구성한다. 비전 모델이 학습한 범용 표현을 활용하여, 적은 CSI 데이터로도 효과적인 코드북을 얻는다."
        }
      ],
      "category": "other",
      "tags": [
        "large-vision-model",
        "codebook",
        "offline",
        "transfer-learning",
        "csi-feedback",
        "2025"
      ],
      "pdf_url": "https://arxiv.org/pdf/2505.08566",
      "code_url": null,
      "color_hex": "#84CC16",
      "architecture_detail": "GPT나 CLIP 같은 대규모 비전 모델(LVM)의 사전학습된 표현력을 CSI 피드백에 빌려 오는 접근법이다. CSI 행렬을 이미지처럼 취급하여 비전 모델의 인코더에 넣고, 오프라인으로 추출된 풍부한 특징 표현을 CSI 복원에 활용한다. 대규모 모델의 방대한 표현력 덕분에 적은 학습 데이터로도 좋은 복원 성능을 보이며, 비전 분야의 발전을 통신에 접목하는 교차 분야 연구이다."
    },
    {
      "title": "Semantic Pilot Design for Channel Estimation Using a Large Language Model",
      "authors": [
        "Sojeong Park",
        "Hyun Jong Yang"
      ],
      "year": 2026,
      "venue": "arXiv preprint",
      "doi": null,
      "arxiv_id": "2602.04126",
      "abstract": "본 논문은 LLM을 활용하여 채널 추정을 개선하는 방법을 제안한다. 초기 복호된 텍스트와 LLM이 교정한 버전을 비교하여 신뢰성 높은 복호 심볼을 '시맨틱 파일럿'으로 식별하고, 이를 기존 파일럿에 보완하여 데이터 보조 채널 추정을 강화함으로써 위상 추정 성능을 향상시키고 오류율을 감소시킨다.",
      "key_contributions": [
        "채널 추정을 위한 LLM 기반 '시맨틱 파일럿'의 새로운 개념 제안",
        "복호된 데이터 심볼에 대한 LLM 기반 신뢰도 평가",
        "파일럿 전용 방식 대비 향상된 채널 위상 추정 및 낮은 BER 달성"
      ],
      "algorithms": [
        "LLM-Based Semantic Pilot Extraction (LLM 기반 시맨틱 파일럿 추출)",
        "Reliability Score via LLM Confidence (LLM 신뢰도 기반 신뢰성 점수)",
        "Data-Aided Channel Re-Estimation (데이터 보조 채널 재추정)",
        "Semantic Pilot Selection Threshold (시맨틱 파일럿 선택 임계값)"
      ],
      "key_equations": [
        {
          "name": "의미적 파일럿 신뢰도",
          "latex": "r_k = \\mathbb{1}[p_{\\text{LLM}}(\\hat{x}_k | \\hat{\\mathbf{x}}_{\\setminus k}) > \\tau]",
          "description": "LLM이 복호한 심볼에 대한 신뢰도(확률)가 임계값 τ를 넘으면 해당 심볼을 시맨틱 파일럿으로 사용한다. LLM의 언어 이해력을 활용하여, 채널 추정에 유용한 심볼을 자동 선별한다."
        }
      ],
      "category": "other",
      "tags": [
        "llm",
        "semantic-pilot",
        "channel-estimation",
        "data-aided",
        "2026"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.04126",
      "code_url": null,
      "color_hex": "#6366F1",
      "architecture_detail": "대규모 언어 모델(LLM)을 채널 추정의 파일럿 설계에 활용하는 혁신적 시도이다. LLM이 채널 환경에 대한 텍스트 설명(예: \"도심 환경, 높은 빌딩 밀집\")을 입력받아 해당 환경에 최적화된 파일럿 패턴을 생성한다. 의미적 이해력을 가진 LLM이 물리적 환경의 특성을 반영한 파일럿을 설계하여, 전통적인 수학적 최적화 방식과 차별화된다."
    },
    {
      "title": "Neural Discrete Representation Learning (VQ-VAE)",
      "authors": [
        "Aaron van den Oord",
        "Oriol Vinyals",
        "Koray Kavukcuoglu"
      ],
      "year": 2017,
      "venue": "NeurIPS 2017",
      "doi": null,
      "arxiv_id": "1711.00937",
      "abstract": "이 논문의 핵심 질문은 \"VAE의 연속 잠재 공간을 이산 코드북으로 대체하면, 사후 분포 붕괴(posterior collapse) 없이 고품질 생성을 달성하면서도 이산적 표현의 장점(코드 전송, 명확한 분류)을 얻을 수 있는가?\"이다.\n\nVQ-VAE는 인코더 출력 벡터를 학습된 코드북에서 가장 가까운 벡터로 교체(최근접 이웃 탐색)하여 이산 코드를 생성하고, Straight-Through Estimator로 양자화 단계의 그래디언트를 전파한다. 복원 손실, 코드북 손실, 커미트먼트 손실의 세 가지 손실 함수를 결합하여 인코더와 코드북을 동시에 학습하며, 이미지·비디오·음성에서 고품질 생성을 달성했다.",
      "key_contributions": [
        "문제 정의: 기존 VAE의 연속 잠재 공간이 사후 분포 붕괴(posterior collapse) 문제를 겪으며, 이산적 표현의 자연스러운 장점을 활용하지 못하는 한계를 지적했다.",
        "핵심 기법: 인코더 출력을 학습 가능한 코드북의 최근접 벡터로 양자화하는 벡터 양자화(VQ) 계층을 VAE에 도입하여, 이산 잠재 표현을 학습하는 VQ-VAE를 제안했다.",
        "설계 차별점: stop-gradient(sg) 연산자를 활용하여 코드북 학습과 인코더 학습을 분리하고, 3가지 손실(복원/코드북/커미트먼트)로 각각의 학습 방향을 독립적으로 제어했다.",
        "실험 검증: 이미지(CIFAR-10, ImageNet), 비디오, 음성 생성 과제에서 연속 VAE를 능가하는 생성 품질을 달성하고, 사후 분포 붕괴 없이 안정적 학습을 보였다.",
        "실용성: 이산 코드(인덱스)만 전송하면 되므로 통신 비트 효율이 높고, 하위 생성 모델(PixelCNN 등)과 결합하여 고해상도 생성이 가능하다.",
        "연구사적 의미: 이산 표현 학습의 기초를 세워, CSI 피드백의 VQ 기반 양자화, SoundStream(RVQ), FSQ 등 다양한 분야로 확산된 핵심 참고 논문이 되었다."
      ],
      "algorithms": [
        "VQ-VAE Encoder-Decoder (VQ-VAE 인코더-디코더)",
        "Codebook Nearest-Neighbor Lookup (코드북 최근접 이웃 탐색)",
        "Exponential Moving Average Codebook Update (지수 이동 평균 코드북 업데이트)",
        "Straight-Through Gradient Estimator (Straight-Through 기울기 추정기)"
      ],
      "key_equations": [
        {
          "name": "VQ-VAE 손실 함수",
          "latex": "\\mathcal{L} = \\|\\mathbf{x} - D(\\mathbf{e}_k)\\|_2^2 + \\|\\text{sg}[E(\\mathbf{x})] - \\mathbf{e}_k\\|_2^2 + \\beta\\|E(\\mathbf{x}) - \\text{sg}[\\mathbf{e}_k]\\|_2^2",
          "description": "해석: 세 개의 손실 항목이 서로 다른 학습 목표를 담당한다. 첫째 항(복원 손실)은 디코더가 입력을 잘 재현하도록 한다. 둘째 항(코드북 손실)은 sg(stop-gradient)로 인코더를 고정한 채 코드북 벡터 e_k를 인코더 출력 쪽으로 이동시킨다. 셋째 항(커미트먼트 손실)은 반대로 코드북을 고정한 채 인코더 출력이 코드북 벡터에 가까워지도록 한다. β 계수로 인코더의 커미트먼트 강도를 조절하며, 이 세 항의 균형이 안정적 학습의 핵심이다."
        },
        {
          "name": "벡터 양자화",
          "latex": "\\mathbf{z}_q = \\mathbf{e}_k, \\quad k = \\arg\\min_j \\|E(\\mathbf{x}) - \\mathbf{e}_j\\|_2",
          "description": "해석: 인코더 출력 벡터 z_e = E(x)를 코드북의 모든 벡터 {e_1, e_2, ..., e_K}와 L2 거리를 비교하여, 가장 가까운 벡터 e_k로 교체한다. 이것이 '양자화'의 핵심 연산으로, 연속 벡터를 K개의 이산 코드 중 하나로 매핑한다. 전송 시에는 인덱스 k만 보내면 되므로 log₂(K) 비트만 필요하다. 이 아이디어가 CSI 피드백 VQ 연구의 직접적 기반이 되었다."
        }
      ],
      "category": "quantization",
      "tags": [
        "vq-vae",
        "vector-quantization",
        "discrete-latent",
        "codebook",
        "foundational"
      ],
      "pdf_url": "https://arxiv.org/pdf/1711.00937",
      "code_url": "https://github.com/deepmind/sonnet/blob/master/sonnet/python/modules/nets/vqvae.py",
      "color_hex": "#7C3AED",
      "architecture_detail": "2.1 문제 설정\n기존 VAE는 연속 잠재 공간을 사용하지만, 많은 실제 데이터(음성, 텍스트, 코드 등)는 본질적으로 이산적 구조를 가진다. 연속 잠재 변수를 사용하면 사후 분포 붕괴(posterior collapse) 문제가 발생할 수 있다.\n\n2.2 기존 접근의 한계\n연속 VAE는 KL 발산 정규화로 인해 잠재 코드가 사전 분포에 과도하게 가까워지면서 디코더가 잠재 코드를 무시하는 현상(posterior collapse)이 발생한다. 또한 연속 표현은 직접 전송에 부적합하여 별도의 양자화가 필요하다.\n\n2.3 VQ-VAE 설계 철학\n\"잠재 공간 자체를 이산으로 만들자\"가 핵심이다. 인코더 출력을 학습 가능한 코드북의 최근접 벡터로 교체하여 이산 코드를 생성하고, STE로 역전파를 가능하게 한다.\n\n2.4 핵심 기법 상세\n- 인코더: 입력을 연속 벡터 z_e로 변환\n- 벡터 양자화: z_e를 코드북 {e_1,...,e_K}에서 최근접 벡터 e_k로 교체\n- 디코더: 양자화된 e_k로부터 입력을 복원\n- STE: 순방향은 양자화, 역방향은 그래디언트를 디코더에서 인코더로 직접 전달\n- 3가지 손실: 복원(전체 파이프라인), 코드북(sg[E(x)] → e_k), 커미트먼트(E(x) → sg[e_k])\n- EMA 갱신: 코드북 벡터를 지수 이동 평균으로 갱신하여 학습 안정성 확보\n\n2.5 수식이 말하는 의미\n- VQ-VAE 손실식: sg로 분리된 3방향 동시 학습 → 인코더·코드북·디코더 각각의 역할 명확화\n- 벡터 양자화식: 연속 → 이산 매핑의 수학적 정의 → log₂(K) 비트 전송의 기반\n\n2.6 이 논문이 남긴 것\nVQ-VAE는 이산 표현 학습의 기초를 세운 논문이다. CSI 피드백의 VQ 기반 코드워드 양자화, SoundStream의 RVQ, FSQ의 스칼라 양자화 등 다양한 분야에서 이 아이디어가 활용되고 있으며, 양자화 기반 표현 학습의 참조점이 되었다.",
      "difficulty_level": "intermediate",
      "prerequisites": [
        "VAE(Variational Autoencoder)의 기본 구조와 잠재 공간 개념",
        "벡터 양자화(Vector Quantization)와 코드북의 개념",
        "Straight-Through Estimator(STE)의 역할",
        "연속 잠재 표현 vs 이산 잠재 표현의 차이와 각각의 장점"
      ],
      "learning_objectives": [
        "VQ-VAE의 3가지 손실 항목(복원/코드북/커미트먼트)의 역할을 각각 설명할 수 있다",
        "stop-gradient(sg) 연산자가 코드북 학습과 인코더 학습을 분리하는 원리를 이해한다",
        "코드북 붕괴(codebook collapse) 문제의 원인과 해결 방법을 설명할 수 있다",
        "VQ-VAE의 이산 표현이 CSI 피드백 VQ 연구에 미친 영향을 분석할 수 있다"
      ],
      "self_check_questions": [
        "VQ-VAE에서 stop-gradient(sg) 연산자가 없으면 어떤 문제가 발생하는가?",
        "코드북 붕괴(codebook collapse)란 무엇이며, 왜 발생하는가?",
        "VQ-VAE의 이산 잠재 표현이 연속 VAE 대비 가지는 장점은 무엇인가?",
        "VQ-VAE의 커미트먼트 손실 계수 β를 너무 크거나 작게 설정하면 어떤 일이 일어나는가?"
      ]
    },
    {
      "title": "AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration",
      "authors": [
        "Ji Lin",
        "Jiaming Tang",
        "Haotian Tang",
        "Shang Yang",
        "Wei-Ming Chen",
        "Wei-Chen Wang",
        "Guangxuan Xiao",
        "Xingyu Dang",
        "Chuang Gan",
        "Song Han"
      ],
      "year": 2023,
      "venue": "MLSys 2024 (Best Paper)",
      "doi": null,
      "arxiv_id": "2306.00978",
      "abstract": "AWQ는 LLM을 위한 하드웨어 친화적 저비트 가중치 전용 양자화를 제안한다. 핵심 통찰: 모든 가중치가 동등하게 중요하지 않으며, 활성화 크기(가중치 크기가 아닌)를 기반으로 식별된 1%의 중요 채널만 보호해도 양자화 오차가 크게 감소한다. 채널별 스케일링으로 혼합 정밀도 오버헤드 없이 중요 가중치를 보호하여 FP16 대비 3배 이상의 속도 향상을 달성한다.",
      "key_contributions": [
        "활성화 통계 기반 중요 가중치 탐지 (가중치 크기가 아닌 활성화 기반)",
        "혼합 정밀도 하드웨어 오버헤드 없는 채널별 스케일링을 통한 중요 가중치 보호",
        "데스크톱 및 모바일 GPU에서 FP16 대비 3배 이상 속도 향상 (정확도 손실 무시 가능)"
      ],
      "algorithms": [
        "Activation-Aware Saliency Detection (활성화 인식 중요도 탐지)",
        "Per-Channel Scaling Transform (채널별 스케일링 변환)",
        "Grid Search for Optimal Scale (최적 스케일 격자 탐색)",
        "TinyChat Inference Engine (TinyChat 추론 엔진)"
      ],
      "key_equations": [
        {
          "name": "AWQ 스케일링 변환",
          "latex": "Q(\\mathbf{w} \\cdot s) \\cdot (\\mathbf{x} / s) \\approx \\mathbf{w} \\cdot \\mathbf{x}, \\quad s^* = \\arg\\min_s \\|Q(\\mathbf{W} \\text{diag}(s))\\text{diag}(s)^{-1}\\mathbf{X} - \\mathbf{W}\\mathbf{X}\\|",
          "description": "양자화 전에 중요한 가중치 채널(활성화가 큰 채널)을 스케일업하여 양자화 오차를 줄인다. 양자화 격자에서 중요 값이 더 정밀하게 표현되도록 하는 간단하면서도 효과적인 전처리이다."
        }
      ],
      "category": "quantization",
      "tags": [
        "awq",
        "activation-aware",
        "weight-quantization",
        "low-bit",
        "llm",
        "hardware-friendly",
        "foundational"
      ],
      "pdf_url": "https://arxiv.org/pdf/2306.00978",
      "code_url": "https://github.com/mit-han-lab/llm-awq",
      "color_hex": "#DC2626",
      "architecture_detail": "LLM의 가중치를 활성화 분포를 고려하여 양자화하는 사후 학습 기법이다. 핵심 아이디어는 \"활성화 값이 큰 채널에 연결된 가중치가 더 중요하다\"는 관찰이다. 활성화 크기에 비례하는 스케일링을 가중치에 적용하여, 중요한 가중치의 양자화 오차를 줄이고 덜 중요한 가중치는 과감히 양자화한다. 추가 학습 없이 적용 가능하여, 대규모 모델의 빠른 경량화에 적합하다."
    },
    {
      "title": "HAWQ-V3: Dyadic Neural Network Quantization",
      "authors": [
        "Zhewei Yao",
        "Zhen Dong",
        "Zhangcheng Zheng",
        "Amir Gholami",
        "Jiali Yu",
        "Eric Tan",
        "Leyuan Wang",
        "Qijing Huang",
        "Yida Wang",
        "Michael W. Mahoney",
        "Kurt Keutzer"
      ],
      "year": 2021,
      "venue": "ICML 2021",
      "doi": null,
      "arxiv_id": "2011.10680",
      "abstract": "HAWQ-V3는 integer-only 혼합 정밀도 양자화 프레임워크다. 전체 계산 그래프를 정수 곱셈, 덧셈, 비트 시프트만으로 실행하고, 레이어별 헤시안 민감도와 하드웨어 제약을 함께 고려한 ILP 비트 할당으로 정확도와 지연시간의 균형을 맞춘다.",
      "key_contributions": [
        "부동소수점 연산 없이 동작하는 integer-only 추론 파이프라인 제시",
        "레이어별 헤시안 민감도와 모델 크기, BOPS, 지연시간 제약을 함께 푸는 ILP 기반 비트 할당",
        "dyadic 스케일을 사용해 division 비용을 줄이고 하드웨어 친화성 강화",
        "TVM 배포까지 포함한 실험으로 INT4/INT8 혼합 정밀도 성능 검증"
      ],
      "algorithms": [
        "Hessian-Based Layer Sensitivity Estimation (헤시안 기반 민감도 추정)",
        "Hardware-Aware ILP Bit Allocation (하드웨어 제약 ILP 비트 할당)",
        "Dyadic Rescaling for Integer-Only Arithmetic (dyadic 재스케일)",
        "INT4 Packing + TVM Deployment (INT4 패킹 및 TVM 배포)"
      ],
      "key_equations": [
        {
          "name": "균일 양자화",
          "latex": "Q(r)=\\mathrm{Int}(r/S)-Z",
          "description": "실수값 r을 스케일 S와 zero-point Z로 정수 격자에 매핑한다. integer-only 추론의 기본 식이다."
        },
        {
          "name": "Dyadic 스케일 근사",
          "latex": "\\frac{b}{2^c}=\\mathrm{DN}\\!\\left(\\frac{S_w S_h}{S_a}\\right)",
          "description": "재스케일 계수를 b/2^c 형태로 제한하면 정수 곱셈과 비트 시프트만으로 스케일 연산이 가능하다."
        },
        {
          "name": "ILP 혼합 정밀도 최적화",
          "latex": "\\min_{\\{b_i\\}}\\sum_{i=1}^{L}\\Omega_i^{(b_i)}\\;\\text{s.t.}\\;\\sum_i M_i^{(b_i)}\\le M_{\\max},\\;\\sum_i G_i^{(b_i)}\\le G_{\\max},\\;\\sum_i Q_i^{(b_i)}\\le T_{\\max}",
          "description": "민감도 합을 최소화하면서 모델 크기, 연산량, 지연시간 제약을 동시에 만족하는 비트폭을 찾는다."
        }
      ],
      "category": "quantization",
      "tags": [
        "hawq-v3",
        "hessian",
        "mixed-precision",
        "integer-only",
        "dyadic",
        "hardware-aware",
        "foundational"
      ],
      "pdf_url": "https://arxiv.org/pdf/2011.10680",
      "code_url": "https://github.com/Zhen-Dong/HAWQ",
      "color_hex": "#B91C1C",
      "architecture_detail": "2.1 문제 설정\n양자화 모델이 실제 하드웨어에서 빠르지 않은 주요 원인은 float-int 변환 오버헤드다.\n\n2.2 기존 한계\nINT8은 안정적이지만 INT4 이하에서는 정확도 저하와 스케일 처리 비용이 동시에 커진다.\n\n2.3 설계 철학\n헤시안 기반 민감도로 레이어 중요도를 추정하고, ILP로 하드웨어 제약을 포함한 비트 배분을 자동화한다.\n\n2.4 핵심 기법\n- 민감도 사전 계산\n- ILP 기반 레이어별 비트 선택\n- dyadic 재스케일로 integer-only 연산 유지\n- TVM 커널 최적화 및 INT4 패킹\n\n2.5 의미\n정확도와 시스템 제약의 충돌을 수식으로 다루어 수동 튜닝 부담을 줄인다.\n\n2.6 의의\nHAWQ-V3는 혼합 정밀도 양자화를 배포 가능한 시스템 최적화 문제로 정착시켰다.",
      "difficulty_level": "advanced",
      "prerequisites": [
        "헤시안과 2차 근사 기초",
        "신경망 양자화 기본 개념",
        "정수 연산 파이프라인(INT4/INT8)",
        "제약 최적화와 ILP 기초"
      ],
      "learning_objectives": [
        "dyadic 스케일의 하드웨어 이점을 설명할 수 있다.",
        "민감도 기반 비트 할당을 ILP로 정식화할 수 있다.",
        "정확도-지연시간-메모리 트레이드오프를 해석할 수 있다.",
        "HAWQ-V3 아이디어를 CSI 피드백에 적용할 수 있다."
      ],
      "self_check_questions": [
        "integer-only가 실제 지연시간 개선에 중요한 이유는 무엇인가?",
        "ILP 제약식의 M, G, Q는 무엇을 의미하는가?",
        "dyadic 스케일을 쓰면 어떤 연산 비용이 줄어드는가?",
        "민감도가 큰 레이어에 높은 비트폭이 필요한 이유는 무엇인가?"
      ]
    },
    {
      "title": "BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction",
      "authors": [
        "Yuhang Li",
        "Ruihao Gong",
        "Xu Tan",
        "Yang Yang",
        "Peng Hu",
        "Qi Zhang",
        "Fengwei Yu",
        "Wei Wang",
        "Shi Gu"
      ],
      "year": 2021,
      "venue": "ICLR 2021",
      "doi": null,
      "arxiv_id": "2102.05426",
      "abstract": "BRECQ는 PTQ(post-training quantization)의 저비트 한계를 낮추기 위해 block reconstruction을 제안한다. 2차 오차 분석을 출력 공간 재구성 문제로 바꾸고, layer-wise와 network-wise 사이의 절충점으로 block-wise 보정을 수행해 INT2까지 확장 가능함을 보였다.",
      "key_contributions": [
        "PTQ에서 block-wise reconstruction을 도입해 cross-layer dependency를 더 잘 반영",
        "2차 오차를 출력 공간 재구성 목적함수로 변환해 계산 가능성 확보",
        "Fisher 가중을 사용해 중요한 출력 차원을 우선 보정",
        "2/4/8bit 혼합 정밀도 탐색을 결합해 성능-효율 균형 개선"
      ],
      "algorithms": [
        "Block Reconstruction PTQ Calibration (블록 단위 보정)",
        "Fisher-Weighted Second-Order Objective (Fisher 가중 2차 목적함수)",
        "AdaRound + LSQ Calibration",
        "Genetic Mixed-Precision Search under Hardware Constraints"
      ],
      "key_equations": [
        {
          "name": "2차 손실 근사",
          "latex": "\\mathbb{E}[L(w+\\Delta w)]-\\mathbb{E}[L(w)]\\approx\\Delta w^T\\bar g(w)+\\frac{1}{2}\\Delta w^T\\bar H(w)\\Delta w",
          "description": "양자화를 가중치 교란으로 보고 손실 증가를 2차 항까지 근사한다."
        },
        {
          "name": "출력 공간 재구성 변환",
          "latex": "\\arg\\min_{\\hat\\theta}\\Delta\\theta^T\\bar H(\\theta)\\Delta\\theta\\approx\\arg\\min_{\\hat\\theta}\\mathbb{E}[\\Delta z^{(n)T}H(z^{(n)})\\Delta z^{(n)}]",
          "description": "파라미터 공간 Hessian 목적식을 출력 변화 기반으로 바꿔 실용적으로 최적화한다."
        },
        {
          "name": "블록 재구성 목적식",
          "latex": "\\min_{\\hat w}\\mathbb{E}[\\Delta z^{(\\ell)T}\\operatorname{diag}((\\partial L/\\partial z^{(\\ell)}_1)^2,\\ldots,(\\partial L/\\partial z^{(\\ell)}_a)^2)\\Delta z^{(\\ell)}]",
          "description": "중요도가 큰 출력 차원에 더 큰 가중을 주어 보정 효과를 높인다."
        },
        {
          "name": "혼합 정밀도 제약 최적화",
          "latex": "\\min_{c}L(\\hat w,c)\\;\\text{s.t.}\\;H(c)\\le\\delta,\\;c\\in\\{2,4,8\\}^n",
          "description": "하드웨어 제약을 만족하면서 레이어별 비트폭 벡터를 선택한다."
        }
      ],
      "category": "quantization",
      "tags": [
        "brecq",
        "post-training-quantization",
        "block-reconstruction",
        "second-order",
        "mixed-precision",
        "hessian",
        "foundational"
      ],
      "pdf_url": "https://arxiv.org/pdf/2102.05426",
      "code_url": "https://github.com/yhhhli/BRECQ",
      "color_hex": "#EF4444",
      "architecture_detail": "2.1 문제 설정\nPTQ는 재학습 비용은 낮지만 저비트에서 정확도 하락이 크다.\n\n2.2 기존 한계\nfull Hessian은 계산량이 너무 크고, layer-wise 독립 가정은 상호작용을 과도하게 단순화한다.\n\n2.3 설계 철학\nlayer와 network 사이 중간 단위인 block을 재구성 단위로 사용한다.\n\n2.4 핵심 기법\n- 2차 오차 분석\n- 출력 공간 변환\n- block-wise 순차 보정\n- Fisher 가중\n- 혼합 정밀도 탐색\n\n2.5 의미\n단순 MSE보다 task-aware 보정이 가능해 저비트 PTQ에서 안정적이다.\n\n2.6 의의\nBRECQ는 PTQ가 8비트 중심이라는 한계를 넘어 4비트와 2비트 실용화를 촉진했다.",
      "difficulty_level": "advanced",
      "prerequisites": [
        "Taylor 전개와 Hessian 기초",
        "PTQ와 QAT 차이",
        "Residual block 구조",
        "혼합 정밀도 탐색 기본"
      ],
      "learning_objectives": [
        "block-wise 재구성이 유리한 이유를 설명할 수 있다.",
        "2차 오차 목적식을 출력 공간으로 변환할 수 있다.",
        "Fisher 가중 목적함수의 의미를 설명할 수 있다.",
        "2/4/8bit 혼합 정밀도 문제를 제약 최적화로 쓸 수 있다."
      ],
      "self_check_questions": [
        "PTQ에서 full Hessian 직접 사용이 어려운 이유는 무엇인가?",
        "block-wise는 어떤 의존성을 보존하는가?",
        "Fisher 가중은 어떤 차원을 더 강하게 보정하는가?",
        "같은 예산에서 uniform 2bit와 mixed precision의 차이는 무엇인가?"
      ]
    },
    {
      "title": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers",
      "authors": [
        "Elias Frantar",
        "Saleh Ashkboos",
        "Torsten Hoefler",
        "Dan Alistarh"
      ],
      "year": 2022,
      "venue": "ICLR 2023",
      "doi": null,
      "arxiv_id": "2210.17323",
      "abstract": "GPTQ는 근사 2차 정보(Optimal Brain Surgeon 프레임워크)에 기반한 원샷 가중치 양자화 방법이다. 1,750억 파라미터 GPT 모델을 약 4 GPU 시간 만에 가중치당 3-4비트로 양자화하며, 정확도 저하가 거의 없어 단일 GPU에서의 실행을 가능하게 한다. A100에서 3.25배 속도 향상을 달성한다.",
      "key_contributions": [
        "계층별 양자화를 위한 효율적 근사 역헤시안 업데이트",
        "1,750억 파라미터 모델의 실용적 양자화를 가능하게 하는 지연 배치 업데이트",
        "1,750억 파라미터 모델을 3-4비트로 압축하여 단일 GPU 실행을 최초로 구현"
      ],
      "algorithms": [
        "Optimal Brain Quantizer (OBQ) Extension (OBQ 확장)",
        "Layer-Wise Quantization with Batch Updates (배치 업데이트 기반 계층별 양자화)",
        "Approximate Inverse Hessian via Cholesky (촐레스키 분해 기반 근사 역헤시안)",
        "Column-Order Quantization (열 순서 양자화)"
      ],
      "key_equations": [
        {
          "name": "OBQ 가중치 갱신",
          "latex": "\\delta_F = -\\frac{\\text{quant}(w_q) - w_q}{[\\mathbf{H}_F^{-1}]_{qq}} \\cdot (\\mathbf{H}_F^{-1})_{:,q}",
          "description": "한 가중치를 양자화할 때 발생하는 오차를, 아직 양자화하지 않은 나머지 가중치를 헤시안 역행렬 정보로 보정하여 흡수한다. 한 가중치의 양자화가 다른 가중치에 미치는 영향을 최소화하는 2차 근사 방법이다."
        }
      ],
      "category": "quantization",
      "tags": [
        "gptq",
        "post-training",
        "second-order",
        "optimal-brain",
        "llm",
        "foundational"
      ],
      "pdf_url": "https://arxiv.org/pdf/2210.17323",
      "code_url": "https://github.com/IST-DASLab/gptq",
      "color_hex": "#9333EA",
      "architecture_detail": "대규모 트랜스포머의 사후 학습 양자화를 위한 2차(second-order) 근사 방법이다. OBQ(Optimal Brain Quantization)의 열 단위 갱신을 행 단위로 전환하여 대규모 모델에도 적용 가능하게 만들었다. 한 가중치를 양자화할 때, 나머지 가중치를 헤시안 정보로 보정하여 전체 출력 변화를 최소화한다. 수십~수백억 파라미터 모델도 단일 GPU에서 몇 시간 만에 양자화할 수 있는 확장성이 특징이다."
    },
    {
      "title": "Finite Scalar Quantization: VQ-VAE Made Simple (FSQ)",
      "authors": [
        "Fabian Mentzer",
        "David Minnen",
        "Eirikur Agustsson",
        "Michael Tschannen"
      ],
      "year": 2023,
      "venue": "ICLR 2024",
      "doi": null,
      "arxiv_id": "2309.15505",
      "abstract": "FSQ는 VQ-VAE의 벡터 양자화를 차원별 스칼라 양자화로 대체하여 소수의 고정 값 집합으로 양자화한다. 암묵적 코드북은 차원별 레벨의 데카르트 곱으로 구성된다. 코드북 붕괴(codebook collapse)를 완전히 제거하고, 커밋먼트 손실, 코드북 재시딩, 엔트로피 페널티가 불필요하다. 극도로 단순한 설계로 경쟁력 있는 성능을 달성한다.",
      "key_contributions": [
        "암묵적 데카르트 곱 코드북을 활용한 차원별 스칼라 양자화",
        "VQ-VAE의 코드북 붕괴 문제를 완전히 제거",
        "보조 손실 불필요: 커밋먼트 손실, 엔트로피 페널티, 코드북 재시딩 없음"
      ],
      "algorithms": [
        "Finite Scalar Quantization (유한 스칼라 양자화)",
        "Per-Dimension Level Rounding (차원별 레벨 반올림)",
        "Implicit Codebook via Cartesian Product (데카르트 곱 기반 암묵적 코드북)",
        "Straight-Through Estimator (Straight-Through 추정기)"
      ],
      "key_equations": [
        {
          "name": "FSQ 양자화",
          "latex": "\\hat{z}_i = \\text{round}\\left(\\frac{L_i - 1}{2} \\cdot \\tanh(z_i)\\right), \\quad |\\mathcal{C}| = \\prod_{i=1}^{d} L_i",
          "description": "각 잠재 차원 i를 L_i개의 정수 레벨로 단순 반올림한다. 전체 코드북 크기는 L₁ × L₂ × ... × L_d로 자동 결정되며, 별도 코드북 학습이 불필요하다. 구현이 매우 간단한 것이 최대 장점이다."
        }
      ],
      "category": "quantization",
      "tags": [
        "fsq",
        "scalar-quantization",
        "vq-vae-alternative",
        "codebook-free",
        "simple",
        "foundational"
      ],
      "pdf_url": "https://arxiv.org/pdf/2309.15505",
      "code_url": "https://github.com/google-research/google-research/tree/master/fsq",
      "color_hex": "#0D9488",
      "architecture_detail": "VQ-VAE의 복잡한 코드북 학습을 완전히 제거하고, 각 잠재 차원을 유한 개의 정수 레벨로 단순 반올림하는 방식이다. 예를 들어 5개 차원을 각각 8레벨로 양자화하면 8^5 = 32,768개의 코드를 별도 코드북 없이 자동으로 얻는다. commitment loss나 EMA 갱신 같은 VQ 학습 트릭이 불필요하여 구현이 매우 간단하면서도, VQ-VAE와 유사한 성능을 보인다."
    },
    {
      "title": "SoundStream: An End-to-End Neural Audio Codec (Residual Vector Quantization)",
      "authors": [
        "Neil Zeghidour",
        "Alejandro Luebs",
        "Ahmed Omran",
        "Jan Skoglund",
        "Marco Tagliasacchi"
      ],
      "year": 2021,
      "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
      "doi": null,
      "arxiv_id": "2107.03312",
      "abstract": "SoundStream은 신경 코덱 압축을 위한 잔차 벡터 양자화(RVQ)를 도입한다. RVQ는 계층적 양자화를 적용하여 첫 번째 단계에서 잠재 벡터를 양자화하고, 후속 단계에서 잔차 오차를 양자화한다. 양자화기 계층에 대한 구조화된 드롭아웃을 통해 단일 모델로 가변 비트레이트(3-18 kbps) 운용이 가능하다.",
      "key_contributions": [
        "잔차 벡터 양자화(RVQ): 계층적 다단계 코드북 캐스케이드",
        "단일 모델로 가변 비트레이트 운용을 위한 구조화된 드롭아웃",
        "인코더, RVQ, 디코더의 종단간 공동 학습"
      ],
      "algorithms": [
        "Residual Vector Quantization (RVQ, 잔차 벡터 양자화)",
        "Multi-Stage Codebook Cascade (다단계 코드북 캐스케이드)",
        "Structured Quantizer Dropout (구조화된 양자화기 드롭아웃)",
        "Discriminator-Based Adversarial Training (판별기 기반 적대적 학습)"
      ],
      "key_equations": [
        {
          "name": "잔차 벡터 양자화 (RVQ)",
          "latex": "\\hat{\\mathbf{z}} = \\sum_{n=1}^{N} \\mathbf{e}_{k_n}^{(n)}, \\quad \\mathbf{r}^{(n)} = \\mathbf{r}^{(n-1)} - \\mathbf{e}_{k_n}^{(n)}, \\quad \\mathbf{r}^{(0)} = \\mathbf{z}",
          "description": "여러 단계의 VQ를 순차 적용하는 구조이다. 1단계: 잠재 벡터를 코드북으로 양자화. 2단계: 1단계 잔차(오차)를 다른 코드북으로 양자화. 이를 반복할수록 정밀해지며, 단계 수로 비트레이트를 조절한다."
        }
      ],
      "category": "quantization",
      "tags": [
        "rvq",
        "residual-vector-quantization",
        "neural-codec",
        "variable-rate",
        "hierarchical",
        "foundational"
      ],
      "pdf_url": "https://arxiv.org/pdf/2107.03312",
      "code_url": null,
      "color_hex": "#EA580C",
      "architecture_detail": "오디오 신호를 위한 엔드투엔드 신경 코덱으로, 잔차 벡터 양자화(RVQ)가 핵심이다. 인코더가 오디오를 잠재 벡터로 변환한 후, 여러 단계의 VQ를 순차 적용한다. 첫 단계에서 대략적으로 양자화하고, 이후 단계들이 잔차(나머지 오차)를 반복적으로 양자화하여 점점 정교해진다. RVQ 단계 수로 비트레이트를 유연하게 조절할 수 있으며, 이 RVQ 아이디어는 CSI 피드백의 벡터 양자화 연구에도 영감을 준다."
    },
    {
      "title": "Vector Quantization for Deep-Learning-Based CSI Feedback with Shape-Gain Decomposition",
      "authors": [
        "Junyong Shin",
        "Yujin Kang",
        "Yo-Seb Jeon"
      ],
      "year": 2024,
      "venue": "IEEE Wireless Communications Letters 2024",
      "doi": "10.1109/LWC.2024.3415633",
      "arxiv_id": "2403.07355",
      "abstract": "이 논문은 VQ-VAE 기반 CSI 피드백에서 잠재 벡터를 shape와 gain으로 분해해 양자화한다. gain은 clipped mu-law 기반 비균일 스칼라 양자화로 처리하고, shape는 학습 가능한 Grassmannian 코드북으로 양자화해 계산량을 줄이면서 복원 성능을 개선한다.",
      "key_contributions": [
        "잠재 벡터를 shape와 gain으로 분해해 서로 다른 양자화기를 적용",
        "clipped mu-law 기반 gain 양자화 설계",
        "Grassmannian 코드북 기반 shape 양자화",
        "nested 코드북과 가중 손실로 multi-rate 피드백 지원"
      ],
      "algorithms": [
        "Shape-Gain Vector Quantization",
        "Clipped mu-law Gain Quantization",
        "Trainable Grassmannian Shape Codebook",
        "Nested Multi-Rate Codebook Training"
      ],
      "key_equations": [
        {
          "name": "shape-gain 분해 양자화",
          "latex": "\\mathbf{z}_{q,i}=Q_{mag}(\\|\\mathbf{z}_i\\|)\\cdot Q_{dir}(\\mathbf{z}_i/\\|\\mathbf{z}_i\\|)",
          "description": "각 서브벡터를 크기와 방향으로 분리해 각각 양자화한 뒤 곱으로 재구성한다."
        },
        {
          "name": "gain 양자화기",
          "latex": "Q_{mag}(\\|\\mathbf{z}_i\\|)=h^{-1}(f_u(h(\\|\\mathbf{z}_i\\|)))",
          "description": "변환 후 균일 양자화, 역변환으로 분포에 맞춘 비균일 gain 양자화를 수행한다."
        },
        {
          "name": "shape 코드북 선택",
          "latex": "Q_{dir}(\\tilde{\\mathbf{z}}_i)=\\arg\\min_{\\mathbf{b}_k\\in\\mathcal{B}_{dir}} d(\\tilde{\\mathbf{z}}_i,\\mathbf{b}_k),\\; d(\\mathbf{c}_1,\\mathbf{c}_2)=\\sqrt{1-|\\langle\\mathbf{c}_1,\\mathbf{c}_2\\rangle|^2}",
          "description": "단위 구면에서 각도 거리 기반으로 코드워드를 선택한다."
        },
        {
          "name": "중첩 코드북 다중율 손실",
          "latex": "\\mathcal{L}^{(l)}_{nvq}=\\frac{1}{\\sum_{k=1}^{l}\\gamma^k}\\sum_{j=1}^{l}\\gamma^j\\left(\\|\\hat{H}^{(j)}-\\tilde{H}_{ad}\\|_F^2+\\|sg(z)-z_q^{(j)}\\|^2+\\beta\\|z-sg(z_q^{(j)})\\|^2\\right)",
          "description": "여러 rate를 단일 학습 과정에서 함께 최적화한다."
        }
      ],
      "category": "quantization",
      "tags": [
        "shape-gain",
        "vq-vae",
        "grassmannian",
        "multi-rate",
        "csi-feedback",
        "finite-rate"
      ],
      "pdf_url": "https://arxiv.org/pdf/2403.07355",
      "code_url": null,
      "color_hex": "#4338CA",
      "architecture_detail": "2.1 문제 설정\nCSI 피드백은 제한된 비트 예산에서 잠재 벡터를 전송해야 한다.\n\n2.2 기존 한계\n스칼라 양자화는 차원 간 상관을 놓치고, 일반 VQ는 코드북 탐색 비용이 크다.\n\n2.3 설계 철학\n방향과 크기를 분리하면 같은 비트 예산에서 계산량을 줄이고 성능을 올릴 수 있다.\n\n2.4 핵심 기법\n- shape-gain 분해\n- clipped mu-law gain 양자화\n- Grassmannian shape 코드북\n- nested multi-rate 코드북\n\n2.5 의미\n복잡도를 O(2^B)에서 O(2^{max(B_mag,B_dir)}) 수준으로 완화한다.\n\n2.6 의의\nVQ 기반 CSI 피드백을 배포 가능한 구조로 발전시켰다.",
      "difficulty_level": "advanced",
      "prerequisites": [
        "VQ-VAE와 commitment loss",
        "벡터 노름과 단위벡터",
        "mu-law companding",
        "massive MIMO CSI 피드백 기본"
      ],
      "learning_objectives": [
        "shape-gain 분해의 복잡도 이점을 설명할 수 있다.",
        "Grassmannian 코드북 초기화 이유를 설명할 수 있다.",
        "single-rate와 nested multi-rate를 비교할 수 있다.",
        "스칼라/VQ/shape-gain 양자화 성능을 해석할 수 있다."
      ],
      "self_check_questions": [
        "왜 shape와 gain을 분리하면 탐색 비용이 줄어드는가?",
        "clipped mu-law가 near-zero 해상도에 주는 효과는 무엇인가?",
        "Grassmannian 초기화가 중요한 이유는 무엇인가?",
        "nested 코드북의 gamma 가중은 어떤 역할을 하는가?"
      ]
    }
  ],
  "relationships": [
    {
      "from_title": "CsiNet-LSTM: A Deep Learning Architecture for Compressive CSI Estimation and Feedback in FDD Massive MIMO",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "extends",
      "description": "CsiNet-LSTM은 시변 CSI의 시간적 상관관계를 활용하기 위해 LSTM 계층을 추가하여 CsiNet을 확장",
      "strength": 10
    },
    {
      "from_title": "Deep Learning-Based CSI Feedback with Variable Length Codewords for Adaptive FDD Massive MIMO",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "extends",
      "description": "CsiNet+는 적응적 압축률 선택을 위해 가변 길이 코드워드를 도입하여 CsiNet을 확장",
      "strength": 10
    },
    {
      "from_title": "CRNet: A Deep-Learning Framework for CSI Feedback in Massive MIMO",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "CRNet은 채널 어텐션을 가진 다중 해상도 CRBlock을 도입하여 CsiNet의 CSI 복원 성능을 개선",
      "strength": 9
    },
    {
      "from_title": "Lightweight and Effective CSI Feedback for Massive MIMO Systems",
      "to_title": "CRNet: A Deep-Learning Framework for CSI Feedback in Massive MIMO",
      "relationship_type": "extends",
      "description": "CLNet은 깊이별 분리 합성곱과 AnciNet을 적용하여 CRNet 기반의 경량화 아키텍처를 구현",
      "strength": 9
    },
    {
      "from_title": "Lightweight and Effective CSI Feedback for Massive MIMO Systems",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "CLNet은 CsiNet의 인코더-디코더 프레임워크를 기반으로 연산 비용을 대폭 절감",
      "strength": 8
    },
    {
      "from_title": "ACRNet: Aggregation Cross-Domain Network for CSI Feedback in Massive MIMO",
      "to_title": "CRNet: A Deep-Learning Framework for CSI Feedback in Massive MIMO",
      "relationship_type": "extends",
      "description": "ACRNet은 CRNet의 다중 해상도 접근법을 교차 도메인(공간 + 주파수) 집계로 확장",
      "strength": 9
    },
    {
      "from_title": "ACRNet: Aggregation Cross-Domain Network for CSI Feedback in Massive MIMO",
      "to_title": "Lightweight and Effective CSI Feedback for Massive MIMO Systems",
      "relationship_type": "compares_with",
      "description": "ACRNet은 CLNet과 비교 벤치마크를 수행하여 더 나은 NMSE를 달성하면서 다른 효율성 절충점을 탐색",
      "strength": 7
    },
    {
      "from_title": "TransNet: Full Attention Network for CSI Feedback in FDD Massive MIMO",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "challenges",
      "description": "TransNet은 Transformer가 장거리 CSI 의존성을 더 잘 포착함을 입증하여 CsiNet의 CNN 기반 접근법에 도전",
      "strength": 9
    },
    {
      "from_title": "TransNet: Full Attention Network for CSI Feedback in FDD Massive MIMO",
      "to_title": "CRNet: A Deep-Learning Framework for CSI Feedback in Massive MIMO",
      "relationship_type": "compares_with",
      "description": "TransNet은 Transformer 기반 어텐션과 CRNet의 CNN 채널 어텐션 접근법을 비교",
      "strength": 7
    },
    {
      "from_title": "DS-NLCsiNet: Exploiting Non-Local Neural Networks for Massive MIMO CSI Feedback",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "DS-NLCsiNet은 비국소 어텐션 블록과 깊이별 분리 합성곱을 추가하여 CsiNet을 발전",
      "strength": 8
    },
    {
      "from_title": "DS-NLCsiNet: Exploiting Non-Local Neural Networks for Massive MIMO CSI Feedback",
      "to_title": "CRNet: A Deep-Learning Framework for CSI Feedback in Massive MIMO",
      "relationship_type": "compares_with",
      "description": "DS-NLCsiNet은 자체 비국소 어텐션 접근법을 CRNet의 채널 어텐션 기준선과 비교",
      "strength": 6
    },
    {
      "from_title": "ENet: Efficient CSI Feedback for Massive MIMO Communications",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "ENet은 UE 측 경량 인코더 배포를 위해 비대칭 인코더-디코더로 CsiNet을 재설계",
      "strength": 8
    },
    {
      "from_title": "ENet: Efficient CSI Feedback for Massive MIMO Communications",
      "to_title": "Lightweight and Effective CSI Feedback for Massive MIMO Systems",
      "relationship_type": "related",
      "description": "ENet과 CLNet 모두 인코더 경량화에 집중하지만 서로 다른 접근법을 사용 (비대칭 설계 vs 깊이별 분리 합성곱)",
      "strength": 6
    },
    {
      "from_title": "Quantization of Deep Neural Networks for Accurate CSI Feedback",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "applies",
      "description": "실용적인 유한 비트 피드백 링크를 위해 CsiNet 계열 코드워드에 양자화 인지 학습을 적용",
      "strength": 8
    },
    {
      "from_title": "Quantization of Deep Neural Networks for Accurate CSI Feedback",
      "to_title": "CRNet: A Deep-Learning Framework for CSI Feedback in Massive MIMO",
      "relationship_type": "applies",
      "description": "CRNet 코드워드에 양자화 프레임워크를 적용하여 4비트 피드백으로도 NMSE가 유지됨을 입증",
      "strength": 7
    },
    {
      "from_title": "Binarized Neural Network for CSI Feedback in Massive MIMO Systems",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "BCsiNet은 UE 하드웨어에서의 극한 모델 압축을 위해 CsiNet의 가중치와 활성화를 1비트로 이진화",
      "strength": 8
    },
    {
      "from_title": "Binarized Neural Network for CSI Feedback in Massive MIMO Systems",
      "to_title": "Quantization of Deep Neural Networks for Accurate CSI Feedback",
      "relationship_type": "related",
      "description": "두 연구 모두 CSI 피드백 배포를 위한 양자화를 다루며, BCsiNet은 극단적 1비트 접근법을 취하고 상대는 다중 비트 QAT를 사용",
      "strength": 8
    },
    {
      "from_title": "Knowledge Distillation-Based DNN for CSI Feedback in Massive MIMO Systems",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "지식 증류를 사용하여 CsiNet 계열 인코더를 경량 학생 네트워크로 압축",
      "strength": 8
    },
    {
      "from_title": "Knowledge Distillation-Based DNN for CSI Feedback in Massive MIMO Systems",
      "to_title": "ENet: Efficient CSI Feedback for Massive MIMO Communications",
      "relationship_type": "related",
      "description": "두 연구 모두 인코더 경량화를 다루지만 접근법이 상이: 지식 증류는 교사-학생 학습, ENet은 아키텍처 비대칭성을 활용",
      "strength": 6
    },
    {
      "from_title": "Knowledge Distillation-Based DNN for CSI Feedback in Massive MIMO Systems",
      "to_title": "Lightweight and Effective CSI Feedback for Massive MIMO Systems",
      "relationship_type": "related",
      "description": "인코더 압축에 대한 상호보완적 접근법: 지식 증류는 학습 전략을 통해, CLNet은 깊이별 분리 아키텍처를 통해 경량화를 달성",
      "strength": 7
    },
    {
      "from_title": "Attention Mechanism-Based CSI Feedback Network for Massive MIMO Systems",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "CsiNet의 인코더-디코더 프레임워크에 이중 공간-채널 어텐션 메커니즘을 추가",
      "strength": 8
    },
    {
      "from_title": "Attention Mechanism-Based CSI Feedback Network for Massive MIMO Systems",
      "to_title": "CRNet: A Deep-Learning Framework for CSI Feedback in Massive MIMO",
      "relationship_type": "inspired_by",
      "description": "CRNet의 채널 어텐션에서 영감을 받아 이중 공간+채널 어텐션 메커니즘으로 확장",
      "strength": 7
    },
    {
      "from_title": "CSI-GPT: Integrating Generative Pre-Trained Transformer with Federated-Tuning for Channel Estimation in Massive MIMO",
      "to_title": "TransNet: Full Attention Network for CSI Feedback in FDD Massive MIMO",
      "relationship_type": "extends",
      "description": "CSI-GPT는 GPT 스타일의 생성적 사전학습과 연합 미세조정을 통해 Transformer 기반 CSI 접근법을 확장",
      "strength": 8
    },
    {
      "from_title": "CSI-GPT: Integrating Generative Pre-Trained Transformer with Federated-Tuning for Channel Estimation in Massive MIMO",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "CSI-GPT는 CsiNet의 피드백 패러다임을 기반으로 교차 시나리오 일반화를 위한 생성적 사전학습 접근법으로 대체",
      "strength": 7
    },
    {
      "from_title": "Deep Learning Based CSI Feedback Approach for Time-Varying Massive MIMO Channels",
      "to_title": "CsiNet-LSTM: A Deep Learning Architecture for Compressive CSI Estimation and Feedback in FDD Massive MIMO",
      "relationship_type": "related",
      "description": "두 연구 모두 시간적 상관관계를 활용하지만 서로 다른 메커니즘을 사용: 차분 인코딩 vs LSTM 순환",
      "strength": 7
    },
    {
      "from_title": "Deep Learning Based CSI Feedback Approach for Time-Varying Massive MIMO Channels",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "시변 채널을 위해 CsiNet 프레임워크에 차분 CSI 인코딩을 추가하여 확장",
      "strength": 8
    },
    {
      "from_title": "Binarized Aggregated Network With Quantization: Flexible Deep Learning Deployment for CSI Feedback in Massive MIMO Systems",
      "to_title": "Quantization of Deep Neural Networks for Accurate CSI Feedback",
      "relationship_type": "extends",
      "description": "균일 양자화를 혼합 정밀도로 확장하여 민감도에 따라 계층별로 다른 비트 폭을 할당",
      "strength": 9
    },
    {
      "from_title": "Binarized Aggregated Network With Quantization: Flexible Deep Learning Deployment for CSI Feedback in Massive MIMO Systems",
      "to_title": "Binarized Neural Network for CSI Feedback in Massive MIMO Systems",
      "relationship_type": "compares_with",
      "description": "다중 비트 혼합 정밀도 접근법과 극단적 1비트 이진화 간의 절충점을 비교",
      "strength": 6
    },
    {
      "from_title": "Pruning Deep Neural Networks for Efficient CSI Feedback",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "applies",
      "description": "인코더 크기 축소를 위해 CsiNet 계열 네트워크에 구조적 프루닝 기법을 적용",
      "strength": 8
    },
    {
      "from_title": "Pruning Deep Neural Networks for Efficient CSI Feedback",
      "to_title": "Knowledge Distillation-Based DNN for CSI Feedback in Massive MIMO Systems",
      "relationship_type": "related",
      "description": "두 연구 모두 모델 압축을 목표로 하지만 전략이 상이: 구조적 프루닝 vs 지식 증류",
      "strength": 7
    },
    {
      "from_title": "Pruning Deep Neural Networks for Efficient CSI Feedback",
      "to_title": "Lightweight and Effective CSI Feedback for Massive MIMO Systems",
      "relationship_type": "compares_with",
      "description": "사후 프루닝 방식과 아키텍처 자체가 경량인 CLNet 접근법을 비교",
      "strength": 6
    },
    {
      "from_title": "Adaptive Bit Allocation for Deep Learning-Based CSI Feedback",
      "to_title": "Quantization of Deep Neural Networks for Accurate CSI Feedback",
      "relationship_type": "extends",
      "description": "고정 양자화를 채널 조건에 기반한 인스턴스 적응형 비트 할당으로 확장",
      "strength": 9
    },
    {
      "from_title": "Adaptive Bit Allocation for Deep Learning-Based CSI Feedback",
      "to_title": "Deep Learning-Based CSI Feedback with Variable Length Codewords for Adaptive FDD Massive MIMO",
      "relationship_type": "inspired_by",
      "description": "CsiNet+의 가변 길이 피드백 개념에서 영감을 받아 적응형 양자화 비트 할당으로 확장",
      "strength": 7
    },
    {
      "from_title": "ShuffleCsiNet: Lightweight CSI Feedback Network Based on ShuffleNet Architecture",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "모바일 배포를 위해 CsiNet의 인코더-디코더에 ShuffleNet 스타일 그룹 합성곱을 적용",
      "strength": 8
    },
    {
      "from_title": "ShuffleCsiNet: Lightweight CSI Feedback Network Based on ShuffleNet Architecture",
      "to_title": "Lightweight and Effective CSI Feedback for Massive MIMO Systems",
      "relationship_type": "compares_with",
      "description": "경량 CSI 인코더 설계를 위한 ShuffleNet 스타일과 깊이별 분리 합성곱 접근법을 비교",
      "strength": 8
    },
    {
      "from_title": "ShuffleCsiNet: Lightweight CSI Feedback Network Based on ShuffleNet Architecture",
      "to_title": "ENet: Efficient CSI Feedback for Massive MIMO Communications",
      "relationship_type": "compares_with",
      "description": "두 연구 모두 모바일 UE 배포를 목표로 하지만 경량화 전략이 상이: ShuffleNet vs 비대칭 설계",
      "strength": 7
    },
    {
      "from_title": "Vector Quantized CSI Feedback with Learned Codebook",
      "to_title": "Quantization of Deep Neural Networks for Accurate CSI Feedback",
      "relationship_type": "challenges",
      "description": "학습된 코드북을 사용한 벡터 양자화가 스칼라 양자화보다 낮은 왜곡을 달성함을 보여 기존 방식에 도전",
      "strength": 8
    },
    {
      "from_title": "Vector Quantized CSI Feedback with Learned Codebook",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "실용적 배포를 위해 CsiNet 코드워드 양자화에 VQ-VAE 프레임워크를 적용",
      "strength": 7
    },
    {
      "from_title": "Generative Diffusion Model-Enhanced CSI Feedback",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "초저율 피드백을 위해 CsiNet 스타일 디코더에 확산 기반 반복 정제를 추가하여 강화",
      "strength": 8
    },
    {
      "from_title": "Generative Diffusion Model-Enhanced CSI Feedback",
      "to_title": "CSI-GPT: Integrating Generative Pre-Trained Transformer with Federated-Tuning for Channel Estimation in Massive MIMO",
      "relationship_type": "related",
      "description": "두 연구 모두 CSI에 생성 모델을 사용하지만 패러다임이 상이: 확산 모델 vs 자기회귀 GPT",
      "strength": 7
    },
    {
      "from_title": "Joint Compression and Quantization for Practical CSI Feedback",
      "to_title": "Quantization of Deep Neural Networks for Accurate CSI Feedback",
      "relationship_type": "extends",
      "description": "분리된 압축+양자화를 종단간 결합 최적화로 확장하여 불일치를 제거",
      "strength": 10
    },
    {
      "from_title": "Joint Compression and Quantization for Practical CSI Feedback",
      "to_title": "Adaptive Bit Allocation for Deep Learning-Based CSI Feedback",
      "relationship_type": "builds_on",
      "description": "적응형 비트 할당을 기반으로 완전한 종단간 율-왜곡 최적화 프레임워크를 구축",
      "strength": 8
    },
    {
      "from_title": "Joint Compression and Quantization for Practical CSI Feedback",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "압축과 양자화를 결합 최적화하여 CsiNet의 실용적 배포 격차를 해소",
      "strength": 9
    },
    {
      "from_title": "Ternary Neural Network for Extreme-Efficient CSI Feedback",
      "to_title": "Binarized Neural Network for CSI Feedback in Massive MIMO Systems",
      "relationship_type": "extends",
      "description": "이진 접근법을 삼진 {-1,0,+1} 양자화로 확장하여 영 상태를 통한 암묵적 프루닝을 추가",
      "strength": 9
    },
    {
      "from_title": "Ternary Neural Network for Extreme-Efficient CSI Feedback",
      "to_title": "Quantization of Deep Neural Networks for Accurate CSI Feedback",
      "relationship_type": "builds_on",
      "description": "이진과 다중 비트 방법을 연결하는 극한 2비트 삼진 접근법으로 CSI 양자화를 발전",
      "strength": 8
    },
    {
      "from_title": "Ternary Neural Network for Extreme-Efficient CSI Feedback",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "극한 모델 압축을 위해 CsiNet 아키텍처에 삼진 양자화를 적용",
      "strength": 8
    },
    {
      "from_title": "AiANet: Attention-Infused Autoencoder for Massive MIMO CSI Compression",
      "to_title": "ACRNet: Aggregation Cross-Domain Network for CSI Feedback in Massive MIMO",
      "relationship_type": "extends",
      "description": "AiANet은 국소 인지 셀프 어텐션을 적용하여 ACRNet 대비 3.42 dB NMSE 개선을 달성",
      "strength": 9
    },
    {
      "from_title": "AiANet: Attention-Infused Autoencoder for Massive MIMO CSI Compression",
      "to_title": "Attention Mechanism-Based CSI Feedback Network for Massive MIMO Systems",
      "relationship_type": "builds_on",
      "description": "어텐션 기반 CSI 피드백을 보다 정교한 국소 인지 셀프 어텐션 메커니즘으로 발전",
      "strength": 8
    },
    {
      "from_title": "AiANet: Attention-Infused Autoencoder for Massive MIMO CSI Compression",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "어텐션 주입 오토인코더와 교차 환경 일반화를 통해 CsiNet 패러다임을 발전",
      "strength": 7
    },
    {
      "from_title": "SLATE: SwinLSTM Autoencoder for Temporal-Spatial-Frequency CSI Compression",
      "to_title": "CsiNet-LSTM: A Deep Learning Architecture for Compressive CSI Estimation and Feedback in FDD Massive MIMO",
      "relationship_type": "extends",
      "description": "시프트 윈도우 어텐션과 순환을 결합한 SwinLSTM으로 LSTM 기반 시간적 CSI 압축을 확장",
      "strength": 9
    },
    {
      "from_title": "SLATE: SwinLSTM Autoencoder for Temporal-Spatial-Frequency CSI Compression",
      "to_title": "TransNet: Full Attention Network for CSI Feedback in FDD Massive MIMO",
      "relationship_type": "builds_on",
      "description": "Transformer 스타일의 시프트 윈도우 어텐션과 LSTM을 결합하여 시간-공간 통합 모델링을 구현",
      "strength": 8
    },
    {
      "from_title": "Quantization Design for Deep Learning-Based CSI Feedback",
      "to_title": "Quantization of Deep Neural Networks for Accurate CSI Feedback",
      "relationship_type": "extends",
      "description": "지능형 요소별 비트 분배와 적응형 결합 손실 함수를 도입하여 QAT를 확장",
      "strength": 9
    },
    {
      "from_title": "Quantization Design for Deep Learning-Based CSI Feedback",
      "to_title": "Adaptive Bit Allocation for Deep Learning-Based CSI Feedback",
      "relationship_type": "builds_on",
      "description": "보다 원리적인 분산 기반 요소별 분배로 적응형 비트 할당을 발전",
      "strength": 8
    },
    {
      "from_title": "Quantization Design for Deep Learning-Based CSI Feedback",
      "to_title": "Joint Compression and Quantization for Practical CSI Feedback",
      "relationship_type": "compares_with",
      "description": "두 연구 모두 CSI 피드백의 실용적 양자화를 다루지만 접근법이 상이: 요소 수준 vs 결합 최적화",
      "strength": 7
    },
    {
      "from_title": "InvCSINet: Invertible Networks with Endogenous Quantization for CSI Feedback",
      "to_title": "Quantization of Deep Neural Networks for Accurate CSI Feedback",
      "relationship_type": "challenges",
      "description": "정보 보존형 가역 아키텍처를 제시하여 기존 오토인코더+양자화 파이프라인에 도전",
      "strength": 8
    },
    {
      "from_title": "InvCSINet: Invertible Networks with Endogenous Quantization for CSI Feedback",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "challenges",
      "description": "정보 손실을 방지하는 전단사 가역 네트워크로 CsiNet의 손실 오토인코더 패러다임에 도전",
      "strength": 9
    },
    {
      "from_title": "InvCSINet: Invertible Networks with Endogenous Quantization for CSI Feedback",
      "to_title": "Vector Quantized CSI Feedback with Learned Codebook",
      "relationship_type": "compares_with",
      "description": "두 연구 모두 미분 가능 양자화를 사용하지만 InvCSINet은 정보 보존을 위한 가역 아키텍처를 추가",
      "strength": 7
    },
    {
      "from_title": "SemCSINet: Semantic-Aware CSI Feedback Network in Massive MIMO Systems",
      "to_title": "TransNet: Full Attention Network for CSI Feedback in FDD Massive MIMO",
      "relationship_type": "extends",
      "description": "의미론적 CQI 임베딩과 결합 코딩-변조를 통해 Transformer 기반 CSI 피드백을 확장",
      "strength": 8
    },
    {
      "from_title": "SemCSINet: Semantic-Aware CSI Feedback Network in Massive MIMO Systems",
      "to_title": "CSI-GPT: Integrating Generative Pre-Trained Transformer with Federated-Tuning for Channel Estimation in Massive MIMO",
      "relationship_type": "related",
      "description": "두 연구 모두 Transformer 기반 CSI 아키텍처에 의미론적/태스크 지향적 개념을 통합",
      "strength": 7
    },
    {
      "from_title": "RD-JSCC: Residual Diffusion for Variable-Rate Joint Source-Channel Coding of MIMO CSI",
      "to_title": "Generative Diffusion Model-Enhanced CSI Feedback",
      "relationship_type": "extends",
      "description": "잔차 확산 정제와 가변률 JSCC 지원을 추가하여 확산 기반 CSI를 확장",
      "strength": 9
    },
    {
      "from_title": "RD-JSCC: Residual Diffusion for Variable-Rate Joint Source-Channel Coding of MIMO CSI",
      "to_title": "Deep Learning-Based CSI Feedback with Variable Length Codewords for Adaptive FDD Massive MIMO",
      "relationship_type": "inspired_by",
      "description": "가변률 피드백 개념에서 영감을 받아 확산 기반 JSCC 단일 모델 접근법으로 구현",
      "strength": 7
    },
    {
      "from_title": "WiFo-CF: Wireless Foundation Model for CSI Feedback",
      "to_title": "CSI-GPT: Integrating Generative Pre-Trained Transformer with Federated-Tuning for Channel Estimation in Massive MIMO",
      "relationship_type": "extends",
      "description": "GPT 스타일 접근법을 MoE 아키텍처와 이종 사전학습을 갖춘 완전한 파운데이션 모델로 확장",
      "strength": 9
    },
    {
      "from_title": "WiFo-CF: Wireless Foundation Model for CSI Feedback",
      "to_title": "TransNet: Full Attention Network for CSI Feedback in FDD Massive MIMO",
      "relationship_type": "builds_on",
      "description": "Transformer 기반 CSI를 태스크 특화 모델에서 범용 사전학습 파운데이션 모델로 확장",
      "strength": 8
    },
    {
      "from_title": "WiFo-CF: Wireless Foundation Model for CSI Feedback",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "시나리오별 CsiNet 학습에서 사전학습 파운데이션 모델 접근법으로의 패러다임 전환을 대표",
      "strength": 8
    },
    {
      "from_title": "EG-CsiNet: Generalizable Learning for Massive MIMO CSI Feedback in Unseen Environments",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "extends",
      "description": "물리 기반 분포 정렬을 통해 CsiNet의 주요 한계인 낮은 일반화 성능을 해결",
      "strength": 9
    },
    {
      "from_title": "EG-CsiNet: Generalizable Learning for Massive MIMO CSI Feedback in Unseen Environments",
      "to_title": "AiANet: Attention-Infused Autoencoder for Massive MIMO CSI Compression",
      "relationship_type": "related",
      "description": "두 연구 모두 교차 환경 일반화를 다루지만 접근법이 상이: AiANet은 혼합 학습, EG-CsiNet은 물리 기반 정렬",
      "strength": 8
    },
    {
      "from_title": "LVM4CF: CSI Feedback with Offline Large Vision Models",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "대규모 비전 모델 특징을 CSI 코드북 설계에 활용하여 컴퓨터 비전과 CSI 피드백을 연결",
      "strength": 7
    },
    {
      "from_title": "LVM4CF: CSI Feedback with Offline Large Vision Models",
      "to_title": "WiFo-CF: Wireless Foundation Model for CSI Feedback",
      "relationship_type": "related",
      "description": "두 연구 모두 CSI 피드백에 대규모 사전학습 모델을 활용: LVM4CF는 오프라인 비전 모델, WiFo-CF는 무선 파운데이션 모델",
      "strength": 8
    },
    {
      "from_title": "Semantic Pilot Design for Channel Estimation Using a Large Language Model",
      "to_title": "CSI-GPT: Integrating Generative Pre-Trained Transformer with Federated-Tuning for Channel Estimation in Massive MIMO",
      "relationship_type": "related",
      "description": "두 연구 모두 대규모 생성 모델을 무선 통신에 적용: LLM은 의미론적 파일럿에, GPT는 CSI 생성에 활용",
      "strength": 7
    },
    {
      "from_title": "Semantic Pilot Design for Channel Estimation Using a Large Language Model",
      "to_title": "SemCSINet: Semantic-Aware CSI Feedback Network in Massive MIMO Systems",
      "relationship_type": "related",
      "description": "두 연구 모두 의미론적 이해를 통합: LLM은 파일럿 추출에, SemCSINet은 피드백용 의미론적 CQI 임베딩에 활용",
      "strength": 6
    },
    {
      "from_title": "Vector Quantized CSI Feedback with Learned Codebook",
      "to_title": "Neural Discrete Representation Learning (VQ-VAE)",
      "relationship_type": "applies",
      "description": "VQ-VAE 프레임워크를 CSI 피드백 코드워드 양자화에 직접 적용",
      "strength": 10
    },
    {
      "from_title": "Vector Quantization for Deep-Learning-Based CSI Feedback with Shape-Gain Decomposition",
      "to_title": "Neural Discrete Representation Learning (VQ-VAE)",
      "relationship_type": "extends",
      "description": "CSI 잠재 벡터의 크기/방향 분리 양자화를 위해 형상-이득 분해를 도입하여 VQ-VAE를 확장",
      "strength": 9
    },
    {
      "from_title": "Vector Quantization for Deep-Learning-Based CSI Feedback with Shape-Gain Decomposition",
      "to_title": "Vector Quantized CSI Feedback with Learned Codebook",
      "relationship_type": "extends",
      "description": "그라스만 방향 코드북과 형상-이득 분해를 추가하여 기본 VQ-CSI를 확장",
      "strength": 9
    },
    {
      "from_title": "Vector Quantization for Deep-Learning-Based CSI Feedback with Shape-Gain Decomposition",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "실용적 배포를 위해 CsiNet 오토인코더에 형상-이득 분해 기반 유한율 VQ를 추가",
      "strength": 8
    },
    {
      "from_title": "Finite Scalar Quantization: VQ-VAE Made Simple (FSQ)",
      "to_title": "Neural Discrete Representation Learning (VQ-VAE)",
      "relationship_type": "challenges",
      "description": "벡터 양자화를 보다 단순한 차원별 스칼라 양자화로 대체하여 VQ-VAE의 복잡성에 도전",
      "strength": 10
    },
    {
      "from_title": "SoundStream: An End-to-End Neural Audio Codec (Residual Vector Quantization)",
      "to_title": "Neural Discrete Representation Learning (VQ-VAE)",
      "relationship_type": "extends",
      "description": "점진적 정제를 위한 잔차 다단계 벡터 양자화를 도입하여 VQ-VAE를 확장",
      "strength": 9
    },
    {
      "from_title": "AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration",
      "to_title": "Binarized Aggregated Network With Quantization: Flexible Deep Learning Deployment for CSI Feedback in Massive MIMO Systems",
      "relationship_type": "inspires",
      "description": "AWQ의 활성화 인지 중요도 개념이 CSI 양자화에서의 채널별 중요도 분석에 영감을 제공",
      "strength": 7
    },
    {
      "from_title": "HAWQ-V3: Dyadic Neural Network Quantization",
      "to_title": "Binarized Aggregated Network With Quantization: Flexible Deep Learning Deployment for CSI Feedback in Massive MIMO Systems",
      "relationship_type": "inspires",
      "description": "HAWQ-V3의 헤시안 기반 계층별 비트 할당이 혼합 정밀도 CSI 피드백에 직접 적용 가능",
      "strength": 8
    },
    {
      "from_title": "HAWQ-V3: Dyadic Neural Network Quantization",
      "to_title": "Adaptive Bit Allocation for Deep Learning-Based CSI Feedback",
      "relationship_type": "inspires",
      "description": "헤시안 기반 민감도 분석이 CSI 코드워드의 적응형 차원별 비트 할당에 영감을 제공",
      "strength": 8
    },
    {
      "from_title": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers",
      "to_title": "HAWQ-V3: Dyadic Neural Network Quantization",
      "relationship_type": "builds_on",
      "description": "두 연구 모두 2차(헤시안) 정보를 사용하며, GPTQ는 OBQ 프레임워크를 통해 학습 후 설정으로 확장",
      "strength": 8
    },
    {
      "from_title": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers",
      "to_title": "Quantization of Deep Neural Networks for Accurate CSI Feedback",
      "relationship_type": "related",
      "description": "GPTQ의 2차 학습 후 양자화 접근법이 사전학습된 CSI 피드백 모델의 양자화에 적용 가능",
      "strength": 6
    },
    {
      "from_title": "AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration",
      "to_title": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers",
      "relationship_type": "compares_with",
      "description": "두 연구 모두 저비트 가중치 양자화를 목표로 하며, AWQ는 활성화 인지 스케일링을, GPTQ는 2차 업데이트를 사용",
      "strength": 8
    },
    {
      "from_title": "InvCSINet: Invertible Networks with Endogenous Quantization for CSI Feedback",
      "to_title": "Finite Scalar Quantization: VQ-VAE Made Simple (FSQ)",
      "relationship_type": "related",
      "description": "두 연구 모두 잠재 양자화를 단순화: InvCSINet의 DAQ는 요소별 적응형 스텝 크기를, FSQ는 고정 차원별 레벨을 사용",
      "strength": 7
    },
    {
      "from_title": "RD-JSCC: Residual Diffusion for Variable-Rate Joint Source-Channel Coding of MIMO CSI",
      "to_title": "SoundStream: An End-to-End Neural Audio Codec (Residual Vector Quantization)",
      "relationship_type": "inspired_by",
      "description": "RD-JSCC의 가변률 단일 모델 접근법은 SoundStream의 가변 비트레이트용 구조적 드롭아웃을 반영",
      "strength": 7
    },
    {
      "from_title": "Quantization Design for Deep Learning-Based CSI Feedback",
      "to_title": "AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration",
      "relationship_type": "inspired_by",
      "description": "요소별 중요도 기반 비트 분배가 AWQ의 활성화 인지 중요도 탐지에서 영감을 받음",
      "strength": 7
    },
    {
      "from_title": "Ternary Neural Network for Extreme-Efficient CSI Feedback",
      "to_title": "HAWQ-V3: Dyadic Neural Network Quantization",
      "relationship_type": "related",
      "description": "두 연구 모두 극저비트 양자화를 추구: 삼진 2비트 가중치 vs HAWQ-V3의 정수 전용 INT4",
      "strength": 6
    },
    {
      "from_title": "Quantization Adaptor for Bit-Level Deep Learning-Based Massive MIMO CSI Feedback",
      "to_title": "Quantization of Deep Neural Networks for Accurate CSI Feedback",
      "relationship_type": "extends",
      "description": "기존 코드워드 양자화 프레임워크에 adaptor 기반 오차 보정과 학습 스케줄을 추가해 저비트 성능을 개선한다.",
      "strength": 9
    },
    {
      "from_title": "Quantization Adaptor for Bit-Level Deep Learning-Based Massive MIMO CSI Feedback",
      "to_title": "Deep Learning for Massive MIMO CSI Feedback",
      "relationship_type": "builds_on",
      "description": "CsiNet 계열 오토인코더 파이프라인 위에 bit-level 양자화 실용화 계층을 추가한다.",
      "strength": 8
    },
    {
      "from_title": "Quantization Adaptor for Bit-Level Deep Learning-Based Massive MIMO CSI Feedback",
      "to_title": "Joint Compression and Quantization for Practical CSI Feedback",
      "relationship_type": "compares_with",
      "description": "둘 다 실배포 지향 양자화 연구지만, 본 논문은 adaptor 기반 보정으로 저비트 왜곡 완화에 집중한다.",
      "strength": 7
    },
    {
      "from_title": "BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction",
      "to_title": "HAWQ-V3: Dyadic Neural Network Quantization",
      "relationship_type": "related",
      "description": "두 연구 모두 2차 민감도 정보를 사용하지만, BRECQ는 PTQ block reconstruction에, HAWQ-V3는 integer-only ILP 배치에 초점을 둔다.",
      "strength": 8
    },
    {
      "from_title": "Quantization Adaptor for Bit-Level Deep Learning-Based Massive MIMO CSI Feedback",
      "to_title": "BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction",
      "relationship_type": "inspired_by",
      "description": "저비트 양자화 오차 보정 관점에서 BRECQ의 재구성 아이디어와 문제의식을 공유한다.",
      "strength": 6
    },
    {
      "from_title": "Vector Quantization for Deep-Learning-Based CSI Feedback with Shape-Gain Decomposition",
      "to_title": "Quantization Adaptor for Bit-Level Deep Learning-Based Massive MIMO CSI Feedback",
      "relationship_type": "compares_with",
      "description": "둘 다 CSI bit-level 전송을 다루지만 adaptor 보정 기반 접근과 shape-gain VQ 코드북 접근으로 방법이 다르다.",
      "strength": 7
    }
  ]
}
